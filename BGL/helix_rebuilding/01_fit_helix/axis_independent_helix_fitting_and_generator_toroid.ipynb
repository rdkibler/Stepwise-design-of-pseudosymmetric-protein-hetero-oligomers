{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyRosetta-4 2019 [Rosetta PyRosetta4.conda.linux.CentOS.python37.Release 2019.19.post.dev+17.commits.d5a7d8129801bf7eaf383dba4ad48c78085ffd42 2019-05-20T01:48:51] retrieved from: http://www.pyrosetta.org\n",
      "(C) Copyright Rosetta Commons Member Institutions. Created in JHU by Sergey Lyskov and PyRosetta Team.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from Bio.PDB import PDBParser # for parsing input structure\n",
    "from math import cos,sin,tan,asin,acos,radians,sqrt,degrees,atan\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lmfit import Parameters,minimize,report_fit # fot fitting helix\n",
    "import io # for printing output to file\n",
    "from contextlib import redirect_stdout # for printing output to file\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "import pyrosetta\n",
    "#from rosetta import *\n",
    "pyrosetta.init(\"-beta_nov16 -mute all\")\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_helix_coords(pose, min_len=3):\n",
    "    \"\"\"Given a secondary strucure asignmet, count the number of helices (at least as long as min_len)\n",
    "    \"\"\"\n",
    "    \n",
    "    if min_len < 1:\n",
    "        raise ValueError\n",
    "    \n",
    "    pyrosetta.rosetta.core.scoring.dssp.Dssp(pose).insert_ss_into_pose(pose, True)\n",
    "    \n",
    "    all_helix_resis=[]\n",
    "    \n",
    "    \n",
    "    for chain in pyrosetta.rosetta.core.pose.get_chains(pose):\n",
    "        current_helix_resis=[]\n",
    "        \n",
    "        for res_num in pyrosetta.rosetta.core.pose.get_resnums_for_chain_id(pose,chain):\n",
    "            res_ss = pose.secstruct(res_num)\n",
    "            if res_ss == 'H':\n",
    "                current_helix_resis.append(res_num)\n",
    "            else:\n",
    "                if len(current_helix_resis) >= min_len:\n",
    "                    all_helix_resis.append(current_helix_resis)\n",
    "                current_helix_resis = []\n",
    "        if len(current_helix_resis) >= min_len:\n",
    "            all_helix_resis.append(current_helix_resis)\n",
    "    \n",
    "    #now I need to convert those resis to Calpha coords\n",
    "    all_helix_coords = []\n",
    "    for helix in all_helix_resis:\n",
    "        helix_coords = []\n",
    "        for res_id in helix:\n",
    "            \n",
    "            res = pose.residue(res_id)\n",
    "            ca = res.atom(\"CA\")\n",
    "            x,y,z = ca.xyz()\n",
    "            x = float(x)\n",
    "            y = float(y)\n",
    "            z = float(z)\n",
    "            helix_coords.append([x,y,z])\n",
    "        arr_helix_coords = np.array(helix_coords)\n",
    "        all_helix_coords.append(arr_helix_coords)\n",
    "    return all_helix_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.78867513 -0.21132487  0.57735027]\n",
      " [-0.21132487  0.78867513  0.57735027]\n",
      " [-0.57735027 -0.57735027  0.57735027]]\n",
      "[0.57735027 0.57735027 0.57735027] [0.57735027 0.57735027 0.57735027]\n"
     ]
    }
   ],
   "source": [
    "def normalize(v):\n",
    "    norm = np.linalg.norm(v)\n",
    "    if norm == 0: \n",
    "        return v\n",
    "    return v / norm\n",
    "\n",
    "# Calculates Rotation Matrix given euler angles and back.\n",
    "#https://www.learnopencv.com/rotation-matrix-to-euler-angles/\n",
    "def euler_to_R(phi,theta,psi):\n",
    "    R_x = np.array([[1,         0,                  0                   ],\n",
    "                    [0,         np.cos(phi), -np.sin(phi) ],\n",
    "                    [0,         np.sin(phi), np.cos(phi)  ]\n",
    "                    ])\n",
    "\n",
    "    R_y = np.array([[np.cos(theta),    0,      np.sin(theta)  ],\n",
    "                    [0,                     1,      0                   ],\n",
    "                    [-np.sin(theta),   0,      np.cos(theta)  ]\n",
    "                    ])\n",
    "\n",
    "    R_z = np.array([[np.cos(psi),    -np.sin(psi),    0],\n",
    "                    [np.sin(psi),    np.cos(psi),     0],\n",
    "                    [0,                     0,                      1]\n",
    "                    ])\n",
    "\n",
    "    R = np.dot(R_z, np.dot( R_y, R_x ))\n",
    "\n",
    "    return R\n",
    "\n",
    "\n",
    "def isRotationMatrix(R) :\n",
    "    Rt = np.transpose(R)\n",
    "    shouldBeIdentity = np.dot(Rt, R)\n",
    "    I = np.identity(3, dtype = R.dtype)\n",
    "    n = np.linalg.norm(I - shouldBeIdentity)\n",
    "    return n < 1e-6\n",
    "\n",
    "def R_to_euler(R) :\n",
    "    assert(isRotationMatrix(R))\n",
    "\n",
    "    s_y = np.sqrt(R[0,0] * R[0,0] +  R[1,0] * R[1,0])\n",
    "\n",
    "    singular = s_y < 1e-6\n",
    "\n",
    "    if  not singular :\n",
    "        phi = np.arctan2(R[2,1] , R[2,2])\n",
    "        theta = np.arctan2(-R[2,0], s_y)\n",
    "        psi = np.arctan2(R[1,0], R[0,0])\n",
    "    else :\n",
    "        phi = np.arctan2(-R[1,2], R[1,1])\n",
    "        theta = np.arctan2(-R[2,0], s_y)\n",
    "        psi = 0\n",
    "\n",
    "    return np.array([phi, theta, psi])\n",
    "\n",
    "\n",
    "def rotation(u,v):\n",
    "    #a = np.array([0,0,1])\n",
    "    #b = random_tilt_u(sigma)\n",
    "    a = normalize(u)\n",
    "    b = normalize(v)\n",
    "    \n",
    "    v = np.cross(a,b)\n",
    "    s = np.linalg.norm(v) #?\n",
    "    c = a.dot(b)\n",
    "    I = np.identity(3)\n",
    "    \n",
    "    #vXStr = '{} {} {}; {} {} {}; {} {} {}'.format(0, -v[2], v[1], v[2], 0, -v[0], -v[1], v[0], 0)\n",
    "    #k = np.matrix(vXStr)\n",
    "    \n",
    "    k = np.array([[0 , -v[2], v[1]],\n",
    "                  [v[2], 0, -v[0]],\n",
    "                  [-v[1], v[0], 0]])\n",
    "    \n",
    "    R = I + k + np.matmul(k,k) * ((1 -c)/(s**2))\n",
    "    assert(isRotationMatrix(R))\n",
    "    return R\n",
    "\n",
    "\n",
    "u = [0,0,1]\n",
    "v = normalize([1,1,1])\n",
    "R1 = rotation(u,v)\n",
    "print(R1)\n",
    "print(R1.dot(u),v)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class HelixParameters():\n",
    "    def __init__(self,r0=None,omega0=None,omega1=None,phi0=None,phi1=None,delta_z=None,invert=None,helix_length=None,z_aligned=False,translate_x=None,translate_y=None,translate_z=None,rotate_phi=None,rotate_theta=None,rotate_psi=None):\n",
    "        self._r0,self._omega0,self._omega1,self._phi0,self._phi1,self._delta_z,self._invert,self._length,self._d,self._r1 = (None,)*10\n",
    "        \n",
    "        self._translate_x, self._translate_y, self._translate_z, self._rotate_phi, self._rotate_theta,self._rotate_psi = (None,)*6\n",
    "        \n",
    "        self.r0(r0)\n",
    "        self.omega0(omega0)\n",
    "        self.omega1(omega1)\n",
    "        self.phi0(phi0)\n",
    "        self.phi1(phi1)\n",
    "        self.delta_z(delta_z)\n",
    "        self.invert(invert)\n",
    "        self.length(helix_length)\n",
    "        self._d = 1.51 # FIXED, distance between successive residues along the helical axis, [angstrom] -- BundleGridSampler=z1\n",
    "        self._r1 = 2.26 # FIXED, helical radius, [angstrom] -- BundleGridSampler=r1_peratom        \n",
    "        \n",
    "        self.z_aligned = z_aligned\n",
    "        \n",
    "        if self.z_aligned and any([translate_x,translate_y,translate_z,rotate_phi,rotate_theta,rotate_psi]):\n",
    "            raise ValueError(\"no transformation parameters are allowed in z_aligned mode\")\n",
    "        \n",
    "        if not self.z_aligned:\n",
    "            self.translate_x(translate_x)\n",
    "            self.translate_y(translate_y)\n",
    "            self.translate_z(translate_z)\n",
    "            self.rotate_phi(rotate_phi)\n",
    "            self.rotate_theta(rotate_theta)\n",
    "            self.rotate_psi(rotate_psi)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Helical Parameters: r0={self.r0()},omega0={self.omega0()},omega1={self.omega1()},phi0={self.phi0()},' \\\n",
    "               f'phi1={self.phi1()},delta_z={self.delta_z()},d={self.d()},r1={self.r1()},' \\\n",
    "               f'translate_x={self.translate_x()},translate_y={self.translate_y()},translate_z={self.translate_z()},' \\\n",
    "               f'rotate_phi={self.rotate_phi()},rotate_theta={self.rotate_theta()},rotate_psi={self.rotate_psi()},' \\\n",
    "               f'invert={self.invert()},length={self.length()}'\n",
    "    \n",
    "    #hybrid setters/getters. They will always return the value you ask for, but if you pass \n",
    "    #something to the function, it'll update the stored value and then return the (updated) value\n",
    "    def r0(self,r0:float=None):\n",
    "        if r0 is not None:\n",
    "            assert(r0 >0)\n",
    "            #assert(r0 <= 20)\n",
    "            self._r0 = r0\n",
    "        return self._r0\n",
    "        \n",
    "    def omega0(self,omega0:float=None):\n",
    "        if omega0 is not None:\n",
    "            self._omega0 = omega0\n",
    "        return self._omega0\n",
    "            \n",
    "    def omega1(self,omega1:float=None):    \n",
    "        if omega1 is not None:\n",
    "            self._omega1 = omega1\n",
    "        return self._omega1\n",
    "    \n",
    "    def phi0(self,phi0:float=None):\n",
    "        if phi0 is not None:\n",
    "            assert(phi0 >= 0) #enforece pos only\n",
    "            self._phi0 = phi0\n",
    "        return self._phi0\n",
    "    \n",
    "    def phi1(self,phi1:float=None):\n",
    "        if phi1 is not None:\n",
    "            self._phi1 = phi1\n",
    "        return self._phi1\n",
    "    \n",
    "    def delta_z(self,delta_z:float=None):\n",
    "        if delta_z is not None:\n",
    "            self._delta_z = delta_z\n",
    "        return self._delta_z\n",
    "    \n",
    "    def invert(self,invert:bool=None):\n",
    "        if invert is not None:\n",
    "            self._invert = invert\n",
    "        return self._invert\n",
    "    \n",
    "    def length(self,length:int=None):\n",
    "        if length is not None:\n",
    "            self._length = length\n",
    "        return self._length\n",
    "    \n",
    "    def d(self,d:float=None):\n",
    "        if d is not None:\n",
    "            warnings.warn(\"HelixParamaters variable d is a physical constraint should not be touched\")\n",
    "            self._d = d\n",
    "        return self._d\n",
    "    \n",
    "    def r1(self,r1:float=None):\n",
    "        if r1 is not None:\n",
    "            warnings.warn(\"HelixParamaters variable r1 is a physical constraint should not be touched\")\n",
    "            self._r1 = r1\n",
    "        return self._r1\n",
    "    \n",
    "    \n",
    "    #new axis independent code\n",
    "    def translate_x(self,x:float=None):\n",
    "        if x is not None:\n",
    "            self._translate_x = x\n",
    "        #print(f\"self._translate_x: {self._translate_x}\")\n",
    "        return self._translate_x\n",
    "    \n",
    "    def translate_y(self,y:float=None):\n",
    "        if y is not None:\n",
    "            self._translate_y = y\n",
    "        #print(f\"self._translate_y: {self._translate_y}\")\n",
    "        return self._translate_y\n",
    "    \n",
    "    def translate_z(self,z:float=None):\n",
    "        if z is not None:\n",
    "            self._translate_z = z\n",
    "        #print(f\"self._translate_z: {self._translate_z}\")\n",
    "        return self._translate_z\n",
    "    \n",
    "    def rotate_phi(self,phi:float=None):\n",
    "        if phi is not None:\n",
    "            self._rotate_phi = phi\n",
    "        #print(f\"self._rotate_phi: {self._rotate_phi}\")\n",
    "        return self._rotate_phi\n",
    "    \n",
    "    def rotate_theta(self,theta:float=None):\n",
    "        if theta is not None:\n",
    "            self._rotate_theta = theta\n",
    "        #print(f\"self._rotate_theta: {self._rotate_theta}\")\n",
    "        return self._rotate_theta\n",
    "    \n",
    "    def rotate_psi(self,psi:float=None):\n",
    "        if psi is not None:\n",
    "            self._rotate_psi = psi\n",
    "        #print(f\"self._rotate_psi: {self._rotate_psi}\")\n",
    "        return self._rotate_psi\n",
    "    \n",
    "    def transformation_matrix(self):\n",
    "        if self.z_aligned:\n",
    "            return np.identity(4)\n",
    "            \n",
    "            \n",
    "        R = euler_to_R(self.rotate_phi(),self.rotate_theta(),self.rotate_psi())\n",
    "        #print(R)\n",
    "        #R.resize(4,4)\n",
    "        M = np.append(np.append(R,[[0]*3],axis=0),[[0]]*4,axis=1)\n",
    "        #print(M)\n",
    "        M[3][3] = 1\n",
    "        M[0][3] = self.translate_x()\n",
    "        M[1][3] = self.translate_y()\n",
    "        M[2][3] = self.translate_z()\n",
    "        #print(M)\n",
    "        return M\n",
    "    \n",
    "    def to_lmfit_parameters(self, round_num=None):\n",
    "        if self.z_aligned and round_num is not None:\n",
    "            raise ValueError(\"z aligned mode only has one round. Just don't set round_num\")\n",
    "        \n",
    "        if self.z_aligned:\n",
    "            params = Parameters()\n",
    "            params.add('r0', value=self.r0(), min=0.000001, max=40, vary=True) # avoid negative radii\n",
    "            params.add('omega0', value=self.omega0(), vary=True)\n",
    "            params.add('omega1', value=self.omega1(),  vary=True)\n",
    "            params.add('phi0', value=self.phi0(), min=0,vary=True) # enforce positive values only\n",
    "            params.add('phi1', value=self.phi1(),vary=True)\n",
    "            params.add('delta_z', value=self.delta_z(), vary=True)\n",
    "            params.add('invert', value=self.invert(), vary=False)\n",
    "            \n",
    "            return params\n",
    "        \n",
    "        if round_num is None:\n",
    "            params = Parameters()\n",
    "            params.add('r0', value=self.r0(), min=0.0000000001, max=20, vary=True) # avoid zero\n",
    "\n",
    "            params.add('omega0', value=self.omega0(),min=radians(-10),max=radians(10), vary=True)\n",
    "            #params.add('d', value=self.d(),vary=False)\n",
    "            #params.add('omega0', value=self.omega0(), expr='r0/d')\n",
    "            #print(\"I attempted to tie these values together but I'm not sure it worked\")\n",
    "\n",
    "            params.add('omega1', value=self.omega1(),min=radians(80),max=radians(120), vary=True) #TODO:use a function constraint to tie omega0 and omega1 together\n",
    "            params.add('omega1_omega0_coupling', value=0,min=radians(-10),max=radians(10),expr=\"abs(omega0+omega1)-radians(100)\")\n",
    "            params.add('phi0', value=self.phi0(), min=0,vary=False) # enforce positive values only\n",
    "            params.add('phi1', value=self.phi1(),vary=True)\n",
    "            params.add('delta_z', value=self.delta_z(), vary=False) #taken care of by axis_independent code?\n",
    "            params.add('invert', value=self.invert(), vary=False)\n",
    "\n",
    "            #r0*omega0 = d * sin(alpha)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "            return params\n",
    "        \n",
    "        elif round_num == 1:\n",
    "            params = Parameters()\n",
    "            params.add('r0', value=self.r0(), min=5, max=20, vary=False) # avoid zero\n",
    "\n",
    "            params.add('omega0', value=self.omega0(),min=radians(-10),max=radians(10), vary=False)\n",
    "            #params.add('d', value=self.d(),vary=False)\n",
    "            #params.add('omega0', value=self.omega0(), expr='r0/d')\n",
    "            #print(\"I attempted to tie these values together but I'm not sure it worked\")\n",
    "\n",
    "            params.add('omega1', value=self.omega1(),min=radians(80),max=radians(120), vary=False) #TODO:use a function constraint to tie omega0 and omega1 together\n",
    "            params.add('omega1_omega0_coupling', value=0,min=radians(-10),max=radians(10),expr=\"abs(omega0+omega1)-radians(100)\",vary=False)\n",
    "            params.add('phi0', value=self.phi0(), min=0,vary=False) # enforce positive values only\n",
    "            params.add('phi1', value=self.phi1(),vary=True)\n",
    "            params.add('delta_z', value=self.delta_z(), vary=False) #taken care of by axis_independent code?\n",
    "            params.add('invert', value=self.invert(), vary=False)\n",
    "\n",
    "            #axis independent code:\n",
    "            params.add('translate_x', value=self.translate_x(),vary=True)\n",
    "            params.add('translate_y', value=self.translate_y(),vary=True)\n",
    "            params.add('translate_z', value=self.translate_z(),vary=True)\n",
    "            params.add('rotate_phi', value=self.rotate_phi(),min=-np.pi,max=np.pi,vary=True)\n",
    "            params.add('rotate_theta', value=self.rotate_theta(),min=-np.pi,max=np.pi,vary=True)\n",
    "            params.add('rotate_psi',value=self.rotate_psi(),min=-np.pi,max=np.pi,vary=True)\n",
    "        \n",
    "            return params\n",
    "        \n",
    "        elif round_num == 2:\n",
    "            params = Parameters()\n",
    "            params.add('r0', value=self.r0(), min=5, max=20, vary=True) # avoid zero\n",
    "\n",
    "            params.add('omega0', value=self.omega0(),min=radians(-10),max=radians(10), vary=True)\n",
    "            #params.add('d', value=self.d(),vary=False)\n",
    "            #params.add('omega0', value=self.omega0(), expr='r0/d')\n",
    "            #print(\"I attempted to tie these values together but I'm not sure it worked\")\n",
    "\n",
    "            params.add('omega1', value=self.omega1(),min=radians(80),max=radians(120), vary=True) #TODO:use a function constraint to tie omega0 and omega1 together\n",
    "            params.add('omega1_omega0_coupling', value=0,min=radians(-10),max=radians(10),expr=\"abs(omega0+omega1)-radians(100)\",vary=True)\n",
    "            params.add('phi0', value=self.phi0(), min=0,vary=True) # enforce positive values only\n",
    "            params.add('phi1', value=self.phi1(),vary=True)\n",
    "            params.add('delta_z', value=self.delta_z(), vary=False) #taken care of by axis_independent code?\n",
    "            params.add('invert', value=self.invert(), vary=False)\n",
    "\n",
    "            #axis independent code:\n",
    "            params.add('translate_x', value=self.translate_x(),vary=False)\n",
    "            params.add('translate_y', value=self.translate_y(),vary=False)\n",
    "            params.add('translate_z', value=self.translate_z(),vary=False)\n",
    "            params.add('rotate_phi', value=self.rotate_phi(),min=-np.pi,max=np.pi,vary=False)\n",
    "            params.add('rotate_theta', value=self.rotate_theta(),min=-np.pi,max=np.pi,vary=False)\n",
    "            params.add('rotate_psi',value=self.rotate_psi(),min=-np.pi,max=np.pi,vary=False)\n",
    "        \n",
    "            return params\n",
    "        \n",
    "        elif round_num == 3:\n",
    "            params = Parameters()\n",
    "            params.add('r0', value=self.r0(), min=5, max=20, vary=True) # avoid zero\n",
    "\n",
    "            params.add('omega0', value=self.omega0(),min=radians(-10),max=radians(10), vary=True)\n",
    "            #params.add('d', value=self.d(),vary=False)\n",
    "            #params.add('omega0', value=self.omega0(), expr='r0/d')\n",
    "            #print(\"I attempted to tie these values together but I'm not sure it worked\")\n",
    "\n",
    "            params.add('omega1', value=self.omega1(),min=radians(80),max=radians(120), vary=True) #TODO:use a function constraint to tie omega0 and omega1 together\n",
    "            params.add('omega1_omega0_coupling', value=0,min=radians(-10),max=radians(10),expr=\"abs(omega0+omega1)-radians(100)\")\n",
    "            params.add('phi0', value=self.phi0(), min=0,vary=False) # enforce positive values only\n",
    "            params.add('phi1', value=self.phi1(),vary=True)\n",
    "            params.add('delta_z', value=self.delta_z(), vary=False) #taken care of by axis_independent code?\n",
    "            params.add('invert', value=self.invert(), vary=False)\n",
    "\n",
    "            #r0*omega0 = d * sin(alpha)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #axis independent code:\n",
    "            params.add('translate_x', value=self.translate_x(),vary=True)\n",
    "            params.add('translate_y', value=self.translate_y(),vary=True)\n",
    "            params.add('translate_z', value=self.translate_z(),vary=True)\n",
    "            params.add('rotate_phi', value=self.rotate_phi(),min=-np.pi,max=np.pi,vary=True)\n",
    "            params.add('rotate_theta', value=self.rotate_theta(),min=-np.pi,max=np.pi,vary=True)\n",
    "            params.add('rotate_psi',value=self.rotate_psi(),min=-np.pi,max=np.pi,vary=True)\n",
    "        \n",
    "            return params\n",
    "        else:\n",
    "            print(f\"round_num {round_num} not recognized\")\n",
    "            return None\n",
    "    \n",
    "    \n",
    "    def from_lmfit(self, fit):\n",
    "        self.r0(fit.valuesdict()['r0'])\n",
    "        self.omega0(fit.valuesdict()['omega0'])\n",
    "        self.omega1(fit.valuesdict()['omega1'])\n",
    "        self.phi0(fit.valuesdict()['phi0'])\n",
    "        self.phi1(fit.valuesdict()['phi1'])\n",
    "        self.delta_z(fit.valuesdict()['delta_z'])\n",
    "        self.invert(fit.valuesdict()['invert'])\n",
    "        \n",
    "        if not self.z_aligned:\n",
    "\n",
    "            self.translate_x(fit.valuesdict()['translate_x'])\n",
    "            self.translate_y(fit.valuesdict()['translate_y'])\n",
    "            self.translate_z(fit.valuesdict()['translate_z'])\n",
    "            self.rotate_phi(fit.valuesdict()['rotate_phi'])\n",
    "            self.rotate_theta(fit.valuesdict()['rotate_theta'])\n",
    "            self.rotate_psi(fit.valuesdict()['rotate_psi'])\n",
    "        \n",
    "       \n",
    "    def get_dict(self):\n",
    "        d = {\n",
    "            'r0':self.r0(),\n",
    "            'omega0':self.omega0(),\n",
    "            'omega1':self.omega1(),\n",
    "            'phi0':self.phi0(),\n",
    "            'phi1':self.phi1(),\n",
    "            'delta_z':self.delta_z(),\n",
    "            'd':self.d(),\n",
    "            'r1':self.r1(),\n",
    "            'translate_x':self.translate_x(),\n",
    "            'translate_y':self.translate_y(),\n",
    "            'translate_z':self.translate_z(),\n",
    "            'rotate_phi':self.rotate_phi(),\n",
    "            'rotate_theta':self.rotate_theta(),\n",
    "            'rotate_psi':self.rotate_psi(),\n",
    "            'invert':self.invert(),\n",
    "            'length':self.length()\n",
    "        }\n",
    "        \n",
    "        return d\n",
    "\n",
    "import warnings \n",
    "\n",
    "class ParametricFit():\n",
    "    def __init__(self, name, fit=None, write_axis=False):\n",
    "        self._name = None\n",
    "        self.write_axis = write_axis\n",
    "        if self.write_axis:\n",
    "            self.axis_movie = []\n",
    "        self.fit = pd.DataFrame()\n",
    "        self.coordinate_movie = []\n",
    "        self.rmsd = []\n",
    "        self.parameter_history=[]\n",
    "        if name is None:\n",
    "            name = \"parametric_fit\"\n",
    "        self.name(name)\n",
    "\n",
    "        if fit is not None:\n",
    "            self.parse_fit(fit)\n",
    "            \n",
    "    #this really should only be accessed by the ParametricHelix class\n",
    "    #take a fit and \n",
    "    def parse_fit(self, fit):\n",
    "        self.fit = fit\n",
    "        warnings.warn(\"PARSE_FIT NOT IMPLEMENTED\")\n",
    "    \n",
    "    def name(self,name:str=None):\n",
    "        if name is not None:\n",
    "            self._name = name\n",
    "        return self._name\n",
    "    \n",
    "    def append_trajectory_rmsd(self,rmsd):\n",
    "        self.rmsd.append(rmsd)\n",
    "\n",
    "    def append_trajectory_coords(self,coords, axis=None):\n",
    "        self.coordinate_movie.append(coords)\n",
    "        if self.write_axis:\n",
    "            self.axis_movie.append(axis)\n",
    "\n",
    "    def write_trajectory_movie(self, filename):\n",
    "        # Generate movie PDB of fitting trajectories\n",
    "        f=open(filename,'w')\n",
    "        model=1\n",
    "        for coord_frame,ax_frame in zip(self.coordinate_movie,self.axis_movie):\n",
    "            resid=1\n",
    "            atomnumb=2\n",
    "            f.write('MODEL{:>8s}\\n'.format(str(model)))  \n",
    "            for i in coord_frame:\n",
    "                f.write('ATOM{:>7s}  CA  ALA A{:>4s}     {:>7.3f} {:>7.3f} {:>7.3f}  1.00  0.00           C\\n'.format(str(atomnumb),str(resid),float(i[0]),float(i[1]),float(i[2])))\n",
    "                resid=resid+1\n",
    "                atomnumb=atomnumb+10\n",
    "            if self.write_axis:\n",
    "                for i in ax_frame:\n",
    "                    f.write('ATOM{:>7s}  CA  ALA B{:>4s}     {:>7.3f} {:>7.3f} {:>7.3f}  1.00  0.00           C\\n'.format(str(atomnumb),str(resid),float(i[0]),float(i[1]),float(i[2])))\n",
    "                    resid=resid+1\n",
    "                    atomnumb=atomnumb+10\n",
    "            f.write('TER\\n')\n",
    "            f.write('ENDMDL\\n')\n",
    "            model=model+1\n",
    "        f.write('END')\n",
    "        f.close()\n",
    "\n",
    "    def plot_trajectory_rmsd(self, ax=None):\n",
    "        # Plot minimization trajectories\n",
    "        \n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "        #warning, don't know how to get fig if ax is passed to us. Do I need fig? probably not\n",
    "        plt.plot(self.rmsd, axes=ax, label=self.name())\n",
    "        ax.set_title('Minimization trajectory')\n",
    "        ax.set_xlabel('Minimization steps')\n",
    "        ax.set_ylabel('RMSD ($\\AA$)')\n",
    "        plt.legend(loc='best')\n",
    "        print(\"final rmsd: \" + str(self.rmsd[-1]))\n",
    "        return ax\n",
    "    \n",
    "    def plot_trajectory_parameter(self, parameter:str=None, ax=None):\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "        #warning, don't know how to get fig if ax is passed to us. Do I need fig? probably not\n",
    "\n",
    "        data = [timepoint[parameter] for timepoint in self.parameter_history]\n",
    "        plt.plot(data, axes=ax, label=self.name())\n",
    "        ax.set_title('Minimization trajectory for ' + parameter)\n",
    "        ax.set_xlabel('Minimization steps')\n",
    "        ax.set_ylabel('parameter value')\n",
    "        plt.legend(loc='best')\n",
    "        return ax\n",
    "    \n",
    "    def append_trajectory_parameters(self,hp:HelixParameters=None):\n",
    "        self.parameter_history.append(hp.get_dict())\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ParametricHelix():\n",
    "    def __init__(self,name:str=None,z_aligned:bool=False):\n",
    "        self.helix_parameters = HelixParameters()\n",
    "        self._name = None\n",
    "        self.name(name)\n",
    "        self.z_aligned = z_aligned\n",
    "    \n",
    "    def name(self,name:str=None):\n",
    "        if name is not None:\n",
    "            self._name = name\n",
    "        return self._name\n",
    "    \n",
    "    def is_named(self):\n",
    "        return self._name is not None\n",
    "    \n",
    "    def get_helix_parameters(self):\n",
    "        #may want to make this a deep copy? \n",
    "        return self.helix_parameters\n",
    "\n",
    "    #### FUNCTIONS ####\n",
    "\n",
    "    # Parametric helix equation based on Huang et al. equations as described in SI \n",
    "    # Contains small patch to make it compatible with BundleGridSampler mover (due to differences in origin definition)\n",
    "\n",
    "    #----------MAKE CARTESIAN COORDINATES FOR CA OF RESIDUE t---------------\n",
    "    def cartesian(self,t):\n",
    "    #def cartesian(r0, omega0, omega1, phi0, phi1, delta_z):\n",
    "        \n",
    "        # d AND r1 SHOULD NOT BE VARIED IF WANT TO RETAIN IDEAL ALPHA-HELIX\n",
    "        d = self.helix_parameters.d()\n",
    "        r1 = self.helix_parameters.r1()\n",
    "        r0 = self.helix_parameters.r0()\n",
    "        omega0 = self.helix_parameters.omega0()\n",
    "        omega1 = self.helix_parameters.omega1()\n",
    "        phi0 = self.helix_parameters.phi0()\n",
    "        phi1 = self.helix_parameters.phi1()\n",
    "        delta_z = self.helix_parameters.delta_z()\n",
    "\n",
    "        # ONLY FUNCTIONS OF OTHER PARAMETERS\n",
    "        pre_asin = np.clip((r0*omega0)/d,-1,1) #ryan added this hack\n",
    "        alpha=asin(pre_asin) # CONSTRAINED (function of other variables), pitch angle, [radians] -- BundleGridSampler=delta_omega1_peratom?\n",
    "        phi_prime0=phi0+delta_z*tan(alpha)/r0 # CONSTRAINED (function of other variables), superhelical phase decoupled from delta_z, [radians] \n",
    "\n",
    "        x=r0*cos(omega0*t+phi_prime0)+r1*cos(omega0*t+phi_prime0)*cos(omega1*t+phi1)-r1*cos(alpha)*sin(omega0*t+phi_prime0)*sin(omega1*t+phi1)\n",
    "        y=r0*sin(omega0*t+phi_prime0)+r1*sin(omega0*t+phi_prime0)*cos(omega1*t+phi1)+r1*cos(alpha)*cos(omega0*t+phi_prime0)*sin(omega1*t+phi1)\n",
    "        z=((omega0*r0)/(tan(alpha)))*t-r1*sin(alpha)*sin(omega1*t+phi1)+delta_z\n",
    "\n",
    "        return [x,y,z]\n",
    "\n",
    "\n",
    "    #---------MAKE ARRAY OF XYZ COORDINATES FOR ALL CA-----------------------\n",
    "    #residue_indices would be given like Huang's convention but 0 indexed (0 = first res). Going under the first res means negative numbers\n",
    "    def moving(self,residue_indices=None):\n",
    "        \n",
    "        if residue_indices is None:\n",
    "            # PATCH TO BRIDGE DIFFERENCES IN HOW THE 'ORIGIN' IS DEFINED\n",
    "            delta_t=int(self.helix_parameters.length()/2)# define an offset of half-helix length (in number of residues) -- BundleGridSampler=delta_t\n",
    "            # 're-number' indices +/- around middle of helix\n",
    "            # to patch Vikram's convention (start from middle of helix) and Huang's convention (start at resid 1) \n",
    "\n",
    "            \n",
    "            \n",
    "            # Correct for helices that have odd numbers of residues (otherwise fitting helix will be one residue short)\n",
    "            if (self.helix_parameters.length() % 2) == 0:\n",
    "                residue_renumber_indices=np.arange(-delta_t,+delta_t,1)\n",
    "            if (self.helix_parameters.length() % 2) != 0:\n",
    "                residue_renumber_indices=np.arange(-delta_t,+delta_t+1,1)\n",
    "\n",
    "\n",
    "            if self.helix_parameters.invert(): # change direction of helix\n",
    "                residue_renumber_indices=-1*residue_renumber_indices\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            residue_renumber_indices = residue_indices\n",
    "            print('this is almost certainly not what I wnat to do')\n",
    "        \n",
    "        moving_coordinates = np.array([self.cartesian(t) for t in residue_renumber_indices])\n",
    "\n",
    "        return moving_coordinates\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def Ca_coords_from_stored_params(self,axis=False,residue_indices=None):\n",
    "        #print(\"Ca_coords_from_stored_params\")\n",
    "        #print(\"residue_indices\")\n",
    "        #print(residue_indices)\n",
    "        move = self.moving(residue_indices)\n",
    "        #print(\"move\")\n",
    "        #print(move)\n",
    "        padded_move = np.append(move,[[1]]*move.shape[0], axis = 1)\n",
    "        transformed = self.helix_parameters.transformation_matrix().dot(padded_move.T).T\n",
    "        striped_transformed = np.delete(transformed,3,axis=1)\n",
    "        \n",
    "        \n",
    "        if axis:\n",
    "            axis = np.array([[0,0,-10],[0,0,10]])\n",
    "            padded_axis = np.append(axis,[[1]]*axis.shape[0], axis = 1)\n",
    "            transformed_axis = self.helix_parameters.transformation_matrix().dot(padded_axis.T).T\n",
    "            striped_axis = np.delete(transformed_axis,3,axis=1)\n",
    "            \n",
    "            return striped_transformed, striped_axis\n",
    "        else:\n",
    "            return striped_transformed\n",
    "    \n",
    "#-----------Objective RMSD function used during minimization---------------    \n",
    "    def rmsd_array(self,params, target, dummy):\n",
    "#         r0=params['r0']\n",
    "#         omega0=params['omega0'] \n",
    "#         omega1=params['omega1'] \n",
    "#         phi0=params['phi0']\n",
    "#         phi1=params['phi1'] \n",
    "#         delta_z=params['delta_z']\n",
    "#         invert=params['invert']\n",
    "        self.helix_parameters.from_lmfit(params)\n",
    "        \n",
    "#         move = self.moving()\n",
    "        \n",
    "#         axis = np.array([[0,0,-10],[0,0,10]])\n",
    "        \n",
    "#         #print(move)\n",
    "#         #print(move.shape)\n",
    "#         padded_move = np.append(move,[[1]]*move.shape[0], axis = 1)\n",
    "#         padded_axis = np.append(axis,[[1]]*axis.shape[0], axis = 1)\n",
    "#         #print(padded_move)\n",
    "#         #print(self.helix_parameters.transformation_matrix())\n",
    "#         transformed = self.helix_parameters.transformation_matrix().dot(padded_move.T).T\n",
    "#         transformed_axis = self.helix_parameters.transformation_matrix().dot(padded_axis.T).T\n",
    "#         #print(transformed)\n",
    "        \n",
    "#         striped_transformed = np.delete(transformed,3,axis=1)\n",
    "#         striped_axis = np.delete(transformed_axis,3,axis=1)\n",
    "#         #print(striped_transformed)\n",
    "        striped_transformed,striped_axis = self.Ca_coords_from_stored_params(axis=True)\n",
    "        \n",
    "        subtract_coord=striped_transformed-target\n",
    "\n",
    "        rmsd_array=np.sqrt(np.sum(np.power(subtract_coord,2),axis=1))\n",
    "        rmsd=np.sqrt((1/self.helix_parameters.length())*np.sum(np.sum(np.power(subtract_coord,2),axis=1)))\n",
    "        \n",
    "        self.fit.append_trajectory_rmsd(rmsd)\n",
    "        self.fit.append_trajectory_coords(striped_transformed,striped_axis)\n",
    "        self.fit.append_trajectory_parameters(self.helix_parameters)\n",
    "\n",
    "        print(f'rmsd={rmsd}')\n",
    "        \n",
    "        return rmsd_array\n",
    "    \n",
    "    \n",
    "    #meant for users to use\n",
    "    #pose is assumed to be a single helix that I want to know about\n",
    "    def fit_target_helix(self,pose, write_axis=False):\n",
    "        if(not self.z_aligned):\n",
    "    #         self.fit = ParametricFit(self.name(),write_axis=write_axis)\n",
    "\n",
    "    #         #this gets all the coordinates. I only need Calphas\n",
    "    #         #target_coords = [ [ pose.residue( r.xyz(a)) for a in range(1, pose.residue(r).natoms() + 1)] for r in range(1, pose.total_residue() + 1)]\n",
    "\n",
    "    #         target_helix = np.array([np.array(pose.residue(r).atom(\"CA\").xyz()) for r in range(1, pose.total_residue() + 1)])\n",
    "\n",
    "    #         helix_length=len(target_helix) # number of residues in the helix, [aa]\n",
    "\n",
    "    #         # not 100% sure this code will be necessary after the coordinate independence upgrade\n",
    "    #         if (target_helix[-1]-target_helix[0])[2]<0: # check helix orientation\n",
    "    #             invert=True\n",
    "    #         else:\n",
    "    #             invert=False\n",
    "\n",
    "    #         #some guesses\n",
    "    #         r0_guess=0.00001 # VARY, superhelical radius, [angstrom] -- BundleGridSampler=r0\n",
    "    #         delta_z_guess=0 # VARY, offest along the z axis, [angstrom] -- BundleGridSampler=z0_offset\n",
    "    #         phi1_guess=radians(0) # VARY, helical phase (around the internal axis of that helix), [degrees] -- BundleGridSampler=delta_omega1\n",
    "    #         #phi0_guess=radians(180) # FIXED? superhelical phase, i.e. 0, 90, 180, 270 for 4 evenly spaced helices, [degrees] -- BundleGridSampler=delta_omega0\n",
    "    #         omega0_guess=radians(-2.85) # FIXED? superhelical twist (-2.85 degrees for two layers), relates to omega1, [degrees] -- BundleGridSampler=omega0\n",
    "    #         omega1_guess=radians(+102.85) # FIXED? helical twist (+102.85 degrees for two layers), relates to omega0, [degrees] -- BundleGridSampler=omega1\n",
    "\n",
    "    #         # Generate quick estimates of phi0 to pass as better guess to avoid convergence problems and math domain errors\n",
    "    #         if np.average(target_helix,axis=0)[0] > 0 and np.average(target_helix,axis=0)[1] > 0: # quadrant I\n",
    "    #             phi0_guess=radians(degrees(atan(abs(np.average(target_helix,axis=0)[1])/abs(np.average(target_helix,axis=0)[0]))))\n",
    "    #         if np.average(target_helix,axis=0)[0] < 0 and np.average(target_helix,axis=0)[1] > 0: # quadrant II\n",
    "    #             phi0_guess=radians(180-degrees(atan(abs(np.average(target_helix,axis=0)[1])/abs(np.average(target_helix,axis=0)[0]))))\n",
    "    #         if np.average(target_helix,axis=0)[0] < 0 and np.average(target_helix,axis=0)[1] < 0: # quadrant III\n",
    "    #             phi0_guess=radians(degrees(atan(abs(np.average(target_helix,axis=0)[1])/abs(np.average(target_helix,axis=0)[0])))+180)\n",
    "    #         if np.average(target_helix,axis=0)[0] > 0 and np.average(target_helix,axis=0)[1] < 0: # quadrant IV\n",
    "    #             phi0_guess=radians(360-degrees(atan(abs(np.average(target_helix,axis=0)[1])/abs(np.average(target_helix,axis=0)[0]))))\n",
    "\n",
    "    #         phi0_guess=0\n",
    "\n",
    "    # #         #guess about transform        \n",
    "    # #         translate_x_guess = 0\n",
    "    # #         translate_y_guess = 0\n",
    "    # #         translate_z_guess = 0\n",
    "    # #         rotate_phi_guess = 0\n",
    "    # #         rotate_theta_guess = 0\n",
    "    # #         rotate_psi_guess = 0\n",
    "\n",
    "    #         #I can do better than that\n",
    "    #         helical_pseudo_axis = normalize(target_helix[-1] - target_helix[0])\n",
    "    #         helical_pseudo_origin = (target_helix[0] + target_helix[-1])/2\n",
    "    #         #print(target_helix[0],target_helix[-1],helical_pseudo_axis,helical_pseudo_origin)\n",
    "    #         exit(\"something about the pseduo_axis is bad\")\n",
    "    #         rotate_phi_guess,rotate_theta_guess,rotate_psi_guess = R_to_euler(rotation(helical_pseudo_axis,[0,0,-1]))\n",
    "    #         translate_x_guess,translate_y_guess,translate_z_guess = helical_pseudo_origin\n",
    "\n",
    "\n",
    "\n",
    "    #         #input guesses\n",
    "    #         self.helix_parameters=HelixParameters(r0_guess,omega0_guess,omega1_guess,phi0_guess,phi1_guess,delta_z_guess,invert,helix_length,translate_x_guess,translate_y_guess,translate_z_guess,rotate_phi_guess,rotate_theta_guess,rotate_psi_guess)\n",
    "\n",
    "    #         #-----GENERATE PARAMETER DICTIONARY-----------\n",
    "\n",
    "\n",
    "\n",
    "    #         params = self.helix_parameters.to_lmfit_parameters()\n",
    "\n",
    "    #         # FIT\n",
    "    #         fit=minimize(self.rmsd_array,params,method='bfgs',args=(target_helix,True),**{\"options\":{\"maxiter\":1000}}) #,**{\"ftol\":1.e-3}\n",
    "\n",
    "\n",
    "    #         #self.helix_parameters.from_lmfit(fit)\n",
    "\n",
    "    #         self.fit.parse_fit(fit)\n",
    "\n",
    "\n",
    "\n",
    "            #3 step fitting\n",
    "            #1) using a slightly supercoiled helix, fit the transform, everything else fixed\n",
    "            #2) using the fitted transform as fixed variables, fit the helical parameters\n",
    "            #3) fit everything,initialized with previous fits, to work out kinks\n",
    "\n",
    "\n",
    "            self.fit = ParametricFit(self.name(),write_axis=write_axis)\n",
    "\n",
    "            #this gets all the coordinates. I only need Calphas\n",
    "            #target_coords = [ [ pose.residue( r.xyz(a)) for a in range(1, pose.residue(r).natoms() + 1)] for r in range(1, pose.total_residue() + 1)]\n",
    "\n",
    "            target_helix = np.array([np.array(pose.residue(r).atom(\"CA\").xyz()) for r in range(1, pose.total_residue() + 1)])\n",
    "\n",
    "            helix_length=len(target_helix) # number of residues in the helix, [aa]\n",
    "\n",
    "    #         # not 100% sure this code will be necessary after the coordinate independence upgrade\n",
    "    #         if (target_helix[-1]-target_helix[0])[2]<0: # check helix orientation\n",
    "    #             invert=True\n",
    "    #         else:\n",
    "    #             invert=False\n",
    "            invert_guess=True\n",
    "\n",
    "            #some guesses\n",
    "            r0_guess=5 # VARY, superhelical radius, [angstrom] -- BundleGridSampler=r0\n",
    "            delta_z_guess=0 # VARY, offest along the z axis, [angstrom] -- BundleGridSampler=z0_offset\n",
    "            phi1_guess=radians(0) # VARY, helical phase (around the internal axis of that helix), [degrees] -- BundleGridSampler=delta_omega1\n",
    "            #phi0_guess=radians(180) # FIXED? superhelical phase, i.e. 0, 90, 180, 270 for 4 evenly spaced helices, [degrees] -- BundleGridSampler=delta_omega0\n",
    "            omega0_guess=radians(-2.85) # FIXED? superhelical twist (-2.85 degrees for two layers), relates to omega1, [degrees] -- BundleGridSampler=omega0\n",
    "            omega1_guess=radians(+102.85) # FIXED? helical twist (+102.85 degrees for two layers), relates to omega0, [degrees] -- BundleGridSampler=omega1\n",
    "\n",
    "\n",
    "            #make estimates of phi0 using a target helix aligned to z\n",
    "\n",
    "    #         # Generate quick estimates of phi0 to pass as better guess to avoid convergence problems and math domain errors\n",
    "    #         if np.average(target_helix,axis=0)[0] > 0 and np.average(target_helix,axis=0)[1] > 0: # quadrant I\n",
    "    #             phi0_guess=radians(degrees(atan(abs(np.average(target_helix,axis=0)[1])/abs(np.average(target_helix,axis=0)[0]))))\n",
    "    #         if np.average(target_helix,axis=0)[0] < 0 and np.average(target_helix,axis=0)[1] > 0: # quadrant II\n",
    "    #             phi0_guess=radians(180-degrees(atan(abs(np.average(target_helix,axis=0)[1])/abs(np.average(target_helix,axis=0)[0]))))\n",
    "    #         if np.average(target_helix,axis=0)[0] < 0 and np.average(target_helix,axis=0)[1] < 0: # quadrant III\n",
    "    #             phi0_guess=radians(degrees(atan(abs(np.average(target_helix,axis=0)[1])/abs(np.average(target_helix,axis=0)[0])))+180)\n",
    "    #         if np.average(target_helix,axis=0)[0] > 0 and np.average(target_helix,axis=0)[1] < 0: # quadrant IV\n",
    "    #             phi0_guess=radians(360-degrees(atan(abs(np.average(target_helix,axis=0)[1])/abs(np.average(target_helix,axis=0)[0]))))\n",
    "\n",
    "            phi0_guess=0#radians(90)\n",
    "\n",
    "            #guess about transform        \n",
    "    #         translate_x_guess = 0\n",
    "    #         translate_y_guess = 0\n",
    "    #         translate_z_guess = 0\n",
    "    #         rotate_phi_guess = 0\n",
    "    #         rotate_theta_guess = 0\n",
    "    #         rotate_psi_guess = 0\n",
    "\n",
    "    #         #I can do better than that\n",
    "            helical_pseudo_axis = normalize(target_helix[-1] - target_helix[0])\n",
    "            helical_pseudo_origin = (target_helix[0] + target_helix[-1])/2\n",
    "            #print(target_helix[0],target_helix[-1],helical_pseudo_axis,helical_pseudo_origin)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            rotate_phi_guess,rotate_theta_guess,rotate_psi_guess = R_to_euler(rotation([0,0,-1],helical_pseudo_axis))\n",
    "            translate_x_guess,translate_y_guess,translate_z_guess = helical_pseudo_origin\n",
    "\n",
    "\n",
    "            #According to Basile and Nick, the transformation I use is actually degenerate over 180deg so it won't correclty account for fully inverted helices\n",
    "            #to fix this, I present the following hack\n",
    "            orig_hp = HelixParameters(r0_guess,omega0_guess,omega1_guess,phi0_guess,phi1_guess,delta_z_guess,invert_guess,helix_length,False,translate_x_guess,translate_y_guess,translate_z_guess,rotate_phi_guess,rotate_theta_guess,rotate_psi_guess)\n",
    "            self.helix_parameters=orig_hp\n",
    "    #         orig_init_helix = Ca_coords_from_stored_params()\n",
    "    #         orig_subtract_coord=orig_init_helix-target\n",
    "    #         original_rmsd=np.sqrt((1/self.helix_parameters.length())*np.sum(np.sum(np.power(orig_subtract_coord,2),axis=1)))\n",
    "\n",
    "    #         invert_hp = orig_hp = HelixParameters(r0_guess,omega0_guess,omega1_guess,phi0_guess,phi1_guess,delta_z_guess,invert_guess,helix_length,translate_x_guess,translate_y_guess,translate_z_guess,rotate_phi_guess,rotate_theta_guess,rotate_psi_guess)\n",
    "    #         #wait, let's just try this\n",
    "\n",
    "            #input guesses\n",
    "\n",
    "\n",
    "            # FIT\n",
    "            print(\"BEGIN ROUND 1\")\n",
    "            params = self.helix_parameters.to_lmfit_parameters(round_num=1)\n",
    "            #fit=minimize(self.rmsd_array,params,method='leastsq',args=(target_helix,True),**{\"ftol\":1e-9}) #\"maxiter\":1000 #,**{\"ftol\":1.e-3}\n",
    "            fit=minimize(self.rmsd_array,params,method='leastsq',args=(target_helix,True),**{\"ftol\":1.0e-3}) #\"maxiter\":1000 #,**{\"ftol\":1.e-3}\n",
    "            self.helix_parameters.from_lmfit(fit.params)#retrieve last fit #not necessary I think\n",
    "\n",
    "            print(\"BEGIN ROUND 2\")\n",
    "            params = self.helix_parameters.to_lmfit_parameters(round_num=2)\n",
    "            fit=minimize(self.rmsd_array,params,method='leastsq',args=(target_helix,True),**{'ftol':1.0e-3})#,**{\"options\":{\"maxiter\":1000}}) #,**{\"ftol\":1.e-3}\n",
    "            self.helix_parameters.from_lmfit(fit.params)#retrieve last fit #not necessary I think\n",
    "\n",
    "            print(\"BEGIN ROUND 3\")\n",
    "            params = self.helix_parameters.to_lmfit_parameters(round_num=3)\n",
    "            fit=minimize(self.rmsd_array,params,method='leastsq',args=(target_helix,True),**{\"ftol\":1.0e-4})\n",
    "            self.helix_parameters.from_lmfit(fit.params)#retrieve last fit #not necessary I think\n",
    "\n",
    "\n",
    "\n",
    "    #         #standard protocol\n",
    "    #         params = self.helix_parameters.to_lmfit_parameters(round_num=None)\n",
    "    # #        fit=minimize(self.rmsd_array,params,method='leastsq',args=(target_helix,True),**{\"ftol\":1e-3}) #\"maxiter\":1000 #,**{\"ftol\":1.e-3}\n",
    "    #         fit=minimize(self.rmsd_array,params,method='bfgs',args=(target_helix,True),**{\"options\":{}}) #\"maxiter\":1000 #,**{\"ftol\":1.e-3}\n",
    "    #         self.helix_parameters.from_lmfit(fit.params)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            self.fit.parse_fit(fit)\n",
    "\n",
    "\n",
    "\n",
    "            return self.fit\n",
    "        \n",
    "        \n",
    "        else:\n",
    "\n",
    "            self.fit = ParametricFit(self.name(),write_axis=write_axis)\n",
    "\n",
    "            #this gets all the coordinates. I only need Calphas\n",
    "            target_helix = np.array([np.array(pose.residue(r).atom(\"CA\").xyz()) for r in range(1, pose.total_residue() + 1)])\n",
    "\n",
    "            helix_length=len(target_helix) # number of residues in the helix, [aa]\n",
    "\n",
    "            if (target_helix[-1]-target_helix[0])[2]<0: # check helix orientation\n",
    "                invert_guess=True\n",
    "            else:\n",
    "                invert_guess=False\n",
    "\n",
    "            #some guesses\n",
    "            r0_guess=5 # VARY, superhelical radius, [angstrom] -- BundleGridSampler=r0\n",
    "            delta_z_guess=0 # VARY, offest along the z axis, [angstrom] -- BundleGridSampler=z0_offset\n",
    "            phi1_guess=radians(0) # VARY, helical phase (around the internal axis of that helix), [degrees] -- BundleGridSampler=delta_omega1\n",
    "            phi0_guess=radians(180) # FIXED? superhelical phase, i.e. 0, 90, 180, 270 for 4 evenly spaced helices, [degrees] -- BundleGridSampler=delta_omega0\n",
    "            omega0_guess=radians(-2.85) # FIXED? superhelical twist (-2.85 degrees for two layers), relates to omega1, [degrees] -- BundleGridSampler=omega0\n",
    "            omega1_guess=radians(+102.85) # FIXED? helical twist (+102.85 degrees for two layers), relates to omega0, [degrees] -- BundleGridSampler=omega1\n",
    "\n",
    "\n",
    "            #make estimates of phi0 using a target helix aligned to z\n",
    "\n",
    "            # Generate quick estimates of phi0 to pass as better guess to avoid convergence problems and math domain errors\n",
    "            if np.average(target_helix,axis=0)[0] > 0 and np.average(target_helix,axis=0)[1] > 0: # quadrant I\n",
    "                phi0_guess=radians(degrees(atan(abs(np.average(target_helix,axis=0)[1])/abs(np.average(target_helix,axis=0)[0]))))\n",
    "            if np.average(target_helix,axis=0)[0] < 0 and np.average(target_helix,axis=0)[1] > 0: # quadrant II\n",
    "                phi0_guess=radians(180-degrees(atan(abs(np.average(target_helix,axis=0)[1])/abs(np.average(target_helix,axis=0)[0]))))\n",
    "            if np.average(target_helix,axis=0)[0] < 0 and np.average(target_helix,axis=0)[1] < 0: # quadrant III\n",
    "                phi0_guess=radians(degrees(atan(abs(np.average(target_helix,axis=0)[1])/abs(np.average(target_helix,axis=0)[0])))+180)\n",
    "            if np.average(target_helix,axis=0)[0] > 0 and np.average(target_helix,axis=0)[1] < 0: # quadrant IV\n",
    "                phi0_guess=radians(360-degrees(atan(abs(np.average(target_helix,axis=0)[1])/abs(np.average(target_helix,axis=0)[0]))))\n",
    "\n",
    "\n",
    "\n",
    "       \n",
    "            orig_hp = HelixParameters(r0_guess,omega0_guess,omega1_guess,phi0_guess,phi1_guess,delta_z_guess,invert_guess,helix_length,True)\n",
    "            self.helix_parameters=orig_hp\n",
    "\n",
    "\n",
    "            params = self.helix_parameters.to_lmfit_parameters()\n",
    "#            fit=minimize(self.rmsd_array,params,method='leastsq',args=(target_helix,True),**{\"ftol\":1e-3}) #\"maxiter\":1000 #,**{\"ftol\":1.e-3}\n",
    "            fit=minimize(self.rmsd_array,params,method='leastsq',args=(target_helix,True),**{\"ftol\":1e-3}) #\"maxiter\":1000 #,**{\"ftol\":1.e-3}\n",
    "            self.helix_parameters.from_lmfit(fit.params)\n",
    "            self.fit.parse_fit(fit)\n",
    "            return self.fit\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "    #assume it has ss\n",
    "    def find_helices_in_chain(self,input_pose,chain,min_len=3):\n",
    "        pyrosetta.rosetta.core.scoring.dssp.Dssp(pose).insert_ss_into_pose(pose, True) #for some reason the ss wasn't being stored? \n",
    "        #print(f\"chain = {chain}\")\n",
    "        chain_helix_resis=[]\n",
    "        current_helix_resis=[]\n",
    "\n",
    "        for res_num in pyrosetta.rosetta.core.pose.get_resnums_for_chain_id(pose,chain):\n",
    "            res_ss = pose.secstruct(res_num)\n",
    "            if res_ss == 'H':\n",
    "                current_helix_resis.append(res_num)\n",
    "            else:\n",
    "                if len(current_helix_resis) >= min_len:\n",
    "                    chain_helix_resis.append(current_helix_resis)\n",
    "                current_helix_resis = []\n",
    "        if len(current_helix_resis) >= min_len:\n",
    "            chain_helix_resis.append(current_helix_resis)\n",
    "        return chain_helix_resis\n",
    "    \n",
    "    def extract_helix(self,input_pose,helix_number,min_len=3,extract_end:str=None,extract_range:int=None):\n",
    "        #print(helix_number)\n",
    "        pose = pyrosetta.Pose()\n",
    "        pose.assign(input_pose)\n",
    "        pyrosetta.rosetta.core.scoring.dssp.Dssp(pose).insert_ss_into_pose(pose, True)\n",
    "        all_helix_resis=[]\n",
    "        for chain in pyrosetta.rosetta.core.pose.get_chains(pose):\n",
    "            chain_helix_resis=self.find_helices_in_chain(pose,chain,min_len)\n",
    "            all_helix_resis.extend(chain_helix_resis)\n",
    "        #print(all_helix_resis)\n",
    "        #rint(len(all_helix_resis))\n",
    "        target_helix_resis = all_helix_resis[helix_number]\n",
    "\n",
    "        \n",
    "        if extract_range is not None:\n",
    "            assert(extract_range >= 4) #if it's less than 11/3 I think we can't fit it \n",
    "            assert(extract_end is not None)\n",
    "            if extract_end.lower() == \"n\":\n",
    "                target_helix_resi_start = target_helix_resis[0]\n",
    "                target_helix_resis_end = target_helix_resis[extract_range]\n",
    "            elif extract_end.lower() == \"c\":\n",
    "                target_helix_resi_start = target_helix_resis[-extract_range]\n",
    "                target_helix_resis_end = target_helix_resis[-1]\n",
    "        else:\n",
    "            target_helix_resi_start = target_helix_resis[0]\n",
    "            target_helix_resis_end = target_helix_resis[-1]\n",
    "        \n",
    "        krm = pyrosetta.rosetta.protocols.grafting.simple_movers.KeepRegionMover()\n",
    "        krm.region(str(target_helix_resi_start),str(target_helix_resis_end))\n",
    "        pose.dump_pdb(\"00_before.pdb\")\n",
    "        krm.apply(pose)\n",
    "        pose.dump_pdb(f\"01_isolated_helix_{helix_number}.pdb\")\n",
    "        return pose\n",
    "    \n",
    "    # Define 'stub' (from 3 atoms) - necessary for computing the transformation matrix that matches the structures \n",
    "    def stub(self,b,a,c): # a,b,c are the vectors of a, b, c with respect to the general coordinate frame\n",
    "        e1=(a-b)/np.linalg.norm(a-b)\n",
    "        e3=np.cross(e1,(c-b))/np.linalg.norm(np.cross(e1,(c-b)))\n",
    "        e2=np.cross(e1,e3)/np.linalg.norm(np.cross(e1,e3))\n",
    "        partial_matrix = np.array([e1,e2,e3,b]).T\n",
    "        extra_line=np.array([[0,0,0,1]])\n",
    "        stub_matrix=np.append(partial_matrix,extra_line,axis=0)\n",
    "        return stub_matrix\n",
    "\n",
    "    def pdb_str_from_Ca(self,Ca_coordinates):\n",
    "            # Generate 'ideal' stub \n",
    "        stub_file=map(str.split,open('/home/bwicky/Design/add_buttressing_helix_to_zcon/ideal.pdb','r').readlines())\n",
    "\n",
    "        atom=[]\n",
    "        for line in stub_file:\n",
    "            atom.append(np.array([float(line[6]),float(line[7]),float(line[8])]))\n",
    "\n",
    "        ideal_stub=self.stub(atom[6],atom[1],atom[11]) # generate ideal stub from CA coordinates\n",
    "\n",
    "        pdb_str = \"\"\n",
    "        # Generate and write bb of generated helix based on its CA trace\n",
    "        atom_num=1\n",
    "        res_num=0 \n",
    "        chain='A'\n",
    "        CA_chain=Ca_coordinates[:,0:3]\n",
    "        for res in range(1,len(CA_chain)-1):\n",
    "\n",
    "            res_num=res_num+1\n",
    "            actual_stub=self.stub(CA_chain[res],CA_chain[res-1],CA_chain[res+1]) # stub based on CA trace\n",
    "            transform=np.matmul(actual_stub,np.linalg.inv(ideal_stub)) # find transformation matrix between ideal and actual stub\n",
    "\n",
    "            # N\n",
    "            coords=np.matmul(transform,np.append(atom[5],1))\n",
    "            pdb_str += 'ATOM %6d  N   ALA %s %3d    %8.3f%8.3f%8.3f  1.00  0.00           N\\n'%(atom_num,chain,res_num,coords[0],coords[1],coords[2])\n",
    "            atom_num=atom_num+1\n",
    "\n",
    "            # CA (use actual CA from trace rather than superimposed one)\n",
    "            coords=CA_chain[res]\n",
    "            # If want to use CA from ideal stub instead of actual CA\n",
    "            # coords=np.matmul(transform,np.append(atom[6],1)) \n",
    "            pdb_str += 'ATOM %6d  CA  ALA %s %3d    %8.3f%8.3f%8.3f  1.00  0.00           C\\n'%(atom_num,chain,res_num,coords[0],coords[1],coords[2])\n",
    "            atom_num=atom_num+1\n",
    "\n",
    "            # (N)H\n",
    "            coords=np.matmul(transform,np.append(atom[7],1))\n",
    "            pdb_str += 'ATOM %6d  H   ALA %s %3d    %8.3f%8.3f%8.3f  1.00  0.00           H\\n'%(atom_num,chain,res_num,coords[0],coords[1],coords[2])\n",
    "            atom_num=atom_num+1\n",
    "\n",
    "            # C(O)\n",
    "            coords=np.dot(transform,np.append(atom[8],1))\n",
    "            pdb_str += 'ATOM %6d  C   ALA %s %3d    %8.3f%8.3f%8.3f  1.00  0.00           C\\n'%(atom_num,chain,res_num,coords[0],coords[1],coords[2])\n",
    "            atom_num=atom_num+1\n",
    "\n",
    "            # O\n",
    "            coords=np.dot(transform,np.append(atom[9],1))\n",
    "            pdb_str += 'ATOM %6d  O   ALA %s %3d    %8.3f%8.3f%8.3f  1.00  0.00           O\\n'%(atom_num,chain,res_num,coords[0],coords[1],coords[2])\n",
    "            atom_num=atom_num+1\n",
    "\n",
    "        pdb_str += 'END'\n",
    "        return pdb_str\n",
    "    \n",
    "    def pdb_str(self):\n",
    "        return self.pdb_str_from_Ca(self.Ca_coords_from_stored_params())\n",
    "    \n",
    "    # Function that takes CA coordinates as input and return ideal helix backbone in a pose\n",
    "    def pose_from_Ca(self,Ca_coordinates):\n",
    "        pdb_str = self.pdb_str_from_Ca(Ca_coordinates)\n",
    "        pose = pyrosetta.Pose()\n",
    "        pyrosetta.rosetta.core.import_pose.pose_from_pdbstring(pose, pdb_str)\n",
    "        return pose\n",
    "    \n",
    "    def pose(self):\n",
    "        return self.pose_from_Ca(self.Ca_coords_from_stored_params())\n",
    "    \n",
    "    def set_helix_parameters(self,params:HelixParameters):\n",
    "        self.helix_parameters = params\n",
    "\n",
    "    #build range assumes the middle of the helix is residue 0 or -1(?). pos = N, neg = C\n",
    "    #Sure, I could make this elegant. But will I? Nah\n",
    "    def build_helix(self, start:int,stop:int): \n",
    "        return self.pose_from_Ca(self.Ca_coords_from_stored_params(residue_indices=np.arange(start,stop,1)))\n",
    "    \n",
    "    def terminal_helix_number(self,pose,target_chain,direction):\n",
    "        pyrosetta.rosetta.core.scoring.dssp.Dssp(pose).insert_ss_into_pose(pose, True)\n",
    "        all_helix_resis=[]\n",
    "        for chain in pyrosetta.rosetta.core.pose.get_chains(pose):\n",
    "            chain_helix_resis=self.find_helices_in_chain(pose,chain)\n",
    "            all_helix_resis.extend(chain_helix_resis)\n",
    "            print(all_helix_resis)\n",
    "            if chain == pyrosetta.rosetta.core.pose.get_chain_id_from_chain(target_chain,pose):\n",
    "                if direction.lower() =='c':\n",
    "                    return len(all_helix_resis)\n",
    "                else:\n",
    "                    return len(all_helix_resis) - len(chain_helix_resis)\n",
    "        #something went wrong!\n",
    "        print(f\"target_chain {target_chain} not found!\")\n",
    "        return -1\n",
    "    \n",
    "    #this really only supports extending terminal helices. I don't want to have to \n",
    "    #consider the case of extending an internal helix. Therefore this mover will be fixed to \n",
    "    #extending terminal helices. This lets me assume that I can delete everything at the terminus\n",
    "    def extend_terminal_helix(self,pose,chain,direction,num_extend,num_fit=None):\n",
    "        print(f\"I have chain={chain},direction={direction},num_extend={num_extend},and num_fit={num_fit}\")\n",
    "        helix_number = self.terminal_helix_number(pose,chain,direction)\n",
    "        print(f\"helix chosen: {helix_number}\")\n",
    "        target_helix = self.extract_helix(pose,helix_number,extract_end=direction,extract_range=num_fit)\n",
    "        fit = self.fit_target_helix(target_helix)\n",
    "        original_length = len(target_helix)\n",
    "\n",
    "        #make the helix a little longer so I can have some wiggle room for making the fusion\n",
    "        if direction.lower() == \"c\":\n",
    "            #I don't think the length matters?\n",
    "            adj_stop = (-original_length/2) + 6 \n",
    "            adj_start = (-original_length/2) - num_extend\n",
    "\n",
    "            \n",
    "        elif direction.lower() == 'n':\n",
    "            if original_length % 2 == 0: #even\n",
    "                adj_stop = (original_length / 2) + num_extend\n",
    "                adj_start = (original_length / 2) - 6\n",
    "            else:#odd\n",
    "                adj_stop = (original_length / 2) + 1 + num_extend\n",
    "                adj_start = (original_length / 2) + 1 - 6\n",
    "        else:\n",
    "            exit(f\"{direction} isn't a valid direction. Use 'N' or 'C'\")\n",
    "            \n",
    "        print(\"building residue indices\")\n",
    "        print(adj_start,adj_stop)    \n",
    "        residue_indices = np.arange(adj_start,adj_stop,1)\n",
    "        print(residue_indices)\n",
    "        Ca_helix_extension = self.Ca_coords_from_stored_params(residue_indices=residue_indices)\n",
    "        pdb_str = self.pdb_str_from_Ca(Ca_helix_extension)\n",
    "        temp_pdb = tempfile.NamedTemporaryFile(delete=False,dir=\"/net/scratch/rdkibler/\",suffix=\".pdb\")\n",
    "        temp_pdb.write(pdb_str.encode())\n",
    "        temp_pdb.close() #tempfile not immediately deleted       \n",
    "        \n",
    "        \n",
    "        \n",
    "        print(temp_pdb.name)\n",
    "        !cat {temp_pdb.name}\n",
    "#         try:\n",
    "#             pyrosetta.rosetta.protocols.rosetta_scripts.XmlObjects.create_from_string(f\"\"\"\n",
    "#                 <SCOREFXNS>\n",
    "#                     <ScoreFunction name=\"sfxn_asym\" weights=\"beta_nov16\" symmetric=\"0\" />\n",
    "#                 </SCOREFXNS>\n",
    "#                 <RESIDUE_SELECTORS>\n",
    "#                 <True name=\"all\" />\n",
    "#                 </RESIDUE_SELECTORS>\n",
    "#                 <MOVERS>\n",
    "#                     <AddResidueLabel name=\"no_des\" residue_selector=\"all\" label=\"all\" />\n",
    "#                     <MergePDB name=\"mergePDB\"\n",
    "#                         attachment_termini=\"{direction.lower()}_term\"\n",
    "#                         chain=\"{chain}\"\n",
    "#                         overlap_length=\"4\" \n",
    "#                         overlap_rmsd=\"0.5\"\n",
    "#                         attach_pdb=\"{temp_pdb.name}\"\n",
    "#                         design_range=\"0\" \n",
    "#                         packing_range=\"0\"\n",
    "#                         overlap_scan_range_cmdLine_pose=\"4\"\n",
    "#                         overlap_scan_range_xml_pose=\"4\"\n",
    "#                         scorefxn=\"sfxn_asym\" \n",
    "#                         no_design_label=\"all\"\n",
    "#                         init_overlap_sequence=\"input_pose\"\n",
    "#                         output_only_first=\"true\" /> \n",
    "#                     <ParsedProtocol name=\"merge\">\n",
    "#                         <Add mover=\"no_des\"/>\n",
    "#                         <Add mover=\"mergePDB\"/>\n",
    "#                     </ParsedProtocol>\n",
    "#                 </MOVERS>\n",
    "#                 \"\"\").get_mover(\"merge\").apply(pose)\n",
    "#         finally:\n",
    "#             #try not to create clutter\n",
    "#             os.remove(temp_pdb.name)#now let's delete it ourselves\n",
    "        os.remove(temp_pdb.name)\n",
    "    \n",
    "        return pose\n",
    "        \n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_filename = \"/home/rdkibler/projects/tiara_gen2/crowns/06_parametric_extension/1NNone.pdb\"\n",
    "#test_filename = \"/home/rdkibler/projects/learn_interaction/models/dimer/ZCON_37.pdb\"\n",
    "#test_filename = \"/home/rdkibler/projects/learn_interaction/threading/zcon_37_off_axis.pdb\"\n",
    "#test_filename = \"/home/langar2/shared/LOCKR_base_designs/LOCKRa.pdb\"\n",
    "test_filename = \"/home/rdkibler/projects/tiara_gen2/toroids/02_3_churro-9x_parametric/01_fit_helix/input/churro_9x25GB28GB_2_works.pdb\"\n",
    "pose = pyrosetta.pose_from_pdb(test_filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting 7\n",
      "rmsd=18.12684220235292\n",
      "rmsd=18.12684220235292\n",
      "rmsd=18.12684220235292\n",
      "rmsd=18.126842042347082\n",
      "rmsd=18.126842198123075\n",
      "rmsd=18.12684216807901\n",
      "rmsd=18.126842196324464\n",
      "rmsd=18.126842199145884\n",
      "rmsd=18.126842204427785\n",
      "rmsd=38.31018145779641\n",
      "rmsd=17.30312533052485\n",
      "rmsd=17.303125253507996\n",
      "rmsd=17.303125332038203\n",
      "rmsd=17.303125314755622\n",
      "rmsd=17.303125339365675\n",
      "rmsd=17.30312533000739\n",
      "rmsd=17.303125206537\n",
      "rmsd=13.57404078095165\n",
      "rmsd=13.57404071462609\n",
      "rmsd=13.574040782296755\n",
      "rmsd=13.574040772655282\n",
      "rmsd=13.574040842744422\n",
      "rmsd=13.574040779595185\n",
      "rmsd=13.574040681421549\n",
      "rmsd=6.4606278959326975\n",
      "rmsd=6.4606278826247525\n",
      "rmsd=6.4606279296623965\n",
      "rmsd=6.460627886309231\n",
      "rmsd=6.4606277758569135\n",
      "rmsd=6.460627887288456\n",
      "rmsd=6.460627876509533\n",
      "rmsd=14.046693854326968\n",
      "rmsd=4.081024790784785\n",
      "rmsd=4.081024789770514\n",
      "rmsd=4.0810247941166375\n",
      "rmsd=4.081024848989632\n",
      "rmsd=4.081024785302526\n",
      "rmsd=4.081024773909974\n",
      "rmsd=4.081024754860847\n",
      "rmsd=3.640588410466404\n",
      "rmsd=3.640588416703841\n",
      "rmsd=3.64058846926052\n",
      "rmsd=3.6405883134006585\n",
      "rmsd=3.6405882341701568\n",
      "rmsd=3.6405884357498404\n",
      "rmsd=3.640588405866369\n",
      "rmsd=1.6814259811715426\n",
      "rmsd=1.681425977126067\n",
      "rmsd=1.6814260091761184\n",
      "rmsd=1.681425842025783\n",
      "rmsd=1.6814260518134334\n",
      "rmsd=1.6814260130743879\n",
      "rmsd=1.6814259495405293\n",
      "rmsd=1.0058111608704539\n",
      "rmsd=1.005811155836182\n",
      "rmsd=1.0058111637516756\n",
      "rmsd=1.0058113316791106\n",
      "rmsd=1.0058110587227564\n",
      "rmsd=1.0058111518956756\n",
      "rmsd=1.005811174588306\n",
      "rmsd=1.2775302795358332\n",
      "rmsd=1.2775302795358332\n",
      "rmsd=0.8761821539404064\n",
      "rmsd=0.8761821527718807\n",
      "rmsd=0.8761821313040852\n",
      "rmsd=0.876182197980261\n",
      "rmsd=0.8761822629366202\n",
      "rmsd=0.8761821544653122\n",
      "rmsd=0.8761821482216101\n",
      "rmsd=0.9290974549991012\n",
      "rmsd=0.8378602249972363\n",
      "rmsd=0.8378602233942996\n",
      "rmsd=0.8378602206740456\n",
      "rmsd=0.8378602466685229\n",
      "rmsd=0.8378602194433643\n",
      "rmsd=0.8378602237507291\n",
      "rmsd=0.8378602281649362\n",
      "rmsd=0.837775649911315\n",
      "rmsd=0.8377756496205757\n",
      "rmsd=0.8377756557407201\n",
      "rmsd=0.8377756451915378\n",
      "rmsd=0.8377756806628469\n",
      "rmsd=0.8377756495351851\n",
      "rmsd=0.837775645942258\n",
      "rmsd=0.8324053968645293\n",
      "rmsd=0.8324053966207922\n",
      "rmsd=0.8324054005533854\n",
      "rmsd=0.8324053935289644\n",
      "rmsd=0.8324053811566334\n",
      "rmsd=0.8324053968763473\n",
      "rmsd=0.8324053978376472\n",
      "rmsd=0.8362729647259096\n",
      "rmsd=0.8316204730779295\n",
      "rmsd=0.8316204730381451\n",
      "rmsd=0.8316204735022852\n",
      "rmsd=0.8316204707180014\n",
      "rmsd=0.8316204746512457\n",
      "rmsd=0.83162047322107\n",
      "rmsd=0.8316204726750881\n",
      "rmsd=0.8318014462007529\n",
      "rmsd=0.8316204730779295\n",
      "this is almost certainly not what I wnat to do\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rdkibler/.conda/envs/pyro/lib/python3.7/site-packages/ipykernel_launcher.py:429: UserWarning: PARSE_FIT NOT IMPLEMENTED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final rmsd: 0.8316204730779295\n",
      "<__main__.ParametricFit object at 0x7fffafdfac50>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###FIT HELIX 7\n",
    "\n",
    "target_helix_index = 7\n",
    "\n",
    "   \n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "pyrosetta.rosetta.core.scoring.dssp.Dssp(pose).insert_ss_into_pose(pose, True)\n",
    "all_helix_resis=[]\n",
    "for chain in pyrosetta.rosetta.core.pose.get_chains(pose):\n",
    "    current_helix_resis=[]\n",
    "\n",
    "    for res_num in pyrosetta.rosetta.core.pose.get_resnums_for_chain_id(pose,chain):\n",
    "        res_ss = pose.secstruct(res_num)\n",
    "        if res_ss == 'H':\n",
    "            current_helix_resis.append(res_num)\n",
    "        else:\n",
    "            if len(current_helix_resis) >= 3:\n",
    "                all_helix_resis.append(current_helix_resis)\n",
    "            current_helix_resis = []\n",
    "    if len(current_helix_resis) >= 3:\n",
    "        all_helix_resis.append(current_helix_resis)\n",
    "num_helices = len(all_helix_resis)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"fitting {target_helix_index}\")\n",
    "ph = ParametricHelix(f'fit {target_helix_index}',True)\n",
    "single_helix_pose = ph.extract_helix(pose,target_helix_index)\n",
    "\n",
    "fit = ph.fit_target_helix(single_helix_pose, write_axis=True)\n",
    "ph.build_helix(-14,16).dump_pdb(f\"{target_helix_index}.pdb\")\n",
    "ax = fit.plot_trajectory_rmsd(ax)\n",
    "\n",
    "#ax = fit.plot_trajectory_parameter('r0',ax)\n",
    "\n",
    "fit.write_trajectory_movie(f\"movie_{target_helix_index}.pdb\")\n",
    "\n",
    "print(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.write_trajectory_movie(\"churro_outer.pdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Fit Statistics</h2><table><tr><td>fitting method</td><td>leastsq</td><td></td></tr><tr><td># function evals</td><td>98</td><td></td></tr><tr><td># data points</td><td>28</td><td></td></tr><tr><td># variables</td><td>6</td><td></td></tr><tr><td>chi-square</td><td> 19.3645931</td><td></td></tr><tr><td>reduced chi-square</td><td> 0.88020878</td><td></td></tr><tr><td>Akaike info crit.</td><td> 1.67477015</td><td></td></tr><tr><td>Bayesian info crit.</td><td> 9.66799721</td><td></td></tr></table><h2>Variables</h2><table><tr><th> name </th><th> value </th><th> standard error </th><th> relative error </th><th> initial value </th><th> min </th><th> max </th><th> vary </th></tr><tr><td> r0 </td><td>  22.2915548 </td><td>  0.23011103 </td><td> 1.03% </td><td> 5 </td><td>  1.0000e-06 </td><td>  40.0000000 </td><td> True </td></tr><tr><td> omega0 </td><td> -0.03893640 </td><td>  0.00443299 </td><td> -11.39% </td><td> -0.04974188368183839 </td><td>        -inf </td><td>         inf </td><td> True </td></tr><tr><td> omega1 </td><td>  1.75017638 </td><td>  0.01653792 </td><td> 0.94% </td><td> 1.795071135676168 </td><td>        -inf </td><td>         inf </td><td> True </td></tr><tr><td> phi0 </td><td>  0.76463932 </td><td>  0.04413960 </td><td> 5.77% </td><td> 0.820295783654913 </td><td>  0.00000000 </td><td>         inf </td><td> True </td></tr><tr><td> phi1 </td><td>  2.26751118 </td><td>  0.14231646 </td><td> 6.28% </td><td> 0.0 </td><td>        -inf </td><td>         inf </td><td> True </td></tr><tr><td> delta_z </td><td> -2.21234161 </td><td>  0.48425401 </td><td> -21.89% </td><td> 0 </td><td>        -inf </td><td>         inf </td><td> True </td></tr><tr><td> invert </td><td>  1.00000000 </td><td>  0.00000000 </td><td> 0.00% </td><td> True </td><td>        -inf </td><td>         inf </td><td> False </td></tr></table><h2>Correlations (unreported correlations are < 0.100)</h2><table><tr><td>omega0</td><td>phi0</td><td>0.5868</td></tr><tr><td>phi0</td><td>delta_z</td><td>0.5480</td></tr><tr><td>omega0</td><td>omega1</td><td>-0.4584</td></tr><tr><td>r0</td><td>omega0</td><td>0.4340</td></tr><tr><td>phi0</td><td>phi1</td><td>-0.4139</td></tr><tr><td>r0</td><td>phi0</td><td>0.3453</td></tr><tr><td>omega1</td><td>phi0</td><td>-0.2934</td></tr><tr><td>omega0</td><td>phi1</td><td>-0.2794</td></tr><tr><td>r0</td><td>omega1</td><td>-0.1941</td></tr><tr><td>omega1</td><td>phi1</td><td>0.1910</td></tr></table>"
      ],
      "text/plain": [
       "<lmfit.minimizer.MinimizerResult at 0x7fffafe064a8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's make the context structure\n",
    "xml_obj = pyrosetta.rosetta.protocols.rosetta_scripts.XmlObjects.create_from_string(\"\"\"\n",
    "<RESIDUE_SELECTORS>\n",
    "   <SSElement name=\"helix7\" \n",
    "       selection=\"7,L\" \n",
    "       to_selection=\"8,L\" \n",
    "       chain=\"A\" />\n",
    "</RESIDUE_SELECTORS>\n",
    "\n",
    "<MOVERS>\n",
    "   <DeleteRegionMover name=\"delete\" residue_selector=\"helix7\"/>\n",
    "</MOVERS>\n",
    "\"\"\")\n",
    "delete_helix_7 = xml_obj.get_mover(\"delete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_pose = pyrosetta.Pose()\n",
    "context_pose.detached_copy(pose)\n",
    "\n",
    "delete_helix_7.apply(context_pose)\n",
    "context_pose.dump_pdb(\"check.pdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make valine!\n",
    "def make_poly_x(pose,x):\n",
    "    stm = pyrosetta.rosetta.protocols.simple_moves.SimpleThreadingMover()\n",
    "    stm.set_sequence(x*len(pose.residues),1)\n",
    "    stm.apply(pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_poly_x(context_pose,\"V\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_pose.dump_pdb(\"check2.pdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = copy.deepcopy(ph.get_helix_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_todo! 12100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rdkibler/.conda/envs/pyro/lib/python3.7/site-packages/ipykernel_launcher.py:52: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eb626ef84834ac7a76d3d0ee4100ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12100.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#now let's sample around this fit! \n",
    "import tqdm\n",
    "\n",
    "do_run = True\n",
    "\n",
    "num_r0 = 10\n",
    "r0_range = 3\n",
    "r0_start = fp.r0() - r0_range\n",
    "r0_stop = fp.r0() + r0_range\n",
    "r0_step = r0_range * 2 / num_r0\n",
    "\n",
    "num_delta_z = 10\n",
    "delta_z_range = 5\n",
    "delta_z_start = fp.delta_z() - delta_z_range\n",
    "delta_z_stop = fp.delta_z() + delta_z_range\n",
    "delta_z_step = delta_z_range * 2 / num_delta_z\n",
    "\n",
    "num_omega = 10\n",
    "omega0_range = radians(1)\n",
    "omega0_start = fp.omega0() - omega0_range\n",
    "omega0_stop = fp.omega0() + omega0_range\n",
    "omega0_step = omega0_range * 2 / num_omega\n",
    "\n",
    "num_phi0 = 10\n",
    "phi0_range = radians(20)\n",
    "phi0_start = fp.phi0() - phi0_range\n",
    "phi0_stop = fp.phi0() + phi0_range\n",
    "phi0_step = phi0_range * 2 / num_phi0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scorefxn = pyrosetta.ScoreFunction() \n",
    "scorefxn.set_weight(pyrosetta.rosetta.core.scoring.fa_rep, 1.0) \n",
    "scorefxn.set_weight(pyrosetta.rosetta.core.scoring.fa_atr, 1.0) \n",
    "scorefxn.set_weight(pyrosetta.rosetta.core.scoring.fa_sol, 1.0) \n",
    "context_rep = scorefxn(context_pose)\n",
    "\n",
    "clash_check_pose = pyrosetta.Pose()\n",
    "acceptable_helices = []\n",
    "\n",
    "num_todo = 0\n",
    "for r0 in np.arange(r0_start,r0_stop,r0_step):\n",
    "    for delta_z in np.arange(delta_z_start, delta_z_stop, delta_z_step):\n",
    "        for omega0 in np.arange(omega0_start, omega0_stop, omega0_step):\n",
    "            for phi0 in np.arange(phi0_start, phi0_stop, phi0_step):\n",
    "                num_todo += 1\n",
    "\n",
    "print(f\"num_todo! {num_todo}\")\n",
    "\n",
    "\n",
    "bar = tqdm.tqdm_notebook(total = num_todo)\n",
    "\n",
    "if do_run:\n",
    "    all_helices = []\n",
    "    counter = 0\n",
    "    for r0 in np.arange(r0_start,r0_stop,r0_step):\n",
    "        for delta_z in np.arange(delta_z_start, delta_z_stop, delta_z_step):\n",
    "            for omega0 in np.arange(omega0_start, omega0_stop, omega0_step):\n",
    "                for phi0 in np.arange(phi0_start, phi0_stop, phi0_step):\n",
    "\n",
    "                    bar.update(1)\n",
    "                    chp = copy.deepcopy(fp)\n",
    "                    chp.r0(r0)\n",
    "                    chp.delta_z(delta_z)\n",
    "                    chp.omega0(omega0)\n",
    "                    chp.phi0(phi0)\n",
    "\n",
    "                    tph = ParametricHelix()\n",
    "                    tph.set_helix_parameters(chp)\n",
    "\n",
    "                    name=f\"{counter}_{r0:.2f}_{delta_z:.2f}_{degrees(omega0):.2f}_{degrees(phi0):.2f}\"\n",
    "\n",
    "                    #with open(f\"test_{name}.pdb\",'w') as pdb:\n",
    "                    #    pdb.write(tph.pdb_str())\n",
    "\n",
    "                    helix = tph.pose()\n",
    "                    make_poly_x(helix,\"V\")\n",
    "\n",
    "                    helix_rep = scorefxn(helix)\n",
    "                    clash_check_pose.detached_copy(context_pose)\n",
    "                    clash_check_pose.append_pose_by_jump(helix,1)\n",
    "                    merged_rep = scorefxn(clash_check_pose)\n",
    "                    diff = merged_rep - (helix_rep + context_rep)\n",
    "                    #print(name, diff)\n",
    "\n",
    "                    #all_helices.append((name,helix,diff))\n",
    "                    #this magic number was arrived at by looking at many and seeing which looked like crap and which didn't\n",
    "                    energy_diff_cutoff = 9000\n",
    "                    if abs(diff) < energy_diff_cutoff:\n",
    "                        acceptable_helices.append((name,helix))\n",
    "\n",
    "                    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump( acceptable_helices, open( \"acceptable_helices.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2026"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(acceptable_helices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name,helix,diff in sorted(all_helices,key=lambda x: x[2]):\n",
    "#     helix.dump_pdb(f\"V_{name}.pdb\")\n",
    "#     print(name, diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "for name,helix in random.sample(acceptable_helices,20):\n",
    "    helix.dump_pdb(f\"accepted_{name}.pdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hm, I'm noticing gaps that are bigger than I'd like. \n",
    "#i'd better calculate how good of contacts It's making with both parts of the structure\n",
    "\n",
    "\n",
    "xml_obj = pyrosetta.rosetta.protocols.rosetta_scripts.XmlObjects.create_from_string(\"\"\"\n",
    "<RESIDUE_SELECTORS>\n",
    "   <True name=\"all\"/>\n",
    "   <SSElement name=\"left\" \n",
    "       selection=\"6,H\" \n",
    "       to_selection=\"7,H\" \n",
    "       chain=\"A\" />\n",
    "\n",
    "   <SSElement name=\"right\" \n",
    "       selection=\"8,H\" \n",
    "       to_selection=\"9,H\" \n",
    "       chain=\"A\" />\n",
    "</RESIDUE_SELECTORS>\n",
    "\n",
    "<FILTERS>\n",
    "    <BuriedSurfaceArea name=\"BSA\" confidence=\"0\" residue_selector=\"all\"/>\n",
    "    <BuriedSurfaceArea name=\"BSA_left\" confidence=\"0\" residue_selector=\"left\"/>\n",
    "    <BuriedSurfaceArea name=\"BSA_right\" confidence=\"0\" residue_selector=\"right\"/>\n",
    "</FILTERS>\n",
    "\"\"\")\n",
    "all_burial = xml_obj.get_filter(\"BSA\")\n",
    "left_burial = xml_obj.get_filter(\"BSA_left\")\n",
    "right_burial = xml_obj.get_filter(\"BSA_right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_burial_before = left_burial.report_sm(context_pose)\n",
    "right_burial_before = right_burial.report_sm(context_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11488_24.69_-3.21_-1.23_39.81 488.7321081776581 218.06437665433532\n",
      "7915_22.89_-2.21_-2.43_47.81 284.17312030333414 549.1063359801574\n",
      "12047_24.69_1.79_-2.03_31.81 692.413746186573 43.81593236595745\n",
      "8409_22.89_1.79_-2.23_43.81 458.40480943089005 427.1451170126129\n",
      "7617_22.89_-5.21_-1.23_43.81 418.96976208570504 381.291563165576\n",
      "10366_24.09_-2.21_-1.83_39.81 514.5868339402869 275.20593664436274\n",
      "7189_22.29_1.79_-2.43_47.81 373.3506331067747 495.0665596227336\n",
      "7001_22.29_-0.21_-1.43_43.81 427.35563474848186 458.47142670918674\n",
      "8629_23.49_-6.21_-2.63_43.81 275.9521230772307 495.80147510714687\n",
      "8916_23.49_-4.21_-1.83_47.81 261.6088599009827 472.68283607821104\n",
      "10027_24.09_-5.21_-1.43_47.81 242.39480941845704 431.2462141187616\n",
      "10270_24.09_-3.21_-1.43_51.81 150.1495042392189 557.7576848576873\n",
      "9477_23.49_0.79_-2.63_47.81 369.42459640311336 486.57694458922197\n",
      "11005_24.69_-7.21_-1.23_43.81 341.9782777460259 290.83828449209796\n",
      "9366_23.49_-0.21_-2.43_43.81 424.52706883549035 414.83712494071733\n",
      "11587_24.69_-2.21_-1.63_39.81 475.7581682763748 249.07172549085044\n",
      "10324_24.09_-2.21_-2.63_47.81 266.23405223193913 533.2095901432949\n",
      "10644_24.09_-0.21_-1.23_51.81 141.96141228728084 591.7375078217856\n",
      "11288_24.69_-4.21_-2.63_31.81 544.2496509342345 201.91733508869766\n",
      "11896_24.69_0.79_-2.63_43.81 399.54342526700384 324.131200161738\n"
     ]
    }
   ],
   "source": [
    "#TESTING CELL\n",
    "burial_check_pose = pyrosetta.Pose()\n",
    "for name,helix in random.sample(acceptable_helices,20):\n",
    "    burial_check_pose.detached_copy(context_pose)\n",
    "    burial_check_pose.append_pose_by_jump(helix,1)\n",
    "    left_burial_after = left_burial.report_sm(burial_check_pose)\n",
    "    right_burial_after = right_burial.report_sm(burial_check_pose)\n",
    "    delta_left = left_burial_after - left_burial_before\n",
    "    delta_right = right_burial_after - right_burial_before\n",
    "    \n",
    "    #took these into pymol and excel and decided by eye which was touching enough on both sides\n",
    "    #350 as a cutoff for boths sides seems good.\n",
    "    \n",
    "    print(name,delta_left,delta_right)\n",
    "    helix.dump_pdb(f\"accepted_{name}.pdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rdkibler/.conda/envs/pyro/lib/python3.7/site-packages/ipykernel_launcher.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d49a85a7fc4e71b7e52c0af81cf542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2026.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying 5395_21.69_-3.21_-2.03_43.81\n",
      "accepted with 404.34231276511946 and 412.9819097590216\n",
      "trying 5406_21.69_-3.21_-1.83_43.81\n",
      "accepted with 400.24591641242205 and 417.8550474420226\n",
      "trying 5417_21.69_-3.21_-1.63_43.81\n",
      "accepted with 398.54499609361847 and 426.83163260789934\n",
      "trying 5879_21.69_0.79_-2.03_43.81\n",
      "accepted with 446.16725109058916 and 438.5068924053221\n",
      "trying 5890_21.69_0.79_-1.83_43.81\n",
      "accepted with 436.2664869362152 and 446.8697422360092\n",
      "trying 5901_21.69_0.79_-1.63_43.81\n",
      "accepted with 421.72455874897787 and 452.347795523714\n",
      "trying 6011_21.69_1.79_-1.83_43.81\n",
      "accepted with 433.79499211712846 and 447.2520856974779\n",
      "trying 6022_21.69_1.79_-1.63_43.81\n",
      "accepted with 418.8064535668491 and 449.29822438530937\n",
      "trying 6033_21.69_1.79_-1.43_43.81\n",
      "accepted with 413.74640275648653 and 459.1680302772611\n",
      "trying 6087_22.29_-7.21_-2.63_39.81\n",
      "accepted with 371.53353591593805 and 404.005324593144\n",
      "trying 6097_22.29_-7.21_-2.43_35.81\n",
      "trying 6098_22.29_-7.21_-2.43_39.81\n",
      "accepted with 390.5043417998695 and 363.7804963688832\n",
      "trying 6099_22.29_-7.21_-2.43_43.81\n",
      "trying 6109_22.29_-7.21_-2.23_39.81\n",
      "trying 6110_22.29_-7.21_-2.23_43.81\n",
      "trying 6111_22.29_-7.21_-2.23_47.81\n",
      "trying 6120_22.29_-7.21_-2.03_39.81\n",
      "trying 6121_22.29_-7.21_-2.03_43.81\n",
      "trying 6122_22.29_-7.21_-2.03_47.81\n",
      "trying 6131_22.29_-7.21_-1.83_39.81\n",
      "trying 6132_22.29_-7.21_-1.83_43.81\n",
      "trying 6133_22.29_-7.21_-1.83_47.81\n",
      "trying 6142_22.29_-7.21_-1.63_39.81\n",
      "trying 6143_22.29_-7.21_-1.63_43.81\n",
      "accepted with 354.9887609633388 and 357.70496645759613\n",
      "trying 6144_22.29_-7.21_-1.63_47.81\n",
      "trying 6145_22.29_-7.21_-1.63_51.81\n",
      "trying 6153_22.29_-7.21_-1.43_39.81\n",
      "trying 6154_22.29_-7.21_-1.43_43.81\n",
      "accepted with 381.88796156352964 and 361.034022986888\n",
      "trying 6155_22.29_-7.21_-1.43_47.81\n",
      "trying 6156_22.29_-7.21_-1.43_51.81\n",
      "trying 6165_22.29_-7.21_-1.23_43.81\n",
      "accepted with 409.9701540877395 and 358.98229924545103\n",
      "trying 6166_22.29_-7.21_-1.23_47.81\n",
      "trying 6253_22.29_-6.21_-1.83_43.81\n",
      "accepted with 352.5838834225442 and 386.59505250000984\n",
      "trying 6264_22.29_-6.21_-1.63_43.81\n",
      "accepted with 370.10641509316974 and 375.3890380467674\n",
      "trying 6265_22.29_-6.21_-1.63_47.81\n",
      "trying 6275_22.29_-6.21_-1.43_43.81\n",
      "accepted with 392.84348636252435 and 376.1587282468954\n",
      "trying 6276_22.29_-6.21_-1.43_47.81\n",
      "trying 6286_22.29_-6.21_-1.23_43.81\n",
      "accepted with 422.0113977937772 and 372.05763114074944\n",
      "trying 6287_22.29_-6.21_-1.23_47.81\n",
      "trying 6339_22.29_-5.21_-2.43_35.81\n",
      "trying 6350_22.29_-5.21_-2.23_35.81\n",
      "trying 6361_22.29_-5.21_-2.03_35.81\n",
      "trying 6362_22.29_-5.21_-2.03_39.81\n",
      "trying 6372_22.29_-5.21_-1.83_35.81\n",
      "trying 6373_22.29_-5.21_-1.83_39.81\n",
      "trying 6384_22.29_-5.21_-1.63_39.81\n",
      "trying 6385_22.29_-5.21_-1.63_43.81\n",
      "accepted with 379.07594912886725 and 388.64677624144406\n",
      "trying 6395_22.29_-5.21_-1.43_39.81\n",
      "trying 6396_22.29_-5.21_-1.43_43.81\n",
      "accepted with 393.6108261859272 and 391.5407803658554\n",
      "trying 6397_22.29_-5.21_-1.43_47.81\n",
      "trying 6407_22.29_-5.21_-1.23_43.81\n",
      "accepted with 421.08486842855564 and 386.6746938130309\n",
      "trying 6408_22.29_-5.21_-1.23_47.81\n",
      "trying 6461_22.29_-4.21_-2.43_39.81\n",
      "accepted with 462.2441614483723 and 357.63472665147583\n",
      "trying 6471_22.29_-4.21_-2.23_35.81\n",
      "trying 6472_22.29_-4.21_-2.23_39.81\n",
      "trying 6482_22.29_-4.21_-2.03_35.81\n",
      "trying 6483_22.29_-4.21_-2.03_39.81\n",
      "trying 6484_22.29_-4.21_-2.03_43.81\n",
      "accepted with 378.4630980938309 and 406.3214463237109\n",
      "trying 6494_22.29_-4.21_-1.83_39.81\n",
      "trying 6495_22.29_-4.21_-1.83_43.81\n",
      "accepted with 376.93076882375135 and 402.4776960765157\n",
      "trying 6505_22.29_-4.21_-1.63_39.81\n",
      "trying 6506_22.29_-4.21_-1.63_43.81\n",
      "accepted with 382.91969937606245 and 411.9666245835697\n",
      "trying 6507_22.29_-4.21_-1.63_47.81\n",
      "trying 6516_22.29_-4.21_-1.43_39.81\n",
      "trying 6517_22.29_-4.21_-1.43_43.81\n",
      "accepted with 398.09750143042675 and 408.19311414249296\n",
      "trying 6518_22.29_-4.21_-1.43_47.81\n",
      "trying 6528_22.29_-4.21_-1.23_43.81\n",
      "accepted with 418.1160168287988 and 407.4304750725414\n",
      "trying 6529_22.29_-4.21_-1.23_47.81\n",
      "trying 6582_22.29_-3.21_-2.43_39.81\n",
      "accepted with 481.21026657884886 and 350.72396748739266\n",
      "trying 6583_22.29_-3.21_-2.43_43.81\n",
      "accepted with 382.05420223552665 and 463.9682985247391\n",
      "trying 6593_22.29_-3.21_-2.23_39.81\n",
      "accepted with 501.4560548739073 and 353.54068067550816\n",
      "trying 6594_22.29_-3.21_-2.23_43.81\n",
      "accepted with 386.920288788353 and 419.1323802298766\n",
      "trying 6595_22.29_-3.21_-2.23_47.81\n",
      "trying 6604_22.29_-3.21_-2.03_39.81\n",
      "accepted with 518.6277831219004 and 350.79185691678595\n",
      "trying 6605_22.29_-3.21_-2.03_43.81\n",
      "accepted with 392.55371516457944 and 414.5189397825534\n",
      "trying 6606_22.29_-3.21_-2.03_47.81\n",
      "trying 6615_22.29_-3.21_-1.83_39.81\n",
      "trying 6616_22.29_-3.21_-1.83_43.81\n",
      "accepted with 386.15059858822315 and 423.4931745717049\n",
      "trying 6617_22.29_-3.21_-1.83_47.81\n",
      "trying 6626_22.29_-3.21_-1.63_39.81\n",
      "trying 6627_22.29_-3.21_-1.63_43.81\n",
      "accepted with 392.9115697173893 and 424.7752081130111\n",
      "trying 6628_22.29_-3.21_-1.63_47.81\n",
      "trying 6638_22.29_-3.21_-1.43_43.81\n",
      "accepted with 409.36905493633367 and 419.2096711661752\n",
      "trying 6639_22.29_-3.21_-1.43_47.81\n",
      "trying 6649_22.29_-3.21_-1.23_43.81\n",
      "accepted with 424.26413692293136 and 422.80077530787094\n",
      "trying 6650_22.29_-3.21_-1.23_47.81\n",
      "trying 6704_22.29_-2.21_-2.43_43.81\n",
      "accepted with 405.62669668315266 and 450.715261083511\n",
      "trying 6705_22.29_-2.21_-2.43_47.81\n",
      "trying 6715_22.29_-2.21_-2.23_43.81\n",
      "accepted with 408.7031071069432 and 429.38159743015694\n",
      "trying 6716_22.29_-2.21_-2.23_47.81\n",
      "trying 6725_22.29_-2.21_-2.03_39.81\n",
      "accepted with 543.4118773792407 and 356.687330905419\n",
      "trying 6726_22.29_-2.21_-2.03_43.81\n",
      "accepted with 408.6960559767649 and 426.62807291798254\n",
      "trying 6727_22.29_-2.21_-2.03_47.81\n",
      "trying 6737_22.29_-2.21_-1.83_43.81\n",
      "accepted with 406.2277958345576 and 438.161674036297\n",
      "trying 6738_22.29_-2.21_-1.83_47.81\n",
      "trying 6748_22.29_-2.21_-1.63_43.81\n",
      "accepted with 410.45242346665145 and 433.0382406245217\n",
      "trying 6749_22.29_-2.21_-1.63_47.81\n",
      "trying 6759_22.29_-2.21_-1.43_43.81\n",
      "accepted with 418.1723483000342 and 438.42137127197566\n",
      "trying 6760_22.29_-2.21_-1.43_47.81\n",
      "trying 6836_22.29_-1.21_-2.23_43.81\n",
      "accepted with 420.1639241169396 and 440.56185082363936\n",
      "trying 6837_22.29_-1.21_-2.23_47.81\n",
      "trying 6847_22.29_-1.21_-2.03_43.81\n",
      "accepted with 428.0082637764235 and 442.896294632842\n",
      "trying 6848_22.29_-1.21_-2.03_47.81\n",
      "trying 6858_22.29_-1.21_-1.83_43.81\n",
      "accepted with 418.3315378418556 and 446.64893869308526\n",
      "trying 6859_22.29_-1.21_-1.83_47.81\n",
      "trying 6869_22.29_-1.21_-1.63_43.81\n",
      "accepted with 426.8441757074552 and 452.3171397850301\n",
      "trying 6956_22.29_-0.21_-2.23_39.81\n",
      "trying 6957_22.29_-0.21_-2.23_43.81\n",
      "accepted with 445.6233677105738 and 444.0191386323295\n",
      "trying 6967_22.29_-0.21_-2.03_39.81\n",
      "trying 6968_22.29_-0.21_-2.03_43.81\n",
      "accepted with 446.96408309984054 and 439.69311900622415\n",
      "trying 6969_22.29_-0.21_-2.03_47.81\n",
      "trying 6978_22.29_-0.21_-1.83_39.81\n",
      "accepted with 543.4354819877472 and 350.1781215815963\n",
      "trying 6979_22.29_-0.21_-1.83_43.81\n",
      "accepted with 436.61347390555056 and 448.24611664115037\n",
      "trying 6989_22.29_-0.21_-1.63_39.81\n",
      "trying 6990_22.29_-0.21_-1.63_43.81\n",
      "accepted with 427.1315965286758 and 453.8255619228685\n",
      "trying 7001_22.29_-0.21_-1.43_43.81\n",
      "accepted with 427.35563474848186 and 458.47142670918674\n",
      "trying 7066_22.29_0.79_-2.43_39.81\n",
      "trying 7067_22.29_0.79_-2.43_43.81\n",
      "accepted with 465.5357903614813 and 424.32605344777494\n",
      "trying 7077_22.29_0.79_-2.23_39.81\n",
      "trying 7078_22.29_0.79_-2.23_43.81\n",
      "accepted with 457.9821062000965 and 431.43077686939523\n",
      "trying 7079_22.29_0.79_-2.23_47.81\n",
      "trying 7088_22.29_0.79_-2.03_39.81\n",
      "trying 7089_22.29_0.79_-2.03_43.81\n",
      "accepted with 452.6384510218113 and 439.27893298217805\n",
      "trying 7090_22.29_0.79_-2.03_47.81\n",
      "trying 7099_22.29_0.79_-1.83_39.81\n",
      "accepted with 531.4219618672487 and 353.6987919917019\n",
      "trying 7100_22.29_0.79_-1.83_43.81\n",
      "accepted with 424.6370788774984 and 443.25091450877244\n",
      "trying 7101_22.29_0.79_-1.83_47.81\n",
      "trying 7110_22.29_0.79_-1.63_39.81\n",
      "accepted with 525.9097156402413 and 359.87933642482494\n",
      "trying 7111_22.29_0.79_-1.63_43.81\n",
      "accepted with 420.0870210315861 and 450.6215019960955\n",
      "trying 7112_22.29_0.79_-1.63_47.81\n",
      "trying 7121_22.29_0.79_-1.43_39.81\n",
      "accepted with 508.16314574981243 and 365.102393230306\n",
      "trying 7122_22.29_0.79_-1.43_43.81\n",
      "accepted with 418.13580498400734 and 463.04597346375886\n",
      "trying 7133_22.29_0.79_-1.23_43.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accepted with 417.30273218246384 and 458.11180355606757\n",
      "trying 7188_22.29_1.79_-2.43_43.81\n",
      "accepted with 460.83035942704737 and 416.12385923547936\n",
      "trying 7189_22.29_1.79_-2.43_47.81\n",
      "accepted with 373.3506331067747 and 495.0665596227336\n",
      "trying 7198_22.29_1.79_-2.23_39.81\n",
      "trying 7199_22.29_1.79_-2.23_43.81\n",
      "accepted with 457.50365327448253 and 432.5559712456079\n",
      "trying 7200_22.29_1.79_-2.23_47.81\n",
      "trying 7209_22.29_1.79_-2.03_39.81\n",
      "trying 7210_22.29_1.79_-2.03_43.81\n",
      "accepted with 452.0270660633487 and 435.5333400521149\n",
      "trying 7211_22.29_1.79_-2.03_47.81\n",
      "trying 7220_22.29_1.79_-1.83_39.81\n",
      "trying 7221_22.29_1.79_-1.83_43.81\n",
      "accepted with 429.2782429103636 and 442.96260938740033\n",
      "trying 7222_22.29_1.79_-1.83_47.81\n",
      "trying 7231_22.29_1.79_-1.63_39.81\n",
      "accepted with 505.66862809863414 and 350.7149538314343\n",
      "trying 7232_22.29_1.79_-1.63_43.81\n",
      "accepted with 406.6045542424217 and 438.8296697186761\n",
      "trying 7233_22.29_1.79_-1.63_47.81\n",
      "trying 7242_22.29_1.79_-1.43_39.81\n",
      "accepted with 509.63914354865756 and 362.46700811594474\n",
      "trying 7243_22.29_1.79_-1.43_43.81\n",
      "accepted with 401.57692777104967 and 452.98513546741106\n",
      "trying 7253_22.29_1.79_-1.23_39.81\n",
      "accepted with 518.0907491895723 and 369.094162912108\n",
      "trying 7254_22.29_1.79_-1.23_43.81\n",
      "accepted with 399.2091753227005 and 464.06977584595916\n",
      "trying 7296_22.89_-7.21_-2.63_35.81\n",
      "trying 7297_22.89_-7.21_-2.63_39.81\n",
      "accepted with 357.19732386986925 and 406.5670412990321\n",
      "trying 7298_22.89_-7.21_-2.63_43.81\n",
      "trying 7307_22.89_-7.21_-2.43_35.81\n",
      "trying 7308_22.89_-7.21_-2.43_39.81\n",
      "accepted with 381.2751105284933 and 358.1447196159279\n",
      "trying 7309_22.89_-7.21_-2.43_43.81\n",
      "trying 7310_22.89_-7.21_-2.43_47.81\n",
      "trying 7318_22.89_-7.21_-2.23_35.81\n",
      "trying 7319_22.89_-7.21_-2.23_39.81\n",
      "trying 7320_22.89_-7.21_-2.23_43.81\n",
      "trying 7321_22.89_-7.21_-2.23_47.81\n",
      "trying 7322_22.89_-7.21_-2.23_51.81\n",
      "trying 7329_22.89_-7.21_-2.03_35.81\n",
      "trying 7330_22.89_-7.21_-2.03_39.81\n",
      "trying 7331_22.89_-7.21_-2.03_43.81\n",
      "trying 7332_22.89_-7.21_-2.03_47.81\n",
      "trying 7333_22.89_-7.21_-2.03_51.81\n",
      "trying 7340_22.89_-7.21_-1.83_35.81\n",
      "trying 7341_22.89_-7.21_-1.83_39.81\n",
      "trying 7342_22.89_-7.21_-1.83_43.81\n",
      "trying 7343_22.89_-7.21_-1.83_47.81\n",
      "trying 7344_22.89_-7.21_-1.83_51.81\n",
      "trying 7351_22.89_-7.21_-1.63_35.81\n",
      "trying 7352_22.89_-7.21_-1.63_39.81\n",
      "trying 7353_22.89_-7.21_-1.63_43.81\n",
      "trying 7354_22.89_-7.21_-1.63_47.81\n",
      "trying 7355_22.89_-7.21_-1.63_51.81\n",
      "trying 7362_22.89_-7.21_-1.43_35.81\n",
      "trying 7363_22.89_-7.21_-1.43_39.81\n",
      "trying 7364_22.89_-7.21_-1.43_43.81\n",
      "trying 7365_22.89_-7.21_-1.43_47.81\n",
      "trying 7366_22.89_-7.21_-1.43_51.81\n",
      "trying 7374_22.89_-7.21_-1.23_39.81\n",
      "trying 7375_22.89_-7.21_-1.23_43.81\n",
      "trying 7376_22.89_-7.21_-1.23_47.81\n",
      "trying 7377_22.89_-7.21_-1.23_51.81\n",
      "trying 7417_22.89_-6.21_-2.63_35.81\n",
      "trying 7418_22.89_-6.21_-2.63_39.81\n",
      "accepted with 383.8368272343805 and 386.58095023965143\n",
      "trying 7419_22.89_-6.21_-2.63_43.81\n",
      "trying 7428_22.89_-6.21_-2.43_35.81\n",
      "trying 7429_22.89_-6.21_-2.43_39.81\n",
      "accepted with 408.18371263558674 and 354.2915678618292\n",
      "trying 7430_22.89_-6.21_-2.43_43.81\n",
      "trying 7431_22.89_-6.21_-2.43_47.81\n",
      "trying 7438_22.89_-6.21_-2.23_31.81\n",
      "trying 7439_22.89_-6.21_-2.23_35.81\n",
      "trying 7440_22.89_-6.21_-2.23_39.81\n",
      "trying 7441_22.89_-6.21_-2.23_43.81\n",
      "trying 7442_22.89_-6.21_-2.23_47.81\n",
      "trying 7443_22.89_-6.21_-2.23_51.81\n",
      "trying 7449_22.89_-6.21_-2.03_31.81\n",
      "trying 7450_22.89_-6.21_-2.03_35.81\n",
      "trying 7451_22.89_-6.21_-2.03_39.81\n",
      "trying 7452_22.89_-6.21_-2.03_43.81\n",
      "trying 7453_22.89_-6.21_-2.03_47.81\n",
      "trying 7454_22.89_-6.21_-2.03_51.81\n",
      "trying 7460_22.89_-6.21_-1.83_31.81\n",
      "trying 7461_22.89_-6.21_-1.83_35.81\n",
      "trying 7462_22.89_-6.21_-1.83_39.81\n",
      "trying 7463_22.89_-6.21_-1.83_43.81\n",
      "trying 7464_22.89_-6.21_-1.83_47.81\n",
      "trying 7465_22.89_-6.21_-1.83_51.81\n",
      "trying 7472_22.89_-6.21_-1.63_35.81\n",
      "trying 7473_22.89_-6.21_-1.63_39.81\n",
      "trying 7474_22.89_-6.21_-1.63_43.81\n",
      "accepted with 360.3648404806154 and 365.6521641876643\n",
      "trying 7475_22.89_-6.21_-1.63_47.81\n",
      "trying 7476_22.89_-6.21_-1.63_51.81\n",
      "trying 7483_22.89_-6.21_-1.43_35.81\n",
      "trying 7484_22.89_-6.21_-1.43_39.81\n",
      "trying 7485_22.89_-6.21_-1.43_43.81\n",
      "accepted with 389.86053250241184 and 353.35357362267496\n",
      "trying 7486_22.89_-6.21_-1.43_47.81\n",
      "trying 7487_22.89_-6.21_-1.43_51.81\n",
      "trying 7495_22.89_-6.21_-1.23_39.81\n",
      "trying 7496_22.89_-6.21_-1.23_43.81\n",
      "accepted with 408.5923136060255 and 363.0904474817771\n",
      "trying 7497_22.89_-6.21_-1.23_47.81\n",
      "trying 7538_22.89_-5.21_-2.63_35.81\n",
      "trying 7539_22.89_-5.21_-2.63_39.81\n",
      "accepted with 405.61729517624826 and 395.03579055744467\n",
      "trying 7548_22.89_-5.21_-2.43_31.81\n",
      "trying 7549_22.89_-5.21_-2.43_35.81\n",
      "trying 7550_22.89_-5.21_-2.43_39.81\n",
      "trying 7551_22.89_-5.21_-2.43_43.81\n",
      "trying 7552_22.89_-5.21_-2.43_47.81\n",
      "trying 7559_22.89_-5.21_-2.23_31.81\n",
      "trying 7560_22.89_-5.21_-2.23_35.81\n",
      "trying 7561_22.89_-5.21_-2.23_39.81\n",
      "trying 7562_22.89_-5.21_-2.23_43.81\n",
      "trying 7563_22.89_-5.21_-2.23_47.81\n",
      "trying 7570_22.89_-5.21_-2.03_31.81\n",
      "trying 7571_22.89_-5.21_-2.03_35.81\n",
      "trying 7572_22.89_-5.21_-2.03_39.81\n",
      "trying 7573_22.89_-5.21_-2.03_43.81\n",
      "accepted with 354.63090641052986 and 394.01580462854326\n",
      "trying 7574_22.89_-5.21_-2.03_47.81\n",
      "trying 7582_22.89_-5.21_-1.83_35.81\n",
      "trying 7583_22.89_-5.21_-1.83_39.81\n",
      "trying 7584_22.89_-5.21_-1.83_43.81\n",
      "accepted with 359.76139095248345 and 384.543328758572\n",
      "trying 7585_22.89_-5.21_-1.83_47.81\n",
      "trying 7593_22.89_-5.21_-1.63_35.81\n",
      "trying 7594_22.89_-5.21_-1.63_39.81\n",
      "trying 7595_22.89_-5.21_-1.63_43.81\n",
      "accepted with 371.13110177552335 and 381.7921546231237\n",
      "trying 7596_22.89_-5.21_-1.63_47.81\n",
      "trying 7604_22.89_-5.21_-1.43_35.81\n",
      "trying 7605_22.89_-5.21_-1.43_39.81\n",
      "trying 7606_22.89_-5.21_-1.43_43.81\n",
      "accepted with 392.0690954089423 and 384.61356856469047\n",
      "trying 7607_22.89_-5.21_-1.43_47.81\n",
      "trying 7616_22.89_-5.21_-1.23_39.81\n",
      "trying 7617_22.89_-5.21_-1.23_43.81\n",
      "accepted with 418.96976208570504 and 381.291563165576\n",
      "trying 7618_22.89_-5.21_-1.23_47.81\n",
      "trying 7659_22.89_-4.21_-2.63_35.81\n",
      "trying 7660_22.89_-4.21_-2.63_39.81\n",
      "accepted with 433.2979378601967 and 381.20252034564874\n",
      "trying 7661_22.89_-4.21_-2.63_43.81\n",
      "trying 7670_22.89_-4.21_-2.43_35.81\n",
      "trying 7671_22.89_-4.21_-2.43_39.81\n",
      "trying 7672_22.89_-4.21_-2.43_43.81\n",
      "accepted with 358.72965313995155 and 477.80156873653596\n",
      "trying 7673_22.89_-4.21_-2.43_47.81\n",
      "trying 7681_22.89_-4.21_-2.23_35.81\n",
      "trying 7682_22.89_-4.21_-2.23_39.81\n",
      "trying 7683_22.89_-4.21_-2.23_43.81\n",
      "accepted with 369.7485605403599 and 421.17940321786045\n",
      "trying 7684_22.89_-4.21_-2.23_47.81\n",
      "trying 7692_22.89_-4.21_-2.03_35.81\n",
      "trying 7693_22.89_-4.21_-2.03_39.81\n",
      "trying 7694_22.89_-4.21_-2.03_43.81\n",
      "accepted with 367.4465410701496 and 403.24503589991855\n",
      "trying 7695_22.89_-4.21_-2.03_47.81\n",
      "trying 7696_22.89_-4.21_-2.03_51.81\n",
      "trying 7703_22.89_-4.21_-1.83_35.81\n",
      "trying 7704_22.89_-4.21_-1.83_39.81\n",
      "trying 7705_22.89_-4.21_-1.83_43.81\n",
      "accepted with 368.7262242347306 and 402.7373933121926\n",
      "trying 7706_22.89_-4.21_-1.83_47.81\n",
      "trying 7707_22.89_-4.21_-1.83_51.81\n",
      "trying 7714_22.89_-4.21_-1.63_35.81\n",
      "trying 7715_22.89_-4.21_-1.63_39.81\n",
      "trying 7716_22.89_-4.21_-1.63_43.81\n",
      "accepted with 381.63766583475626 and 406.6466826120559\n",
      "trying 7717_22.89_-4.21_-1.63_47.81\n",
      "trying 7718_22.89_-4.21_-1.63_51.81\n",
      "trying 7726_22.89_-4.21_-1.43_39.81\n",
      "trying 7727_22.89_-4.21_-1.43_43.81\n",
      "accepted with 398.13316044629846 and 399.9909199301974\n",
      "trying 7728_22.89_-4.21_-1.43_47.81\n",
      "trying 7729_22.89_-4.21_-1.43_51.81\n",
      "trying 7737_22.89_-4.21_-1.23_39.81\n",
      "trying 7738_22.89_-4.21_-1.23_43.81\n",
      "accepted with 421.12669427445235 and 394.8698368951482\n",
      "trying 7739_22.89_-4.21_-1.23_47.81\n",
      "trying 7770_22.89_-3.21_-2.83_39.81\n",
      "accepted with 429.19684075404984 and 404.33291125821415\n",
      "trying 7781_22.89_-3.21_-2.63_39.81\n",
      "accepted with 453.2863792963053 and 358.4699559042738\n",
      "trying 7782_22.89_-3.21_-2.63_43.81\n",
      "accepted with 370.26325425826326 and 480.43352524854345\n",
      "trying 7791_22.89_-3.21_-2.43_35.81\n",
      "trying 7792_22.89_-3.21_-2.43_39.81\n",
      "trying 7793_22.89_-3.21_-2.43_43.81\n",
      "accepted with 379.2327882939617 and 468.07409638433637\n",
      "trying 7794_22.89_-3.21_-2.43_47.81\n",
      "trying 7802_22.89_-3.21_-2.23_35.81\n",
      "trying 7803_22.89_-3.21_-2.23_39.81\n",
      "trying 7804_22.89_-3.21_-2.23_43.81\n",
      "accepted with 383.3362357768365 and 421.6940969357647\n",
      "trying 7805_22.89_-3.21_-2.23_47.81\n",
      "trying 7806_22.89_-3.21_-2.23_51.81\n",
      "trying 7813_22.89_-3.21_-2.03_35.81\n",
      "trying 7814_22.89_-3.21_-2.03_39.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying 7815_22.89_-3.21_-2.03_43.81\n",
      "accepted with 381.2821616586725 and 413.75159995915055\n",
      "trying 7816_22.89_-3.21_-2.03_47.81\n",
      "trying 7817_22.89_-3.21_-2.03_51.81\n",
      "trying 7824_22.89_-3.21_-1.83_35.81\n",
      "trying 7825_22.89_-3.21_-1.83_39.81\n",
      "trying 7826_22.89_-3.21_-1.83_43.81\n",
      "accepted with 381.024814799719 and 419.9067711834605\n",
      "trying 7827_22.89_-3.21_-1.83_47.81\n",
      "trying 7828_22.89_-3.21_-1.83_51.81\n",
      "trying 7836_22.89_-3.21_-1.63_39.81\n",
      "trying 7837_22.89_-3.21_-1.63_43.81\n",
      "accepted with 388.29577889333814 and 422.53637731874187\n",
      "trying 7838_22.89_-3.21_-1.63_47.81\n",
      "trying 7839_22.89_-3.21_-1.63_51.81\n",
      "trying 7847_22.89_-3.21_-1.43_39.81\n",
      "trying 7848_22.89_-3.21_-1.43_43.81\n",
      "accepted with 402.9612376065252 and 415.87356350670507\n",
      "trying 7849_22.89_-3.21_-1.43_47.81\n",
      "trying 7850_22.89_-3.21_-1.43_51.81\n",
      "trying 7858_22.89_-3.21_-1.23_39.81\n",
      "trying 7859_22.89_-3.21_-1.23_43.81\n",
      "accepted with 413.15412333556833 and 412.29421124864075\n",
      "trying 7860_22.89_-3.21_-1.23_47.81\n",
      "trying 7861_22.89_-3.21_-1.23_51.81\n",
      "trying 7902_22.89_-2.21_-2.63_39.81\n",
      "accepted with 480.7002736143977 and 363.85543692845295\n",
      "trying 7903_22.89_-2.21_-2.63_43.81\n",
      "accepted with 380.00012811736633 and 463.27589926090604\n",
      "trying 7904_22.89_-2.21_-2.63_47.81\n",
      "trying 7913_22.89_-2.21_-2.43_39.81\n",
      "trying 7914_22.89_-2.21_-2.43_43.81\n",
      "accepted with 397.94389694221445 and 455.8457456254664\n",
      "trying 7915_22.89_-2.21_-2.43_47.81\n",
      "trying 7916_22.89_-2.21_-2.43_51.81\n",
      "trying 7924_22.89_-2.21_-2.23_39.81\n",
      "trying 7925_22.89_-2.21_-2.23_43.81\n",
      "accepted with 402.0379429181812 and 428.16980369497014\n",
      "trying 7926_22.89_-2.21_-2.23_47.81\n",
      "trying 7927_22.89_-2.21_-2.23_51.81\n",
      "trying 7935_22.89_-2.21_-2.03_39.81\n",
      "trying 7936_22.89_-2.21_-2.03_43.81\n",
      "accepted with 398.1918422942599 and 427.4024638715655\n",
      "trying 7937_22.89_-2.21_-2.03_47.81\n",
      "trying 7938_22.89_-2.21_-2.03_51.81\n",
      "trying 7946_22.89_-2.21_-1.83_39.81\n",
      "trying 7947_22.89_-2.21_-1.83_43.81\n",
      "accepted with 396.65011151727686 and 433.29323710674635\n",
      "trying 7948_22.89_-2.21_-1.83_47.81\n",
      "trying 7949_22.89_-2.21_-1.83_51.81\n",
      "trying 7957_22.89_-2.21_-1.63_39.81\n",
      "trying 7958_22.89_-2.21_-1.63_43.81\n",
      "accepted with 399.08506302033766 and 430.4788742953597\n",
      "trying 7959_22.89_-2.21_-1.63_47.81\n",
      "trying 7960_22.89_-2.21_-1.63_51.81\n",
      "trying 7968_22.89_-2.21_-1.43_39.81\n",
      "trying 7969_22.89_-2.21_-1.43_43.81\n",
      "accepted with 402.4465438886209 and 428.6821470361474\n",
      "trying 7970_22.89_-2.21_-1.43_47.81\n",
      "trying 7971_22.89_-2.21_-1.43_51.81\n",
      "trying 7980_22.89_-2.21_-1.23_43.81\n",
      "accepted with 417.1824363333981 and 426.63747442488966\n",
      "trying 7981_22.89_-2.21_-1.23_47.81\n",
      "trying 8024_22.89_-1.21_-2.63_43.81\n",
      "accepted with 401.78764718940783 and 435.3426104714563\n",
      "trying 8025_22.89_-1.21_-2.63_47.81\n",
      "trying 8034_22.89_-1.21_-2.43_39.81\n",
      "trying 8035_22.89_-1.21_-2.43_43.81\n",
      "accepted with 412.8065545898171 and 441.7504278012657\n",
      "trying 8036_22.89_-1.21_-2.43_47.81\n",
      "trying 8037_22.89_-1.21_-2.43_51.81\n",
      "trying 8045_22.89_-1.21_-2.23_39.81\n",
      "trying 8046_22.89_-1.21_-2.23_43.81\n",
      "accepted with 409.2131000713953 and 434.31792378910177\n",
      "trying 8047_22.89_-1.21_-2.23_47.81\n",
      "trying 8048_22.89_-1.21_-2.23_51.81\n",
      "trying 8056_22.89_-1.21_-2.03_39.81\n",
      "trying 8057_22.89_-1.21_-2.03_43.81\n",
      "accepted with 402.0379429181803 and 437.0689039990757\n",
      "trying 8058_22.89_-1.21_-2.03_47.81\n",
      "trying 8059_22.89_-1.21_-2.03_51.81\n",
      "trying 8067_22.89_-1.21_-1.83_39.81\n",
      "trying 8068_22.89_-1.21_-1.83_43.81\n",
      "accepted with 406.4217600920965 and 442.70703112875617\n",
      "trying 8069_22.89_-1.21_-1.83_47.81\n",
      "trying 8070_22.89_-1.21_-1.83_51.81\n",
      "trying 8078_22.89_-1.21_-1.63_39.81\n",
      "trying 8079_22.89_-1.21_-1.63_43.81\n",
      "accepted with 408.4331240642068 and 442.52011800139553\n",
      "trying 8080_22.89_-1.21_-1.63_47.81\n",
      "trying 8089_22.89_-1.21_-1.43_39.81\n",
      "trying 8090_22.89_-1.21_-1.43_43.81\n",
      "accepted with 416.43811934208316 and 444.5084591414188\n",
      "trying 8091_22.89_-1.21_-1.43_47.81\n",
      "trying 8101_22.89_-1.21_-1.23_43.81\n",
      "accepted with 426.98415887048486 and 435.60230770713406\n",
      "trying 8145_22.89_-0.21_-2.63_43.81\n",
      "accepted with 429.77403277321173 and 420.4776024471257\n",
      "trying 8146_22.89_-0.21_-2.63_47.81\n",
      "trying 8155_22.89_-0.21_-2.43_39.81\n",
      "trying 8156_22.89_-0.21_-2.43_43.81\n",
      "accepted with 438.4815191965072 and 427.91010645929236\n",
      "trying 8157_22.89_-0.21_-2.43_47.81\n",
      "trying 8165_22.89_-0.21_-2.23_35.81\n",
      "trying 8166_22.89_-0.21_-2.23_39.81\n",
      "trying 8167_22.89_-0.21_-2.23_43.81\n",
      "accepted with 433.52432645672707 and 441.23338370663623\n",
      "trying 8168_22.89_-0.21_-2.23_47.81\n",
      "trying 8176_22.89_-0.21_-2.03_35.81\n",
      "trying 8177_22.89_-0.21_-2.03_39.81\n",
      "trying 8178_22.89_-0.21_-2.03_43.81\n",
      "accepted with 434.2188821718146 and 434.86034109254524\n",
      "trying 8179_22.89_-0.21_-2.03_47.81\n",
      "trying 8187_22.89_-0.21_-1.83_35.81\n",
      "trying 8188_22.89_-0.21_-1.83_39.81\n",
      "trying 8189_22.89_-0.21_-1.83_43.81\n",
      "accepted with 420.86229628532146 and 439.86171005494725\n",
      "trying 8190_22.89_-0.21_-1.83_47.81\n",
      "trying 8199_22.89_-0.21_-1.63_39.81\n",
      "trying 8200_22.89_-0.21_-1.63_43.81\n",
      "accepted with 415.9281263776311 and 439.5109066323157\n",
      "trying 8201_22.89_-0.21_-1.63_47.81\n",
      "trying 8210_22.89_-0.21_-1.43_39.81\n",
      "trying 8211_22.89_-0.21_-1.43_43.81\n",
      "accepted with 410.256690608805 and 451.712805956744\n",
      "trying 8212_22.89_-0.21_-1.43_47.81\n",
      "trying 8222_22.89_-0.21_-1.23_43.81\n",
      "accepted with 416.7603148790222 and 452.1617666965094\n",
      "trying 8265_22.89_0.79_-2.63_39.81\n",
      "trying 8266_22.89_0.79_-2.63_43.81\n",
      "accepted with 460.44801596557863 and 406.3846349996502\n",
      "trying 8267_22.89_0.79_-2.63_47.81\n",
      "accepted with 373.6167996962158 and 496.573515684001\n",
      "trying 8275_22.89_0.79_-2.43_35.81\n",
      "trying 8276_22.89_0.79_-2.43_39.81\n",
      "trying 8277_22.89_0.79_-2.43_43.81\n",
      "accepted with 457.1513837752791 and 420.9922961650309\n",
      "trying 8278_22.89_0.79_-2.43_47.81\n",
      "accepted with 353.81527138746696 and 514.5102333786726\n",
      "trying 8279_22.89_0.79_-2.43_51.81\n",
      "trying 8286_22.89_0.79_-2.23_35.81\n",
      "trying 8287_22.89_0.79_-2.23_39.81\n",
      "trying 8288_22.89_0.79_-2.23_43.81\n",
      "accepted with 455.5866301662063 and 429.44478610609804\n",
      "trying 8289_22.89_0.79_-2.23_47.81\n",
      "trying 8290_22.89_0.79_-2.23_51.81\n",
      "trying 8297_22.89_0.79_-2.03_35.81\n",
      "trying 8298_22.89_0.79_-2.03_39.81\n",
      "trying 8299_22.89_0.79_-2.03_43.81\n",
      "accepted with 438.9272452593923 and 444.2084021364162\n",
      "trying 8300_22.89_0.79_-2.03_47.81\n",
      "trying 8301_22.89_0.79_-2.03_51.81\n",
      "trying 8308_22.89_0.79_-1.83_35.81\n",
      "trying 8309_22.89_0.79_-1.83_39.81\n",
      "trying 8310_22.89_0.79_-1.83_43.81\n",
      "accepted with 423.996504256922 and 438.0950567580021\n",
      "trying 8311_22.89_0.79_-1.83_47.81\n",
      "trying 8319_22.89_0.79_-1.63_35.81\n",
      "trying 8320_22.89_0.79_-1.63_39.81\n",
      "accepted with 520.9177481847446 and 351.4244961070308\n",
      "trying 8321_22.89_0.79_-1.63_43.81\n",
      "accepted with 409.45927682313595 and 441.58946965913856\n",
      "trying 8322_22.89_0.79_-1.63_47.81\n",
      "trying 8331_22.89_0.79_-1.43_39.81\n",
      "accepted with 512.6521713710363 and 351.23199792606283\n",
      "trying 8332_22.89_0.79_-1.43_43.81\n",
      "accepted with 409.2343543031757 and 449.7884291945538\n",
      "trying 8333_22.89_0.79_-1.43_47.81\n",
      "trying 8342_22.89_0.79_-1.23_39.81\n",
      "accepted with 512.3576994196401 and 356.0338175773213\n",
      "trying 8343_22.89_0.79_-1.23_43.81\n",
      "accepted with 403.5985775502186 and 447.8024384312557\n",
      "trying 8386_22.89_1.79_-2.63_39.81\n",
      "trying 8387_22.89_1.79_-2.63_43.81\n",
      "accepted with 477.3243879620213 and 391.26463049309496\n",
      "trying 8388_22.89_1.79_-2.63_47.81\n",
      "accepted with 397.11562573536685 and 476.8377203533946\n",
      "trying 8396_22.89_1.79_-2.43_35.81\n",
      "trying 8397_22.89_1.79_-2.43_39.81\n",
      "trying 8398_22.89_1.79_-2.43_43.81\n",
      "accepted with 468.58359289957843 and 406.6443322353298\n",
      "trying 8399_22.89_1.79_-2.43_47.81\n",
      "accepted with 362.5265742640595 and 492.7274150600806\n",
      "trying 8400_22.89_1.79_-2.43_51.81\n",
      "trying 8407_22.89_1.79_-2.23_35.81\n",
      "trying 8408_22.89_1.79_-2.23_39.81\n",
      "trying 8409_22.89_1.79_-2.23_43.81\n",
      "accepted with 458.40480943089005 and 427.1451170126129\n",
      "trying 8410_22.89_1.79_-2.23_47.81\n",
      "trying 8411_22.89_1.79_-2.23_51.81\n",
      "trying 8418_22.89_1.79_-2.03_35.81\n",
      "trying 8419_22.89_1.79_-2.03_39.81\n",
      "trying 8420_22.89_1.79_-2.03_43.81\n",
      "accepted with 437.64667779465617 and 428.87376091696024\n",
      "trying 8421_22.89_1.79_-2.03_47.81\n",
      "trying 8422_22.89_1.79_-2.03_51.81\n",
      "trying 8429_22.89_1.79_-1.83_35.81\n",
      "trying 8430_22.89_1.79_-1.83_39.81\n",
      "trying 8431_22.89_1.79_-1.83_43.81\n",
      "accepted with 417.113468678378 and 442.13277126273806\n",
      "trying 8432_22.89_1.79_-1.83_47.81\n",
      "trying 8433_22.89_1.79_-1.83_51.81\n",
      "trying 8441_22.89_1.79_-1.63_39.81\n",
      "trying 8442_22.89_1.79_-1.63_43.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accepted with 403.08388383231704 and 445.396676590306\n",
      "trying 8443_22.89_1.79_-1.63_47.81\n",
      "trying 8452_22.89_1.79_-1.43_39.81\n",
      "accepted with 508.5820325273089 and 352.34690649522054\n",
      "trying 8453_22.89_1.79_-1.43_43.81\n",
      "accepted with 396.5168769606871 and 447.8269273399155\n",
      "trying 8454_22.89_1.79_-1.43_47.81\n",
      "trying 8463_22.89_1.79_-1.23_39.81\n",
      "accepted with 505.66157696845676 and 358.3048787851103\n",
      "trying 8464_22.89_1.79_-1.23_43.81\n",
      "accepted with 397.0973036567302 and 456.09015377689775\n",
      "trying 8465_22.89_1.79_-1.23_47.81\n",
      "trying 8494_23.49_-7.21_-2.83_31.81\n",
      "trying 8495_23.49_-7.21_-2.83_35.81\n",
      "accepted with 399.21887935334144 and 366.9247962220679\n",
      "trying 8496_23.49_-7.21_-2.83_39.81\n",
      "trying 8505_23.49_-7.21_-2.63_31.81\n",
      "trying 8506_23.49_-7.21_-2.63_35.81\n",
      "trying 8507_23.49_-7.21_-2.63_39.81\n",
      "trying 8508_23.49_-7.21_-2.63_43.81\n",
      "trying 8516_23.49_-7.21_-2.43_31.81\n",
      "trying 8517_23.49_-7.21_-2.43_35.81\n",
      "trying 8518_23.49_-7.21_-2.43_39.81\n",
      "trying 8519_23.49_-7.21_-2.43_43.81\n",
      "trying 8520_23.49_-7.21_-2.43_47.81\n",
      "trying 8521_23.49_-7.21_-2.43_51.81\n",
      "trying 8527_23.49_-7.21_-2.23_31.81\n",
      "trying 8528_23.49_-7.21_-2.23_35.81\n",
      "trying 8529_23.49_-7.21_-2.23_39.81\n",
      "trying 8530_23.49_-7.21_-2.23_43.81\n",
      "trying 8531_23.49_-7.21_-2.23_47.81\n",
      "trying 8532_23.49_-7.21_-2.23_51.81\n",
      "trying 8538_23.49_-7.21_-2.03_31.81\n",
      "trying 8539_23.49_-7.21_-2.03_35.81\n",
      "trying 8540_23.49_-7.21_-2.03_39.81\n",
      "trying 8541_23.49_-7.21_-2.03_43.81\n",
      "trying 8542_23.49_-7.21_-2.03_47.81\n",
      "trying 8543_23.49_-7.21_-2.03_51.81\n",
      "trying 8544_23.49_-7.21_-2.03_55.81\n",
      "trying 8549_23.49_-7.21_-1.83_31.81\n",
      "trying 8550_23.49_-7.21_-1.83_35.81\n",
      "trying 8551_23.49_-7.21_-1.83_39.81\n",
      "trying 8552_23.49_-7.21_-1.83_43.81\n",
      "trying 8553_23.49_-7.21_-1.83_47.81\n",
      "trying 8554_23.49_-7.21_-1.83_51.81\n",
      "trying 8555_23.49_-7.21_-1.83_55.81\n",
      "trying 8561_23.49_-7.21_-1.63_35.81\n",
      "trying 8562_23.49_-7.21_-1.63_39.81\n",
      "trying 8563_23.49_-7.21_-1.63_43.81\n",
      "trying 8564_23.49_-7.21_-1.63_47.81\n",
      "trying 8565_23.49_-7.21_-1.63_51.81\n",
      "trying 8566_23.49_-7.21_-1.63_55.81\n",
      "trying 8572_23.49_-7.21_-1.43_35.81\n",
      "trying 8573_23.49_-7.21_-1.43_39.81\n",
      "trying 8574_23.49_-7.21_-1.43_43.81\n",
      "trying 8575_23.49_-7.21_-1.43_47.81\n",
      "trying 8576_23.49_-7.21_-1.43_51.81\n",
      "trying 8584_23.49_-7.21_-1.23_39.81\n",
      "trying 8585_23.49_-7.21_-1.23_43.81\n",
      "trying 8586_23.49_-7.21_-1.23_47.81\n",
      "trying 8587_23.49_-7.21_-1.23_51.81\n",
      "trying 8616_23.49_-6.21_-2.83_35.81\n",
      "accepted with 411.00277620042925 and 354.3712091748521\n",
      "trying 8617_23.49_-6.21_-2.83_39.81\n",
      "trying 8626_23.49_-6.21_-2.63_31.81\n",
      "trying 8627_23.49_-6.21_-2.63_35.81\n",
      "trying 8628_23.49_-6.21_-2.63_39.81\n",
      "accepted with 369.4935640581343 and 389.72760046956137\n",
      "trying 8629_23.49_-6.21_-2.63_43.81\n",
      "trying 8637_23.49_-6.21_-2.43_31.81\n",
      "trying 8638_23.49_-6.21_-2.43_35.81\n",
      "trying 8639_23.49_-6.21_-2.43_39.81\n",
      "trying 8640_23.49_-6.21_-2.43_43.81\n",
      "trying 8641_23.49_-6.21_-2.43_47.81\n",
      "trying 8642_23.49_-6.21_-2.43_51.81\n",
      "trying 8648_23.49_-6.21_-2.23_31.81\n",
      "trying 8649_23.49_-6.21_-2.23_35.81\n",
      "trying 8650_23.49_-6.21_-2.23_39.81\n",
      "trying 8651_23.49_-6.21_-2.23_43.81\n",
      "trying 8652_23.49_-6.21_-2.23_47.81\n",
      "trying 8653_23.49_-6.21_-2.23_51.81\n",
      "trying 8659_23.49_-6.21_-2.03_31.81\n",
      "trying 8660_23.49_-6.21_-2.03_35.81\n",
      "trying 8661_23.49_-6.21_-2.03_39.81\n",
      "trying 8662_23.49_-6.21_-2.03_43.81\n",
      "trying 8663_23.49_-6.21_-2.03_47.81\n",
      "trying 8664_23.49_-6.21_-2.03_51.81\n",
      "trying 8665_23.49_-6.21_-2.03_55.81\n",
      "trying 8670_23.49_-6.21_-1.83_31.81\n",
      "trying 8671_23.49_-6.21_-1.83_35.81\n",
      "trying 8672_23.49_-6.21_-1.83_39.81\n",
      "trying 8673_23.49_-6.21_-1.83_43.81\n",
      "trying 8674_23.49_-6.21_-1.83_47.81\n",
      "trying 8675_23.49_-6.21_-1.83_51.81\n",
      "trying 8676_23.49_-6.21_-1.83_55.81\n",
      "trying 8682_23.49_-6.21_-1.63_35.81\n",
      "trying 8683_23.49_-6.21_-1.63_39.81\n",
      "trying 8684_23.49_-6.21_-1.63_43.81\n",
      "accepted with 353.447030186353 and 351.8118428456901\n",
      "trying 8685_23.49_-6.21_-1.63_47.81\n",
      "trying 8686_23.49_-6.21_-1.63_51.81\n",
      "trying 8693_23.49_-6.21_-1.43_35.81\n",
      "trying 8694_23.49_-6.21_-1.43_39.81\n",
      "trying 8695_23.49_-6.21_-1.43_43.81\n",
      "trying 8696_23.49_-6.21_-1.43_47.81\n",
      "trying 8697_23.49_-6.21_-1.43_51.81\n",
      "trying 8704_23.49_-6.21_-1.23_35.81\n",
      "trying 8705_23.49_-6.21_-1.23_39.81\n",
      "trying 8706_23.49_-6.21_-1.23_43.81\n",
      "accepted with 406.76786276127496 and 351.04685339901243\n",
      "trying 8707_23.49_-6.21_-1.23_47.81\n",
      "trying 8708_23.49_-6.21_-1.23_51.81\n",
      "trying 8737_23.49_-5.21_-2.83_35.81\n",
      "trying 8738_23.49_-5.21_-2.83_39.81\n",
      "accepted with 365.9001095397125 and 419.96290872922145\n",
      "trying 8739_23.49_-5.21_-2.83_43.81\n",
      "trying 8747_23.49_-5.21_-2.63_31.81\n",
      "trying 8748_23.49_-5.21_-2.63_35.81\n",
      "trying 8749_23.49_-5.21_-2.63_39.81\n",
      "accepted with 397.41980171740397 and 383.0647866575264\n",
      "trying 8750_23.49_-5.21_-2.63_43.81\n",
      "trying 8751_23.49_-5.21_-2.63_47.81\n",
      "trying 8758_23.49_-5.21_-2.43_31.81\n",
      "trying 8759_23.49_-5.21_-2.43_35.81\n",
      "trying 8760_23.49_-5.21_-2.43_39.81\n",
      "trying 8761_23.49_-5.21_-2.43_43.81\n",
      "trying 8762_23.49_-5.21_-2.43_47.81\n",
      "trying 8763_23.49_-5.21_-2.43_51.81\n",
      "trying 8769_23.49_-5.21_-2.23_31.81\n",
      "trying 8770_23.49_-5.21_-2.23_35.81\n",
      "trying 8771_23.49_-5.21_-2.23_39.81\n",
      "trying 8772_23.49_-5.21_-2.23_43.81\n",
      "trying 8773_23.49_-5.21_-2.23_47.81\n",
      "trying 8774_23.49_-5.21_-2.23_51.81\n",
      "trying 8780_23.49_-5.21_-2.03_31.81\n",
      "trying 8781_23.49_-5.21_-2.03_35.81\n",
      "trying 8782_23.49_-5.21_-2.03_39.81\n",
      "trying 8783_23.49_-5.21_-2.03_43.81\n",
      "accepted with 350.2771631988817 and 391.96643126383333\n",
      "trying 8784_23.49_-5.21_-2.03_47.81\n",
      "trying 8785_23.49_-5.21_-2.03_51.81\n",
      "trying 8791_23.49_-5.21_-1.83_31.81\n",
      "trying 8792_23.49_-5.21_-1.83_35.81\n",
      "trying 8793_23.49_-5.21_-1.83_39.81\n",
      "trying 8794_23.49_-5.21_-1.83_43.81\n",
      "trying 8795_23.49_-5.21_-1.83_47.81\n",
      "trying 8796_23.49_-5.21_-1.83_51.81\n",
      "trying 8803_23.49_-5.21_-1.63_35.81\n",
      "trying 8804_23.49_-5.21_-1.63_39.81\n",
      "trying 8805_23.49_-5.21_-1.63_43.81\n",
      "accepted with 364.6528507141229 and 372.3079268695219\n",
      "trying 8806_23.49_-5.21_-1.63_47.81\n",
      "trying 8807_23.49_-5.21_-1.63_51.81\n",
      "trying 8814_23.49_-5.21_-1.43_35.81\n",
      "trying 8815_23.49_-5.21_-1.43_39.81\n",
      "trying 8816_23.49_-5.21_-1.43_43.81\n",
      "accepted with 382.49376146838677 and 374.61934784663663\n",
      "trying 8817_23.49_-5.21_-1.43_47.81\n",
      "trying 8818_23.49_-5.21_-1.43_51.81\n",
      "trying 8826_23.49_-5.21_-1.23_39.81\n",
      "trying 8827_23.49_-5.21_-1.23_43.81\n",
      "accepted with 405.61641087609314 and 365.911861423343\n",
      "trying 8828_23.49_-5.21_-1.23_47.81\n",
      "trying 8829_23.49_-5.21_-1.23_51.81\n",
      "trying 8858_23.49_-4.21_-2.83_35.81\n",
      "trying 8859_23.49_-4.21_-2.83_39.81\n",
      "accepted with 394.86043538824197 and 412.5304047170557\n",
      "trying 8860_23.49_-4.21_-2.83_43.81\n",
      "trying 8868_23.49_-4.21_-2.63_31.81\n",
      "trying 8869_23.49_-4.21_-2.63_35.81\n",
      "trying 8870_23.49_-4.21_-2.63_39.81\n",
      "accepted with 423.0487206599182 and 374.61229671645833\n",
      "trying 8871_23.49_-4.21_-2.63_43.81\n",
      "trying 8872_23.49_-4.21_-2.63_47.81\n",
      "trying 8879_23.49_-4.21_-2.43_31.81\n",
      "trying 8880_23.49_-4.21_-2.43_35.81\n",
      "trying 8881_23.49_-4.21_-2.43_39.81\n",
      "trying 8882_23.49_-4.21_-2.43_43.81\n",
      "trying 8883_23.49_-4.21_-2.43_47.81\n",
      "trying 8884_23.49_-4.21_-2.43_51.81\n",
      "trying 8890_23.49_-4.21_-2.23_31.81\n",
      "trying 8891_23.49_-4.21_-2.23_35.81\n",
      "trying 8892_23.49_-4.21_-2.23_39.81\n",
      "trying 8893_23.49_-4.21_-2.23_43.81\n",
      "accepted with 355.4029469873849 and 421.179403217865\n",
      "trying 8894_23.49_-4.21_-2.23_47.81\n",
      "trying 8895_23.49_-4.21_-2.23_51.81\n",
      "trying 8901_23.49_-4.21_-2.03_31.81\n",
      "trying 8902_23.49_-4.21_-2.03_35.81\n",
      "trying 8903_23.49_-4.21_-2.03_39.81\n",
      "trying 8904_23.49_-4.21_-2.03_43.81\n",
      "accepted with 361.29136984583874 and 398.12395286486844\n",
      "trying 8905_23.49_-4.21_-2.03_47.81\n",
      "trying 8906_23.49_-4.21_-2.03_51.81\n",
      "trying 8907_23.49_-4.21_-2.03_55.81\n",
      "trying 8913_23.49_-4.21_-1.83_35.81\n",
      "trying 8914_23.49_-4.21_-1.83_39.81\n",
      "trying 8915_23.49_-4.21_-1.83_43.81\n",
      "accepted with 365.6521641876625 and 399.9159793706276\n",
      "trying 8916_23.49_-4.21_-1.83_47.81\n",
      "trying 8917_23.49_-4.21_-1.83_51.81\n",
      "trying 8924_23.49_-4.21_-1.63_35.81\n",
      "trying 8925_23.49_-4.21_-1.63_39.81\n",
      "trying 8926_23.49_-4.21_-1.63_43.81\n",
      "accepted with 375.7421918461232 and 396.90510799950334\n",
      "trying 8927_23.49_-4.21_-1.63_47.81\n",
      "trying 8928_23.49_-4.21_-1.63_51.81\n",
      "trying 8935_23.49_-4.21_-1.43_35.81\n",
      "trying 8936_23.49_-4.21_-1.43_39.81\n",
      "trying 8937_23.49_-4.21_-1.43_43.81\n",
      "accepted with 392.7429786686662 and 389.7370019764667\n",
      "trying 8938_23.49_-4.21_-1.43_47.81\n",
      "trying 8939_23.49_-4.21_-1.43_51.81\n",
      "trying 8947_23.49_-4.21_-1.23_39.81\n",
      "trying 8948_23.49_-4.21_-1.23_43.81\n",
      "accepted with 413.0860399807034 and 387.17998602403077\n",
      "trying 8949_23.49_-4.21_-1.23_47.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying 8950_23.49_-4.21_-1.23_51.81\n",
      "trying 8979_23.49_-3.21_-2.83_35.81\n",
      "trying 8980_23.49_-3.21_-2.83_39.81\n",
      "accepted with 419.2026200359978 and 406.3893357531024\n",
      "trying 8981_23.49_-3.21_-2.83_43.81\n",
      "trying 8982_23.49_-3.21_-2.83_47.81\n",
      "trying 8990_23.49_-3.21_-2.63_35.81\n",
      "trying 8991_23.49_-3.21_-2.63_39.81\n",
      "accepted with 447.64355141317174 and 356.6779293985146\n",
      "trying 8992_23.49_-3.21_-2.63_43.81\n",
      "trying 8993_23.49_-3.21_-2.63_47.81\n",
      "trying 8994_23.49_-3.21_-2.63_51.81\n",
      "trying 9001_23.49_-3.21_-2.43_35.81\n",
      "trying 9002_23.49_-3.21_-2.43_39.81\n",
      "trying 9003_23.49_-3.21_-2.43_43.81\n",
      "accepted with 377.9531051293816 and 452.5096379659981\n",
      "trying 9004_23.49_-3.21_-2.43_47.81\n",
      "trying 9005_23.49_-3.21_-2.43_51.81\n",
      "trying 9012_23.49_-3.21_-2.23_35.81\n",
      "trying 9013_23.49_-3.21_-2.23_39.81\n",
      "trying 9014_23.49_-3.21_-2.23_43.81\n",
      "accepted with 379.2374890474148 and 415.09682217639966\n",
      "trying 9015_23.49_-3.21_-2.23_47.81\n",
      "trying 9016_23.49_-3.21_-2.23_51.81\n",
      "trying 9017_23.49_-3.21_-2.23_55.81\n",
      "trying 9023_23.49_-3.21_-2.03_35.81\n",
      "trying 9024_23.49_-3.21_-2.03_39.81\n",
      "trying 9025_23.49_-3.21_-2.03_43.81\n",
      "accepted with 373.08466819983096 and 409.4002071242285\n",
      "trying 9026_23.49_-3.21_-2.03_47.81\n",
      "trying 9027_23.49_-3.21_-2.03_51.81\n",
      "trying 9028_23.49_-3.21_-2.03_55.81\n",
      "trying 9034_23.49_-3.21_-1.83_35.81\n",
      "trying 9035_23.49_-3.21_-1.83_39.81\n",
      "trying 9036_23.49_-3.21_-1.83_43.81\n",
      "accepted with 371.54058704611816 and 411.00277620043016\n",
      "trying 9037_23.49_-3.21_-1.83_47.81\n",
      "trying 9038_23.49_-3.21_-1.83_51.81\n",
      "trying 9039_23.49_-3.21_-1.83_55.81\n",
      "trying 9045_23.49_-3.21_-1.63_35.81\n",
      "trying 9046_23.49_-3.21_-1.63_39.81\n",
      "trying 9047_23.49_-3.21_-1.63_43.81\n",
      "accepted with 379.32389448091453 and 413.56684328304345\n",
      "trying 9048_23.49_-3.21_-1.63_47.81\n",
      "trying 9049_23.49_-3.21_-1.63_51.81\n",
      "trying 9056_23.49_-3.21_-1.43_35.81\n",
      "trying 9057_23.49_-3.21_-1.43_39.81\n",
      "trying 9058_23.49_-3.21_-1.43_43.81\n",
      "accepted with 393.8982470071469 and 404.0873162828939\n",
      "trying 9059_23.49_-3.21_-1.43_47.81\n",
      "trying 9060_23.49_-3.21_-1.43_51.81\n",
      "trying 9068_23.49_-3.21_-1.23_39.81\n",
      "trying 9069_23.49_-3.21_-1.23_43.81\n",
      "accepted with 412.667153203206 and 399.9909199301974\n",
      "trying 9070_23.49_-3.21_-1.23_47.81\n",
      "trying 9071_23.49_-3.21_-1.23_51.81\n",
      "trying 9101_23.49_-2.21_-2.83_39.81\n",
      "accepted with 449.1829318134314 and 370.7708968459865\n",
      "trying 9102_23.49_-2.21_-2.83_43.81\n",
      "accepted with 363.85308655172685 and 457.6330713777743\n",
      "trying 9111_23.49_-2.21_-2.63_35.81\n",
      "trying 9112_23.49_-2.21_-2.63_39.81\n",
      "trying 9113_23.49_-2.21_-2.63_43.81\n",
      "accepted with 372.3149779996993 and 449.6952751546087\n",
      "trying 9114_23.49_-2.21_-2.63_47.81\n",
      "trying 9115_23.49_-2.21_-2.63_51.81\n",
      "trying 9122_23.49_-2.21_-2.43_35.81\n",
      "trying 9123_23.49_-2.21_-2.43_39.81\n",
      "trying 9124_23.49_-2.21_-2.43_43.81\n",
      "accepted with 392.57016780166214 and 443.0324613425719\n",
      "trying 9125_23.49_-2.21_-2.43_47.81\n",
      "trying 9126_23.49_-2.21_-2.43_51.81\n",
      "trying 9133_23.49_-2.21_-2.23_35.81\n",
      "trying 9134_23.49_-2.21_-2.23_39.81\n",
      "trying 9135_23.49_-2.21_-2.23_43.81\n",
      "accepted with 392.56546704821085 and 426.3754268124858\n",
      "trying 9136_23.49_-2.21_-2.23_47.81\n",
      "trying 9137_23.49_-2.21_-2.23_51.81\n",
      "trying 9138_23.49_-2.21_-2.23_55.81\n",
      "trying 9144_23.49_-2.21_-2.03_35.81\n",
      "trying 9145_23.49_-2.21_-2.03_39.81\n",
      "trying 9146_23.49_-2.21_-2.03_43.81\n",
      "accepted with 373.5970115410073 and 425.8654338480337\n",
      "trying 9147_23.49_-2.21_-2.03_47.81\n",
      "trying 9148_23.49_-2.21_-2.03_51.81\n",
      "trying 9149_23.49_-2.21_-2.03_55.81\n",
      "trying 9155_23.49_-2.21_-1.83_35.81\n",
      "trying 9156_23.49_-2.21_-1.83_39.81\n",
      "trying 9157_23.49_-2.21_-1.83_43.81\n",
      "accepted with 380.2551245995901 and 424.8383967889522\n",
      "trying 9158_23.49_-2.21_-1.83_47.81\n",
      "trying 9159_23.49_-2.21_-1.83_51.81\n",
      "trying 9160_23.49_-2.21_-1.83_55.81\n",
      "trying 9166_23.49_-2.21_-1.63_35.81\n",
      "trying 9167_23.49_-2.21_-1.63_39.81\n",
      "trying 9168_23.49_-2.21_-1.63_43.81\n",
      "accepted with 394.21897646751313 and 416.8958998123353\n",
      "trying 9169_23.49_-2.21_-1.63_47.81\n",
      "trying 9170_23.49_-2.21_-1.63_51.81\n",
      "trying 9178_23.49_-2.21_-1.43_39.81\n",
      "trying 9179_23.49_-2.21_-1.43_43.81\n",
      "accepted with 399.6298307005063 and 413.82183976526903\n",
      "trying 9180_23.49_-2.21_-1.43_47.81\n",
      "trying 9181_23.49_-2.21_-1.43_51.81\n",
      "trying 9189_23.49_-2.21_-1.23_39.81\n",
      "trying 9190_23.49_-2.21_-1.23_43.81\n",
      "accepted with 409.49728621573286 and 413.56684328304345\n",
      "trying 9191_23.49_-2.21_-1.23_47.81\n",
      "trying 9192_23.49_-2.21_-1.23_51.81\n",
      "trying 9223_23.49_-1.21_-2.83_43.81\n",
      "accepted with 374.6240486000888 and 426.3707260590327\n",
      "trying 9224_23.49_-1.21_-2.83_47.81\n",
      "trying 9233_23.49_-1.21_-2.63_39.81\n",
      "trying 9234_23.49_-1.21_-2.63_43.81\n",
      "accepted with 383.0882904247883 and 421.7643367418832\n",
      "trying 9235_23.49_-1.21_-2.63_47.81\n",
      "trying 9243_23.49_-1.21_-2.43_35.81\n",
      "trying 9244_23.49_-1.21_-2.43_39.81\n",
      "trying 9245_23.49_-1.21_-2.43_43.81\n",
      "accepted with 404.35641502547514 and 427.91480721274274\n",
      "trying 9246_23.49_-1.21_-2.43_47.81\n",
      "trying 9247_23.49_-1.21_-2.43_51.81\n",
      "trying 9254_23.49_-1.21_-2.23_35.81\n",
      "trying 9255_23.49_-1.21_-2.23_39.81\n",
      "trying 9256_23.49_-1.21_-2.23_43.81\n",
      "accepted with 404.6067107542467 and 426.1204303302584\n",
      "trying 9257_23.49_-1.21_-2.23_47.81\n",
      "trying 9258_23.49_-1.21_-2.23_51.81\n",
      "trying 9265_23.49_-1.21_-2.03_35.81\n",
      "trying 9266_23.49_-1.21_-2.03_39.81\n",
      "trying 9267_23.49_-1.21_-2.03_43.81\n",
      "accepted with 382.5665455767039 and 423.046370283193\n",
      "trying 9268_23.49_-1.21_-2.03_47.81\n",
      "trying 9269_23.49_-1.21_-2.03_51.81\n",
      "trying 9276_23.49_-1.21_-1.83_35.81\n",
      "trying 9277_23.49_-1.21_-1.83_39.81\n",
      "trying 9278_23.49_-1.21_-1.83_43.81\n",
      "accepted with 386.15294896494834 and 428.4295009306479\n",
      "trying 9279_23.49_-1.21_-1.83_47.81\n",
      "trying 9280_23.49_-1.21_-1.83_51.81\n",
      "trying 9287_23.49_-1.21_-1.63_35.81\n",
      "trying 9288_23.49_-1.21_-1.63_39.81\n",
      "trying 9289_23.49_-1.21_-1.63_43.81\n",
      "accepted with 393.83486440573324 and 430.22622818985747\n",
      "trying 9290_23.49_-1.21_-1.63_47.81\n",
      "trying 9291_23.49_-1.21_-1.63_51.81\n",
      "trying 9298_23.49_-1.21_-1.43_35.81\n",
      "trying 9299_23.49_-1.21_-1.43_39.81\n",
      "trying 9300_23.49_-1.21_-1.43_43.81\n",
      "accepted with 399.24571863872734 and 429.20389188422814\n",
      "trying 9301_23.49_-1.21_-1.43_47.81\n",
      "trying 9302_23.49_-1.21_-1.43_51.81\n",
      "trying 9310_23.49_-1.21_-1.23_39.81\n",
      "trying 9311_23.49_-1.21_-1.23_43.81\n",
      "accepted with 404.5654666847686 and 428.6844974128726\n",
      "trying 9312_23.49_-1.21_-1.23_47.81\n",
      "trying 9344_23.49_-0.21_-2.83_43.81\n",
      "accepted with 430.73622115430953 and 401.76649379887385\n",
      "trying 9354_23.49_-0.21_-2.63_39.81\n",
      "trying 9355_23.49_-0.21_-2.63_43.81\n",
      "accepted with 423.9212689306305 and 410.74072858802356\n",
      "trying 9356_23.49_-0.21_-2.63_47.81\n",
      "trying 9357_23.49_-0.21_-2.63_51.81\n",
      "trying 9364_23.49_-0.21_-2.43_35.81\n",
      "trying 9365_23.49_-0.21_-2.43_39.81\n",
      "trying 9366_23.49_-0.21_-2.43_43.81\n",
      "accepted with 424.52706883549035 and 414.83712494071733\n",
      "trying 9367_23.49_-0.21_-2.43_47.81\n",
      "trying 9368_23.49_-0.21_-2.43_51.81\n",
      "trying 9375_23.49_-0.21_-2.23_35.81\n",
      "trying 9376_23.49_-0.21_-2.23_39.81\n",
      "trying 9377_23.49_-0.21_-2.23_43.81\n",
      "accepted with 413.69037380898953 and 421.7619863651589\n",
      "trying 9378_23.49_-0.21_-2.23_47.81\n",
      "trying 9379_23.49_-0.21_-2.23_51.81\n",
      "trying 9386_23.49_-0.21_-2.03_35.81\n",
      "trying 9387_23.49_-0.21_-2.03_39.81\n",
      "trying 9388_23.49_-0.21_-2.03_43.81\n",
      "accepted with 404.4705440445168 and 427.4001134948385\n",
      "trying 9389_23.49_-0.21_-2.03_47.81\n",
      "trying 9390_23.49_-0.21_-2.03_51.81\n",
      "trying 9397_23.49_-0.21_-1.83_35.81\n",
      "trying 9398_23.49_-0.21_-1.83_39.81\n",
      "trying 9399_23.49_-0.21_-1.83_43.81\n",
      "accepted with 395.0163902531831 and 427.4348882105587\n",
      "trying 9400_23.49_-0.21_-1.83_47.81\n",
      "trying 9401_23.49_-0.21_-1.83_51.81\n",
      "trying 9408_23.49_-0.21_-1.63_35.81\n",
      "trying 9409_23.49_-0.21_-1.63_39.81\n",
      "trying 9410_23.49_-0.21_-1.63_43.81\n",
      "accepted with 390.3719915434349 and 429.74630918767343\n",
      "trying 9411_23.49_-0.21_-1.63_47.81\n",
      "trying 9412_23.49_-0.21_-1.63_51.81\n",
      "trying 9419_23.49_-0.21_-1.43_35.81\n",
      "trying 9420_23.49_-0.21_-1.43_39.81\n",
      "trying 9421_23.49_-0.21_-1.43_43.81\n",
      "accepted with 387.5552783553221 and 434.2029104699059\n",
      "trying 9422_23.49_-0.21_-1.43_47.81\n",
      "trying 9431_23.49_-0.21_-1.23_39.81\n",
      "trying 9432_23.49_-0.21_-1.23_43.81\n",
      "accepted with 395.11366327016003 and 430.3211508301101\n",
      "trying 9433_23.49_-0.21_-1.23_47.81\n",
      "trying 9465_23.49_0.79_-2.83_43.81\n",
      "accepted with 468.6210205157604 and 377.93900286902317\n",
      "trying 9474_23.49_0.79_-2.63_35.81\n",
      "trying 9475_23.49_0.79_-2.63_39.81\n",
      "trying 9476_23.49_0.79_-2.63_43.81\n",
      "accepted with 445.14109833166367 and 382.5524433163491\n",
      "trying 9477_23.49_0.79_-2.63_47.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accepted with 369.42459640311336 and 486.57694458922197\n",
      "trying 9478_23.49_0.79_-2.63_51.81\n",
      "trying 9485_23.49_0.79_-2.43_35.81\n",
      "trying 9486_23.49_0.79_-2.43_39.81\n",
      "trying 9487_23.49_0.79_-2.43_43.81\n",
      "accepted with 441.2316151063269 and 405.61494479952216\n",
      "trying 9488_23.49_0.79_-2.43_47.81\n",
      "trying 9489_23.49_0.79_-2.43_51.81\n",
      "trying 9496_23.49_0.79_-2.23_35.81\n",
      "trying 9497_23.49_0.79_-2.23_39.81\n",
      "trying 9498_23.49_0.79_-2.23_43.81\n",
      "accepted with 430.9570246972344 and 420.22260596490014\n",
      "trying 9499_23.49_0.79_-2.23_47.81\n",
      "trying 9500_23.49_0.79_-2.23_51.81\n",
      "trying 9507_23.49_0.79_-2.03_35.81\n",
      "trying 9508_23.49_0.79_-2.03_39.81\n",
      "trying 9509_23.49_0.79_-2.03_43.81\n",
      "accepted with 412.59671947161223 and 430.47417354190566\n",
      "trying 9510_23.49_0.79_-2.03_47.81\n",
      "trying 9511_23.49_0.79_-2.03_51.81\n",
      "trying 9518_23.49_0.79_-1.83_35.81\n",
      "trying 9519_23.49_0.79_-1.83_39.81\n",
      "trying 9520_23.49_0.79_-1.83_43.81\n",
      "accepted with 399.69232900176576 and 420.8702317156549\n",
      "trying 9521_23.49_0.79_-1.83_47.81\n",
      "trying 9522_23.49_0.79_-1.83_51.81\n",
      "trying 9529_23.49_0.79_-1.63_35.81\n",
      "trying 9530_23.49_0.79_-1.63_39.81\n",
      "trying 9531_23.49_0.79_-1.63_43.81\n",
      "accepted with 390.56360542424954 and 425.0329428229079\n",
      "trying 9532_23.49_0.79_-1.63_47.81\n",
      "trying 9533_23.49_0.79_-1.63_51.81\n",
      "trying 9540_23.49_0.79_-1.43_35.81\n",
      "trying 9541_23.49_0.79_-1.43_39.81\n",
      "trying 9542_23.49_0.79_-1.43_43.81\n",
      "accepted with 382.5854494317573 and 435.89031030477054\n",
      "trying 9543_23.49_0.79_-1.43_47.81\n",
      "trying 9552_23.49_0.79_-1.23_39.81\n",
      "trying 9553_23.49_0.79_-1.23_43.81\n",
      "accepted with 387.070658599685 and 437.7077100193437\n",
      "trying 9554_23.49_0.79_-1.23_47.81\n",
      "trying 9586_23.49_1.79_-2.83_43.81\n",
      "trying 9587_23.49_1.79_-2.83_47.81\n",
      "accepted with 415.82996906049993 and 415.8547604928963\n",
      "trying 9596_23.49_1.79_-2.63_39.81\n",
      "trying 9597_23.49_1.79_-2.63_43.81\n",
      "accepted with 469.6068135053629 and 364.3630795161798\n",
      "trying 9598_23.49_1.79_-2.63_47.81\n",
      "accepted with 390.42743871451785 and 467.3628941066954\n",
      "trying 9599_23.49_1.79_-2.63_51.81\n",
      "trying 9606_23.49_1.79_-2.43_35.81\n",
      "trying 9607_23.49_1.79_-2.43_39.81\n",
      "trying 9608_23.49_1.79_-2.43_43.81\n",
      "accepted with 460.4241088333356 and 378.7063426924278\n",
      "trying 9609_23.49_1.79_-2.43_47.81\n",
      "trying 9610_23.49_1.79_-2.43_51.81\n",
      "trying 9611_23.49_1.79_-2.43_55.81\n",
      "trying 9617_23.49_1.79_-2.23_35.81\n",
      "trying 9618_23.49_1.79_-2.23_39.81\n",
      "trying 9619_23.49_1.79_-2.23_43.81\n",
      "accepted with 441.9773981742137 and 399.46212395193743\n",
      "trying 9620_23.49_1.79_-2.23_47.81\n",
      "trying 9621_23.49_1.79_-2.23_51.81\n",
      "trying 9628_23.49_1.79_-2.03_35.81\n",
      "trying 9629_23.49_1.79_-2.03_39.81\n",
      "trying 9630_23.49_1.79_-2.03_43.81\n",
      "accepted with 420.5176596927131 and 418.1779333536415\n",
      "trying 9631_23.49_1.79_-2.03_47.81\n",
      "trying 9632_23.49_1.79_-2.03_51.81\n",
      "trying 9639_23.49_1.79_-1.83_35.81\n",
      "trying 9640_23.49_1.79_-1.83_39.81\n",
      "trying 9641_23.49_1.79_-1.83_43.81\n",
      "accepted with 396.39099605801493 and 419.29519229952257\n",
      "trying 9642_23.49_1.79_-1.83_47.81\n",
      "trying 9643_23.49_1.79_-1.83_51.81\n",
      "trying 9650_23.49_1.79_-1.63_35.81\n",
      "trying 9651_23.49_1.79_-1.63_39.81\n",
      "trying 9652_23.49_1.79_-1.63_43.81\n",
      "accepted with 383.5753613983934 and 421.3784560797985\n",
      "trying 9653_23.49_1.79_-1.63_47.81\n",
      "trying 9654_23.49_1.79_-1.63_51.81\n",
      "trying 9661_23.49_1.79_-1.43_35.81\n",
      "trying 9662_23.49_1.79_-1.43_39.81\n",
      "trying 9663_23.49_1.79_-1.43_43.81\n",
      "accepted with 375.3191860915913 and 430.33535393171314\n",
      "trying 9664_23.49_1.79_-1.43_47.81\n",
      "trying 9665_23.49_1.79_-1.43_51.81\n",
      "trying 9673_23.49_1.79_-1.23_39.81\n",
      "trying 9674_23.49_1.79_-1.23_43.81\n",
      "accepted with 374.9383087066926 and 434.59799095640574\n",
      "trying 9675_23.49_1.79_-1.23_47.81\n",
      "trying 9703_24.09_-7.21_-2.83_27.81\n",
      "trying 9704_24.09_-7.21_-2.83_31.81\n",
      "trying 9705_24.09_-7.21_-2.83_35.81\n",
      "accepted with 354.1162126926256 and 365.9118614233412\n",
      "trying 9706_24.09_-7.21_-2.83_39.81\n",
      "trying 9715_24.09_-7.21_-2.63_31.81\n",
      "trying 9716_24.09_-7.21_-2.63_35.81\n",
      "trying 9717_24.09_-7.21_-2.63_39.81\n",
      "trying 9718_24.09_-7.21_-2.63_43.81\n",
      "trying 9719_24.09_-7.21_-2.63_47.81\n",
      "trying 9726_24.09_-7.21_-2.43_31.81\n",
      "trying 9727_24.09_-7.21_-2.43_35.81\n",
      "trying 9728_24.09_-7.21_-2.43_39.81\n",
      "trying 9729_24.09_-7.21_-2.43_43.81\n",
      "trying 9730_24.09_-7.21_-2.43_47.81\n",
      "trying 9731_24.09_-7.21_-2.43_51.81\n",
      "trying 9737_24.09_-7.21_-2.23_31.81\n",
      "trying 9738_24.09_-7.21_-2.23_35.81\n",
      "trying 9739_24.09_-7.21_-2.23_39.81\n",
      "trying 9740_24.09_-7.21_-2.23_43.81\n",
      "trying 9741_24.09_-7.21_-2.23_47.81\n",
      "trying 9742_24.09_-7.21_-2.23_51.81\n",
      "trying 9743_24.09_-7.21_-2.23_55.81\n",
      "trying 9748_24.09_-7.21_-2.03_31.81\n",
      "trying 9749_24.09_-7.21_-2.03_35.81\n",
      "trying 9750_24.09_-7.21_-2.03_39.81\n",
      "trying 9751_24.09_-7.21_-2.03_43.81\n",
      "trying 9752_24.09_-7.21_-2.03_47.81\n",
      "trying 9753_24.09_-7.21_-2.03_51.81\n",
      "trying 9754_24.09_-7.21_-2.03_55.81\n",
      "trying 9759_24.09_-7.21_-1.83_31.81\n",
      "trying 9760_24.09_-7.21_-1.83_35.81\n",
      "trying 9761_24.09_-7.21_-1.83_39.81\n",
      "trying 9762_24.09_-7.21_-1.83_43.81\n",
      "trying 9763_24.09_-7.21_-1.83_47.81\n",
      "trying 9764_24.09_-7.21_-1.83_51.81\n",
      "trying 9765_24.09_-7.21_-1.83_55.81\n",
      "trying 9770_24.09_-7.21_-1.63_31.81\n",
      "trying 9771_24.09_-7.21_-1.63_35.81\n",
      "trying 9772_24.09_-7.21_-1.63_39.81\n",
      "trying 9773_24.09_-7.21_-1.63_43.81\n",
      "trying 9774_24.09_-7.21_-1.63_47.81\n",
      "trying 9775_24.09_-7.21_-1.63_51.81\n",
      "trying 9776_24.09_-7.21_-1.63_55.81\n",
      "trying 9782_24.09_-7.21_-1.43_35.81\n",
      "trying 9783_24.09_-7.21_-1.43_39.81\n",
      "trying 9784_24.09_-7.21_-1.43_43.81\n",
      "trying 9785_24.09_-7.21_-1.43_47.81\n",
      "trying 9786_24.09_-7.21_-1.43_51.81\n",
      "trying 9787_24.09_-7.21_-1.43_55.81\n",
      "trying 9793_24.09_-7.21_-1.23_35.81\n",
      "trying 9794_24.09_-7.21_-1.23_39.81\n",
      "trying 9795_24.09_-7.21_-1.23_43.81\n",
      "trying 9796_24.09_-7.21_-1.23_47.81\n",
      "trying 9797_24.09_-7.21_-1.23_51.81\n",
      "trying 9798_24.09_-7.21_-1.23_55.81\n",
      "trying 9814_24.09_-6.21_-3.03_31.81\n",
      "accepted with 388.9720125297881 and 371.2808898104395\n",
      "trying 9825_24.09_-6.21_-2.83_31.81\n",
      "trying 9826_24.09_-6.21_-2.83_35.81\n",
      "trying 9827_24.09_-6.21_-2.83_39.81\n",
      "trying 9836_24.09_-6.21_-2.63_31.81\n",
      "trying 9837_24.09_-6.21_-2.63_35.81\n",
      "trying 9838_24.09_-6.21_-2.63_39.81\n",
      "accepted with 356.4252832930151 and 369.7438597869077\n",
      "trying 9839_24.09_-6.21_-2.63_43.81\n",
      "trying 9840_24.09_-6.21_-2.63_47.81\n",
      "trying 9847_24.09_-6.21_-2.43_31.81\n",
      "trying 9848_24.09_-6.21_-2.43_35.81\n",
      "trying 9849_24.09_-6.21_-2.43_39.81\n",
      "trying 9850_24.09_-6.21_-2.43_43.81\n",
      "trying 9851_24.09_-6.21_-2.43_47.81\n",
      "trying 9852_24.09_-6.21_-2.43_51.81\n",
      "trying 9858_24.09_-6.21_-2.23_31.81\n",
      "trying 9859_24.09_-6.21_-2.23_35.81\n",
      "trying 9860_24.09_-6.21_-2.23_39.81\n",
      "trying 9861_24.09_-6.21_-2.23_43.81\n",
      "trying 9862_24.09_-6.21_-2.23_47.81\n",
      "trying 9863_24.09_-6.21_-2.23_51.81\n",
      "trying 9864_24.09_-6.21_-2.23_55.81\n",
      "trying 9869_24.09_-6.21_-2.03_31.81\n",
      "trying 9870_24.09_-6.21_-2.03_35.81\n",
      "trying 9871_24.09_-6.21_-2.03_39.81\n",
      "trying 9872_24.09_-6.21_-2.03_43.81\n",
      "trying 9873_24.09_-6.21_-2.03_47.81\n",
      "trying 9874_24.09_-6.21_-2.03_51.81\n",
      "trying 9875_24.09_-6.21_-2.03_55.81\n",
      "trying 9880_24.09_-6.21_-1.83_31.81\n",
      "trying 9881_24.09_-6.21_-1.83_35.81\n",
      "trying 9882_24.09_-6.21_-1.83_39.81\n",
      "trying 9883_24.09_-6.21_-1.83_43.81\n",
      "trying 9884_24.09_-6.21_-1.83_47.81\n",
      "trying 9885_24.09_-6.21_-1.83_51.81\n",
      "trying 9886_24.09_-6.21_-1.83_55.81\n",
      "trying 9891_24.09_-6.21_-1.63_31.81\n",
      "trying 9892_24.09_-6.21_-1.63_35.81\n",
      "trying 9893_24.09_-6.21_-1.63_39.81\n",
      "trying 9894_24.09_-6.21_-1.63_43.81\n",
      "trying 9895_24.09_-6.21_-1.63_47.81\n",
      "trying 9896_24.09_-6.21_-1.63_51.81\n",
      "trying 9897_24.09_-6.21_-1.63_55.81\n",
      "trying 9903_24.09_-6.21_-1.43_35.81\n",
      "trying 9904_24.09_-6.21_-1.43_39.81\n",
      "trying 9905_24.09_-6.21_-1.43_43.81\n",
      "trying 9906_24.09_-6.21_-1.43_47.81\n",
      "trying 9907_24.09_-6.21_-1.43_51.81\n",
      "trying 9914_24.09_-6.21_-1.23_35.81\n",
      "trying 9915_24.09_-6.21_-1.23_39.81\n",
      "trying 9916_24.09_-6.21_-1.23_43.81\n",
      "trying 9917_24.09_-6.21_-1.23_47.81\n",
      "trying 9918_24.09_-6.21_-1.23_51.81\n",
      "trying 9936_24.09_-5.21_-3.03_35.81\n",
      "accepted with 367.44654107014776 and 416.378855717704\n",
      "trying 9947_24.09_-5.21_-2.83_35.81\n",
      "trying 9948_24.09_-5.21_-2.83_39.81\n",
      "trying 9949_24.09_-5.21_-2.83_43.81\n",
      "trying 9957_24.09_-5.21_-2.63_31.81\n",
      "trying 9958_24.09_-5.21_-2.63_35.81\n",
      "trying 9959_24.09_-5.21_-2.63_39.81\n",
      "accepted with 377.6887071402507 and 371.2761890569891\n",
      "trying 9960_24.09_-5.21_-2.63_43.81\n",
      "trying 9961_24.09_-5.21_-2.63_47.81\n",
      "trying 9967_24.09_-5.21_-2.43_27.81\n",
      "trying 9968_24.09_-5.21_-2.43_31.81\n",
      "trying 9969_24.09_-5.21_-2.43_35.81\n",
      "trying 9970_24.09_-5.21_-2.43_39.81\n",
      "trying 9971_24.09_-5.21_-2.43_43.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying 9972_24.09_-5.21_-2.43_47.81\n",
      "trying 9973_24.09_-5.21_-2.43_51.81\n",
      "trying 9979_24.09_-5.21_-2.23_31.81\n",
      "trying 9980_24.09_-5.21_-2.23_35.81\n",
      "trying 9981_24.09_-5.21_-2.23_39.81\n",
      "trying 9982_24.09_-5.21_-2.23_43.81\n",
      "trying 9983_24.09_-5.21_-2.23_47.81\n",
      "trying 9984_24.09_-5.21_-2.23_51.81\n",
      "trying 9985_24.09_-5.21_-2.23_55.81\n",
      "trying 9990_24.09_-5.21_-2.03_31.81\n",
      "trying 9991_24.09_-5.21_-2.03_35.81\n",
      "trying 9992_24.09_-5.21_-2.03_39.81\n",
      "trying 9993_24.09_-5.21_-2.03_43.81\n",
      "trying 9994_24.09_-5.21_-2.03_47.81\n",
      "trying 9995_24.09_-5.21_-2.03_51.81\n",
      "trying 9996_24.09_-5.21_-2.03_55.81\n",
      "trying 10001_24.09_-5.21_-1.83_31.81\n",
      "trying 10002_24.09_-5.21_-1.83_35.81\n",
      "trying 10003_24.09_-5.21_-1.83_39.81\n",
      "trying 10004_24.09_-5.21_-1.83_43.81\n",
      "trying 10005_24.09_-5.21_-1.83_47.81\n",
      "trying 10006_24.09_-5.21_-1.83_51.81\n",
      "trying 10007_24.09_-5.21_-1.83_55.81\n",
      "trying 10012_24.09_-5.21_-1.63_31.81\n",
      "trying 10013_24.09_-5.21_-1.63_35.81\n",
      "trying 10014_24.09_-5.21_-1.63_39.81\n",
      "trying 10015_24.09_-5.21_-1.63_43.81\n",
      "trying 10016_24.09_-5.21_-1.63_47.81\n",
      "trying 10017_24.09_-5.21_-1.63_51.81\n",
      "trying 10018_24.09_-5.21_-1.63_55.81\n",
      "trying 10024_24.09_-5.21_-1.43_35.81\n",
      "trying 10025_24.09_-5.21_-1.43_39.81\n",
      "trying 10026_24.09_-5.21_-1.43_43.81\n",
      "accepted with 359.26736968994373 and 351.8094924689649\n",
      "trying 10027_24.09_-5.21_-1.43_47.81\n",
      "trying 10028_24.09_-5.21_-1.43_51.81\n",
      "trying 10035_24.09_-5.21_-1.23_35.81\n",
      "trying 10036_24.09_-5.21_-1.23_39.81\n",
      "trying 10037_24.09_-5.21_-1.23_43.81\n",
      "trying 10038_24.09_-5.21_-1.23_47.81\n",
      "trying 10039_24.09_-5.21_-1.23_51.81\n",
      "trying 10058_24.09_-4.21_-3.03_39.81\n",
      "trying 10068_24.09_-4.21_-2.83_35.81\n",
      "trying 10069_24.09_-4.21_-2.83_39.81\n",
      "accepted with 368.20447938664984 and 403.3105749525839\n",
      "trying 10070_24.09_-4.21_-2.83_43.81\n",
      "trying 10078_24.09_-4.21_-2.63_31.81\n",
      "trying 10079_24.09_-4.21_-2.63_35.81\n",
      "trying 10080_24.09_-4.21_-2.63_39.81\n",
      "accepted with 402.7982316114076 and 352.5744819156416\n",
      "trying 10081_24.09_-4.21_-2.63_43.81\n",
      "trying 10082_24.09_-4.21_-2.63_47.81\n",
      "trying 10089_24.09_-4.21_-2.43_31.81\n",
      "trying 10090_24.09_-4.21_-2.43_35.81\n",
      "trying 10091_24.09_-4.21_-2.43_39.81\n",
      "trying 10092_24.09_-4.21_-2.43_43.81\n",
      "trying 10093_24.09_-4.21_-2.43_47.81\n",
      "trying 10094_24.09_-4.21_-2.43_51.81\n",
      "trying 10100_24.09_-4.21_-2.23_31.81\n",
      "trying 10101_24.09_-4.21_-2.23_35.81\n",
      "trying 10102_24.09_-4.21_-2.23_39.81\n",
      "trying 10103_24.09_-4.21_-2.23_43.81\n",
      "trying 10104_24.09_-4.21_-2.23_47.81\n",
      "trying 10105_24.09_-4.21_-2.23_51.81\n",
      "trying 10106_24.09_-4.21_-2.23_55.81\n",
      "trying 10111_24.09_-4.21_-2.03_31.81\n",
      "trying 10112_24.09_-4.21_-2.03_35.81\n",
      "trying 10113_24.09_-4.21_-2.03_39.81\n",
      "trying 10114_24.09_-4.21_-2.03_43.81\n",
      "accepted with 352.5768322923668 and 386.40324469372445\n",
      "trying 10115_24.09_-4.21_-2.03_47.81\n",
      "trying 10116_24.09_-4.21_-2.03_51.81\n",
      "trying 10117_24.09_-4.21_-2.03_55.81\n",
      "trying 10122_24.09_-4.21_-1.83_31.81\n",
      "trying 10123_24.09_-4.21_-1.83_35.81\n",
      "trying 10124_24.09_-4.21_-1.83_39.81\n",
      "trying 10125_24.09_-4.21_-1.83_43.81\n",
      "trying 10126_24.09_-4.21_-1.83_47.81\n",
      "trying 10127_24.09_-4.21_-1.83_51.81\n",
      "trying 10128_24.09_-4.21_-1.83_55.81\n",
      "trying 10134_24.09_-4.21_-1.63_35.81\n",
      "trying 10135_24.09_-4.21_-1.63_39.81\n",
      "trying 10136_24.09_-4.21_-1.63_43.81\n",
      "accepted with 357.700265704143 and 378.9707406815578\n",
      "trying 10137_24.09_-4.21_-1.63_47.81\n",
      "trying 10138_24.09_-4.21_-1.63_51.81\n",
      "trying 10139_24.09_-4.21_-1.63_55.81\n",
      "trying 10145_24.09_-4.21_-1.43_35.81\n",
      "trying 10146_24.09_-4.21_-1.43_39.81\n",
      "trying 10147_24.09_-4.21_-1.43_43.81\n",
      "accepted with 377.8826713977878 and 367.4394899399722\n",
      "trying 10148_24.09_-4.21_-1.43_47.81\n",
      "trying 10149_24.09_-4.21_-1.43_51.81\n",
      "trying 10156_24.09_-4.21_-1.23_35.81\n",
      "trying 10157_24.09_-4.21_-1.23_39.81\n",
      "trying 10158_24.09_-4.21_-1.23_43.81\n",
      "accepted with 402.38316128720635 and 359.2419964811297\n",
      "trying 10159_24.09_-4.21_-1.23_47.81\n",
      "trying 10160_24.09_-4.21_-1.23_51.81\n",
      "trying 10188_24.09_-3.21_-2.83_31.81\n",
      "trying 10189_24.09_-3.21_-2.83_35.81\n",
      "trying 10190_24.09_-3.21_-2.83_39.81\n",
      "accepted with 391.26933124654624 and 394.8580850115168\n",
      "trying 10191_24.09_-3.21_-2.83_43.81\n",
      "trying 10192_24.09_-3.21_-2.83_47.81\n",
      "trying 10199_24.09_-3.21_-2.63_31.81\n",
      "trying 10200_24.09_-3.21_-2.63_35.81\n",
      "trying 10201_24.09_-3.21_-2.63_39.81\n",
      "trying 10202_24.09_-3.21_-2.63_43.81\n",
      "trying 10203_24.09_-3.21_-2.63_47.81\n",
      "trying 10204_24.09_-3.21_-2.63_51.81\n",
      "trying 10210_24.09_-3.21_-2.43_31.81\n",
      "trying 10211_24.09_-3.21_-2.43_35.81\n",
      "trying 10212_24.09_-3.21_-2.43_39.81\n",
      "trying 10213_24.09_-3.21_-2.43_43.81\n",
      "trying 10214_24.09_-3.21_-2.43_47.81\n",
      "trying 10215_24.09_-3.21_-2.43_51.81\n",
      "trying 10216_24.09_-3.21_-2.43_55.81\n",
      "trying 10221_24.09_-3.21_-2.23_31.81\n",
      "trying 10222_24.09_-3.21_-2.23_35.81\n",
      "trying 10223_24.09_-3.21_-2.23_39.81\n",
      "trying 10224_24.09_-3.21_-2.23_43.81\n",
      "accepted with 364.3748313998103 and 408.9534028357175\n",
      "trying 10225_24.09_-3.21_-2.23_47.81\n",
      "trying 10226_24.09_-3.21_-2.23_51.81\n",
      "trying 10227_24.09_-3.21_-2.23_55.81\n",
      "trying 10232_24.09_-3.21_-2.03_31.81\n",
      "trying 10233_24.09_-3.21_-2.03_35.81\n",
      "trying 10234_24.09_-3.21_-2.03_39.81\n",
      "trying 10235_24.09_-3.21_-2.03_43.81\n",
      "accepted with 361.29842097601795 and 393.3187046112589\n",
      "trying 10236_24.09_-3.21_-2.03_47.81\n",
      "trying 10237_24.09_-3.21_-2.03_51.81\n",
      "trying 10238_24.09_-3.21_-2.03_55.81\n",
      "trying 10243_24.09_-3.21_-1.83_31.81\n",
      "trying 10244_24.09_-3.21_-1.83_35.81\n",
      "trying 10245_24.09_-3.21_-1.83_39.81\n",
      "trying 10246_24.09_-3.21_-1.83_43.81\n",
      "accepted with 359.2443468578549 and 394.09074518811394\n",
      "trying 10247_24.09_-3.21_-1.83_47.81\n",
      "trying 10248_24.09_-3.21_-1.83_51.81\n",
      "trying 10249_24.09_-3.21_-1.83_55.81\n",
      "trying 10255_24.09_-3.21_-1.63_35.81\n",
      "trying 10256_24.09_-3.21_-1.63_39.81\n",
      "trying 10257_24.09_-3.21_-1.63_43.81\n",
      "accepted with 368.4712277525032 and 386.4008943169965\n",
      "trying 10258_24.09_-3.21_-1.63_47.81\n",
      "trying 10259_24.09_-3.21_-1.63_51.81\n",
      "trying 10260_24.09_-3.21_-1.63_55.81\n",
      "trying 10266_24.09_-3.21_-1.43_35.81\n",
      "trying 10267_24.09_-3.21_-1.43_39.81\n",
      "trying 10268_24.09_-3.21_-1.43_43.81\n",
      "accepted with 382.813606628597 and 373.8426065163294\n",
      "trying 10269_24.09_-3.21_-1.43_47.81\n",
      "trying 10270_24.09_-3.21_-1.43_51.81\n",
      "trying 10271_24.09_-3.21_-1.43_55.81\n",
      "trying 10277_24.09_-3.21_-1.23_35.81\n",
      "trying 10278_24.09_-3.21_-1.23_39.81\n",
      "trying 10279_24.09_-3.21_-1.23_43.81\n",
      "accepted with 384.0299071917643 and 375.64403452899205\n",
      "trying 10280_24.09_-3.21_-1.23_47.81\n",
      "trying 10281_24.09_-3.21_-1.23_51.81\n",
      "trying 10310_24.09_-2.21_-2.83_35.81\n",
      "trying 10311_24.09_-2.21_-2.83_39.81\n",
      "accepted with 420.22495634162533 and 360.5193292689828\n",
      "trying 10312_24.09_-2.21_-2.83_43.81\n",
      "trying 10313_24.09_-2.21_-2.83_47.81\n",
      "trying 10321_24.09_-2.21_-2.63_35.81\n",
      "trying 10322_24.09_-2.21_-2.63_39.81\n",
      "trying 10323_24.09_-2.21_-2.63_43.81\n",
      "trying 10324_24.09_-2.21_-2.63_47.81\n",
      "trying 10325_24.09_-2.21_-2.63_51.81\n",
      "trying 10331_24.09_-2.21_-2.43_31.81\n",
      "trying 10332_24.09_-2.21_-2.43_35.81\n",
      "trying 10333_24.09_-2.21_-2.43_39.81\n",
      "trying 10334_24.09_-2.21_-2.43_43.81\n",
      "accepted with 366.1715586590208 and 424.07105696554663\n",
      "trying 10335_24.09_-2.21_-2.43_47.81\n",
      "trying 10336_24.09_-2.21_-2.43_51.81\n",
      "trying 10337_24.09_-2.21_-2.43_55.81\n",
      "trying 10342_24.09_-2.21_-2.23_31.81\n",
      "trying 10343_24.09_-2.21_-2.23_35.81\n",
      "trying 10344_24.09_-2.21_-2.23_39.81\n",
      "trying 10345_24.09_-2.21_-2.23_43.81\n",
      "accepted with 376.1704801305259 and 403.8299694239395\n",
      "trying 10346_24.09_-2.21_-2.23_47.81\n",
      "trying 10347_24.09_-2.21_-2.23_51.81\n",
      "trying 10348_24.09_-2.21_-2.23_55.81\n",
      "trying 10353_24.09_-2.21_-2.03_31.81\n",
      "trying 10354_24.09_-2.21_-2.03_35.81\n",
      "trying 10355_24.09_-2.21_-2.03_39.81\n",
      "trying 10356_24.09_-2.21_-2.03_43.81\n",
      "accepted with 365.6568649411147 and 411.00512657715626\n",
      "trying 10357_24.09_-2.21_-2.03_47.81\n",
      "trying 10358_24.09_-2.21_-2.03_51.81\n",
      "trying 10359_24.09_-2.21_-2.03_55.81\n",
      "trying 10364_24.09_-2.21_-1.83_31.81\n",
      "trying 10365_24.09_-2.21_-1.83_35.81\n",
      "trying 10366_24.09_-2.21_-1.83_39.81\n",
      "trying 10367_24.09_-2.21_-1.83_43.81\n",
      "accepted with 354.63560716398206 and 408.44576024799335\n",
      "trying 10368_24.09_-2.21_-1.83_47.81\n",
      "trying 10369_24.09_-2.21_-1.83_51.81\n",
      "trying 10370_24.09_-2.21_-1.83_55.81\n",
      "trying 10376_24.09_-2.21_-1.63_35.81\n",
      "trying 10377_24.09_-2.21_-1.63_39.81\n",
      "trying 10378_24.09_-2.21_-1.63_43.81\n",
      "accepted with 371.12875139879816 and 401.2682527180532\n",
      "trying 10379_24.09_-2.21_-1.63_47.81\n",
      "trying 10380_24.09_-2.21_-1.63_51.81\n",
      "trying 10381_24.09_-2.21_-1.63_55.81\n",
      "trying 10387_24.09_-2.21_-1.43_35.81\n",
      "trying 10388_24.09_-2.21_-1.43_39.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying 10389_24.09_-2.21_-1.43_43.81\n",
      "accepted with 381.44046690033883 and 392.55606554130645\n",
      "trying 10390_24.09_-2.21_-1.43_47.81\n",
      "trying 10391_24.09_-2.21_-1.43_51.81\n",
      "trying 10398_24.09_-2.21_-1.23_35.81\n",
      "trying 10399_24.09_-2.21_-1.23_39.81\n",
      "trying 10400_24.09_-2.21_-1.23_43.81\n",
      "accepted with 394.14765843576424 and 387.17528527057857\n",
      "trying 10401_24.09_-2.21_-1.23_47.81\n",
      "trying 10402_24.09_-2.21_-1.23_51.81\n",
      "trying 10421_24.09_-1.21_-3.03_39.81\n",
      "accepted with 433.04764213142334 and 374.6099463397313\n",
      "trying 10422_24.09_-1.21_-3.03_43.81\n",
      "accepted with 372.5699744819258 and 426.1039776931757\n",
      "trying 10431_24.09_-1.21_-2.83_35.81\n",
      "trying 10432_24.09_-1.21_-2.83_39.81\n",
      "trying 10433_24.09_-1.21_-2.83_43.81\n",
      "accepted with 365.39481732871263 and 406.3752334927458\n",
      "trying 10434_24.09_-1.21_-2.83_47.81\n",
      "trying 10442_24.09_-1.21_-2.63_35.81\n",
      "trying 10443_24.09_-1.21_-2.63_39.81\n",
      "trying 10444_24.09_-1.21_-2.63_43.81\n",
      "accepted with 356.4323344231925 and 404.8429042226653\n",
      "trying 10445_24.09_-1.21_-2.63_47.81\n",
      "trying 10446_24.09_-1.21_-2.63_51.81\n",
      "trying 10452_24.09_-1.21_-2.43_31.81\n",
      "trying 10453_24.09_-1.21_-2.43_35.81\n",
      "trying 10454_24.09_-1.21_-2.43_39.81\n",
      "trying 10455_24.09_-1.21_-2.43_43.81\n",
      "accepted with 373.103471213637 and 405.62434630642656\n",
      "trying 10456_24.09_-1.21_-2.43_47.81\n",
      "trying 10457_24.09_-1.21_-2.43_51.81\n",
      "trying 10463_24.09_-1.21_-2.23_31.81\n",
      "trying 10464_24.09_-1.21_-2.23_35.81\n",
      "trying 10465_24.09_-1.21_-2.23_39.81\n",
      "trying 10466_24.09_-1.21_-2.23_43.81\n",
      "accepted with 380.2715772366737 and 404.34231276511946\n",
      "trying 10467_24.09_-1.21_-2.23_47.81\n",
      "trying 10468_24.09_-1.21_-2.23_51.81\n",
      "trying 10469_24.09_-1.21_-2.23_55.81\n",
      "trying 10474_24.09_-1.21_-2.03_31.81\n",
      "trying 10475_24.09_-1.21_-2.03_35.81\n",
      "trying 10476_24.09_-1.21_-2.03_39.81\n",
      "trying 10477_24.09_-1.21_-2.03_43.81\n",
      "accepted with 364.6368790122124 and 410.2377867537516\n",
      "trying 10478_24.09_-1.21_-2.03_47.81\n",
      "trying 10479_24.09_-1.21_-2.03_51.81\n",
      "trying 10480_24.09_-1.21_-2.03_55.81\n",
      "trying 10485_24.09_-1.21_-1.83_31.81\n",
      "trying 10486_24.09_-1.21_-1.83_35.81\n",
      "trying 10487_24.09_-1.21_-1.83_39.81\n",
      "trying 10488_24.09_-1.21_-1.83_43.81\n",
      "accepted with 357.45937148227495 and 407.4234239423631\n",
      "trying 10489_24.09_-1.21_-1.83_47.81\n",
      "trying 10490_24.09_-1.21_-1.83_51.81\n",
      "trying 10496_24.09_-1.21_-1.63_31.81\n",
      "trying 10497_24.09_-1.21_-1.63_35.81\n",
      "trying 10498_24.09_-1.21_-1.63_39.81\n",
      "trying 10499_24.09_-1.21_-1.63_43.81\n",
      "accepted with 378.8510266089079 and 404.6043603775224\n",
      "trying 10500_24.09_-1.21_-1.63_47.81\n",
      "trying 10501_24.09_-1.21_-1.63_51.81\n",
      "trying 10508_24.09_-1.21_-1.43_35.81\n",
      "trying 10509_24.09_-1.21_-1.43_39.81\n",
      "trying 10510_24.09_-1.21_-1.43_43.81\n",
      "accepted with 379.648440394576 and 407.94281841371867\n",
      "trying 10511_24.09_-1.21_-1.43_47.81\n",
      "trying 10512_24.09_-1.21_-1.43_51.81\n",
      "trying 10519_24.09_-1.21_-1.23_35.81\n",
      "trying 10520_24.09_-1.21_-1.23_39.81\n",
      "trying 10521_24.09_-1.21_-1.23_43.81\n",
      "accepted with 382.5957352388159 and 399.5767339061522\n",
      "trying 10522_24.09_-1.21_-1.23_47.81\n",
      "trying 10523_24.09_-1.21_-1.23_51.81\n",
      "trying 10543_24.09_-0.21_-3.03_43.81\n",
      "accepted with 409.47044693034695 and 387.67822710485143\n",
      "trying 10553_24.09_-0.21_-2.83_39.81\n",
      "trying 10554_24.09_-0.21_-2.83_43.81\n",
      "accepted with 400.7606101303272 and 388.70291378720685\n",
      "trying 10555_24.09_-0.21_-2.83_47.81\n",
      "trying 10556_24.09_-0.21_-2.83_51.81\n",
      "trying 10563_24.09_-0.21_-2.63_35.81\n",
      "trying 10564_24.09_-0.21_-2.63_39.81\n",
      "trying 10565_24.09_-0.21_-2.63_43.81\n",
      "accepted with 408.19546451921724 and 373.07056593947254\n",
      "trying 10566_24.09_-0.21_-2.63_47.81\n",
      "trying 10567_24.09_-0.21_-2.63_51.81\n",
      "trying 10573_24.09_-0.21_-2.43_31.81\n",
      "trying 10574_24.09_-0.21_-2.43_35.81\n",
      "trying 10575_24.09_-0.21_-2.43_39.81\n",
      "trying 10576_24.09_-0.21_-2.43_43.81\n",
      "accepted with 400.2806911281423 and 390.2399438107386\n",
      "trying 10577_24.09_-0.21_-2.43_47.81\n",
      "trying 10578_24.09_-0.21_-2.43_51.81\n",
      "trying 10579_24.09_-0.21_-2.43_55.81\n",
      "trying 10584_24.09_-0.21_-2.23_31.81\n",
      "trying 10585_24.09_-0.21_-2.23_35.81\n",
      "trying 10586_24.09_-0.21_-2.23_39.81\n",
      "trying 10587_24.09_-0.21_-2.23_43.81\n",
      "accepted with 382.6013202924232 and 403.5655714348122\n",
      "trying 10588_24.09_-0.21_-2.23_47.81\n",
      "trying 10589_24.09_-0.21_-2.23_51.81\n",
      "trying 10590_24.09_-0.21_-2.23_55.81\n",
      "trying 10595_24.09_-0.21_-2.03_31.81\n",
      "trying 10596_24.09_-0.21_-2.03_35.81\n",
      "trying 10597_24.09_-0.21_-2.03_39.81\n",
      "trying 10598_24.09_-0.21_-2.03_43.81\n",
      "accepted with 373.6294358799996 and 408.7007567302189\n",
      "trying 10599_24.09_-0.21_-2.03_47.81\n",
      "trying 10600_24.09_-0.21_-2.03_51.81\n",
      "trying 10606_24.09_-0.21_-1.83_31.81\n",
      "trying 10607_24.09_-0.21_-1.83_35.81\n",
      "trying 10608_24.09_-0.21_-1.83_39.81\n",
      "trying 10609_24.09_-0.21_-1.83_43.81\n",
      "accepted with 367.6381549509606 and 403.5796736951679\n",
      "trying 10610_24.09_-0.21_-1.83_47.81\n",
      "trying 10611_24.09_-0.21_-1.83_51.81\n",
      "trying 10618_24.09_-0.21_-1.63_35.81\n",
      "trying 10619_24.09_-0.21_-1.63_39.81\n",
      "trying 10620_24.09_-0.21_-1.63_43.81\n",
      "accepted with 370.4872924780684 and 406.59270151754754\n",
      "trying 10621_24.09_-0.21_-1.63_47.81\n",
      "trying 10622_24.09_-0.21_-1.63_51.81\n",
      "trying 10629_24.09_-0.21_-1.43_35.81\n",
      "trying 10630_24.09_-0.21_-1.43_39.81\n",
      "trying 10631_24.09_-0.21_-1.43_43.81\n",
      "accepted with 362.8322163226694 and 413.89608995015806\n",
      "trying 10632_24.09_-0.21_-1.43_47.81\n",
      "trying 10633_24.09_-0.21_-1.43_51.81\n",
      "trying 10640_24.09_-0.21_-1.23_35.81\n",
      "trying 10641_24.09_-0.21_-1.23_39.81\n",
      "trying 10642_24.09_-0.21_-1.23_43.81\n",
      "accepted with 372.98239190566255 and 419.40040074683475\n",
      "trying 10643_24.09_-0.21_-1.23_47.81\n",
      "trying 10644_24.09_-0.21_-1.23_51.81\n",
      "trying 10665_24.09_0.79_-3.03_47.81\n",
      "accepted with 398.4538899066638 and 423.03461839956253\n",
      "trying 10674_24.09_0.79_-2.83_39.81\n",
      "trying 10675_24.09_0.79_-2.83_43.81\n",
      "trying 10676_24.09_0.79_-2.83_47.81\n",
      "accepted with 375.1711666569836 and 424.5739987998204\n",
      "trying 10677_24.09_0.79_-2.83_51.81\n",
      "trying 10684_24.09_0.79_-2.63_35.81\n",
      "trying 10685_24.09_0.79_-2.63_39.81\n",
      "trying 10686_24.09_0.79_-2.63_43.81\n",
      "accepted with 434.834083583577 and 354.3641580446738\n",
      "trying 10687_24.09_0.79_-2.63_47.81\n",
      "trying 10688_24.09_0.79_-2.63_51.81\n",
      "trying 10689_24.09_0.79_-2.63_55.81\n",
      "trying 10695_24.09_0.79_-2.43_35.81\n",
      "trying 10696_24.09_0.79_-2.43_39.81\n",
      "trying 10697_24.09_0.79_-2.43_43.81\n",
      "accepted with 426.75777027395543 and 368.9718192100527\n",
      "trying 10698_24.09_0.79_-2.43_47.81\n",
      "trying 10699_24.09_0.79_-2.43_51.81\n",
      "trying 10700_24.09_0.79_-2.43_55.81\n",
      "trying 10705_24.09_0.79_-2.23_31.81\n",
      "trying 10706_24.09_0.79_-2.23_35.81\n",
      "trying 10707_24.09_0.79_-2.23_39.81\n",
      "trying 10708_24.09_0.79_-2.23_43.81\n",
      "accepted with 415.57732295499954 and 386.14354745804485\n",
      "trying 10709_24.09_0.79_-2.23_47.81\n",
      "trying 10710_24.09_0.79_-2.23_51.81\n",
      "trying 10711_24.09_0.79_-2.23_55.81\n",
      "trying 10716_24.09_0.79_-2.03_31.81\n",
      "trying 10717_24.09_0.79_-2.03_35.81\n",
      "trying 10718_24.09_0.79_-2.03_39.81\n",
      "trying 10719_24.09_0.79_-2.03_43.81\n",
      "accepted with 389.57222738103883 and 398.7018352587129\n",
      "trying 10720_24.09_0.79_-2.03_47.81\n",
      "trying 10721_24.09_0.79_-2.03_51.81\n",
      "trying 10722_24.09_0.79_-2.03_55.81\n",
      "trying 10727_24.09_0.79_-1.83_31.81\n",
      "trying 10728_24.09_0.79_-1.83_35.81\n",
      "trying 10729_24.09_0.79_-1.83_39.81\n",
      "trying 10730_24.09_0.79_-1.83_43.81\n",
      "accepted with 376.4104900522407 and 403.60504690398375\n",
      "trying 10731_24.09_0.79_-1.83_47.81\n",
      "trying 10732_24.09_0.79_-1.83_51.81\n",
      "trying 10739_24.09_0.79_-1.63_35.81\n",
      "trying 10740_24.09_0.79_-1.63_39.81\n",
      "trying 10741_24.09_0.79_-1.63_43.81\n",
      "accepted with 360.8786498983636 and 398.2961664414179\n",
      "trying 10742_24.09_0.79_-1.63_47.81\n",
      "trying 10743_24.09_0.79_-1.63_51.81\n",
      "trying 10750_24.09_0.79_-1.43_35.81\n",
      "trying 10751_24.09_0.79_-1.43_39.81\n",
      "trying 10752_24.09_0.79_-1.43_43.81\n",
      "accepted with 359.75492159872374 and 406.32653492810823\n",
      "trying 10753_24.09_0.79_-1.43_47.81\n",
      "trying 10754_24.09_0.79_-1.43_51.81\n",
      "trying 10761_24.09_0.79_-1.23_35.81\n",
      "trying 10762_24.09_0.79_-1.23_39.81\n",
      "trying 10763_24.09_0.79_-1.23_43.81\n",
      "accepted with 365.48650529208226 and 417.9512422333746\n",
      "trying 10764_24.09_0.79_-1.23_47.81\n",
      "trying 10765_24.09_0.79_-1.23_51.81\n",
      "trying 10786_24.09_1.79_-3.03_47.81\n",
      "accepted with 440.57125233054376 and 382.0330488449936\n",
      "trying 10795_24.09_1.79_-2.83_39.81\n",
      "trying 10796_24.09_1.79_-2.83_43.81\n",
      "trying 10797_24.09_1.79_-2.83_47.81\n",
      "accepted with 399.37248384155555 and 398.4327365161298\n",
      "trying 10798_24.09_1.79_-2.83_51.81\n",
      "trying 10805_24.09_1.79_-2.63_35.81\n",
      "trying 10806_24.09_1.79_-2.63_39.81\n",
      "trying 10807_24.09_1.79_-2.63_43.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying 10808_24.09_1.79_-2.63_47.81\n",
      "accepted with 375.8601373184638 and 422.51757430493217\n",
      "trying 10809_24.09_1.79_-2.63_51.81\n",
      "trying 10810_24.09_1.79_-2.63_55.81\n",
      "trying 10816_24.09_1.79_-2.43_35.81\n",
      "trying 10817_24.09_1.79_-2.43_39.81\n",
      "trying 10818_24.09_1.79_-2.43_43.81\n",
      "trying 10819_24.09_1.79_-2.43_47.81\n",
      "trying 10820_24.09_1.79_-2.43_51.81\n",
      "trying 10821_24.09_1.79_-2.43_55.81\n",
      "trying 10826_24.09_1.79_-2.23_31.81\n",
      "trying 10827_24.09_1.79_-2.23_35.81\n",
      "trying 10828_24.09_1.79_-2.23_39.81\n",
      "trying 10829_24.09_1.79_-2.23_43.81\n",
      "accepted with 419.3948156932247 and 366.1504052684859\n",
      "trying 10830_24.09_1.79_-2.23_47.81\n",
      "trying 10831_24.09_1.79_-2.23_51.81\n",
      "trying 10832_24.09_1.79_-2.23_55.81\n",
      "trying 10837_24.09_1.79_-2.03_31.81\n",
      "trying 10838_24.09_1.79_-2.03_35.81\n",
      "trying 10839_24.09_1.79_-2.03_39.81\n",
      "trying 10840_24.09_1.79_-2.03_43.81\n",
      "accepted with 389.7352333761555 and 385.1212111524146\n",
      "trying 10841_24.09_1.79_-2.03_47.81\n",
      "trying 10842_24.09_1.79_-2.03_51.81\n",
      "trying 10843_24.09_1.79_-2.03_55.81\n",
      "trying 10849_24.09_1.79_-1.83_35.81\n",
      "trying 10850_24.09_1.79_-1.83_39.81\n",
      "trying 10851_24.09_1.79_-1.83_43.81\n",
      "accepted with 376.6321778953179 and 387.8698409856652\n",
      "trying 10852_24.09_1.79_-1.83_47.81\n",
      "trying 10853_24.09_1.79_-1.83_51.81\n",
      "trying 10854_24.09_1.79_-1.83_55.81\n",
      "trying 10860_24.09_1.79_-1.63_35.81\n",
      "trying 10861_24.09_1.79_-1.63_39.81\n",
      "trying 10862_24.09_1.79_-1.63_43.81\n",
      "accepted with 360.2324902241817 and 405.58780299040063\n",
      "trying 10863_24.09_1.79_-1.63_47.81\n",
      "trying 10864_24.09_1.79_-1.63_51.81\n",
      "trying 10871_24.09_1.79_-1.43_35.81\n",
      "trying 10872_24.09_1.79_-1.43_39.81\n",
      "trying 10873_24.09_1.79_-1.43_43.81\n",
      "accepted with 357.2866614565155 and 403.5304941953573\n",
      "trying 10874_24.09_1.79_-1.43_47.81\n",
      "trying 10875_24.09_1.79_-1.43_51.81\n",
      "trying 10882_24.09_1.79_-1.23_35.81\n",
      "trying 10883_24.09_1.79_-1.23_39.81\n",
      "trying 10884_24.09_1.79_-1.23_43.81\n",
      "accepted with 355.8486730502691 and 421.752282334518\n",
      "trying 10885_24.09_1.79_-1.23_47.81\n",
      "trying 10886_24.09_1.79_-1.23_51.81\n",
      "trying 10901_24.69_-7.21_-3.03_23.81\n",
      "trying 10902_24.69_-7.21_-3.03_27.81\n",
      "trying 10903_24.69_-7.21_-3.03_31.81\n",
      "trying 10913_24.69_-7.21_-2.83_27.81\n",
      "trying 10914_24.69_-7.21_-2.83_31.81\n",
      "trying 10915_24.69_-7.21_-2.83_35.81\n",
      "trying 10916_24.69_-7.21_-2.83_39.81\n",
      "trying 10924_24.69_-7.21_-2.63_27.81\n",
      "trying 10925_24.69_-7.21_-2.63_31.81\n",
      "trying 10926_24.69_-7.21_-2.63_35.81\n",
      "trying 10927_24.69_-7.21_-2.63_39.81\n",
      "trying 10928_24.69_-7.21_-2.63_43.81\n",
      "trying 10929_24.69_-7.21_-2.63_47.81\n",
      "trying 10936_24.69_-7.21_-2.43_31.81\n",
      "trying 10937_24.69_-7.21_-2.43_35.81\n",
      "trying 10938_24.69_-7.21_-2.43_39.81\n",
      "trying 10939_24.69_-7.21_-2.43_43.81\n",
      "trying 10940_24.69_-7.21_-2.43_47.81\n",
      "trying 10941_24.69_-7.21_-2.43_51.81\n",
      "trying 10947_24.69_-7.21_-2.23_31.81\n",
      "trying 10948_24.69_-7.21_-2.23_35.81\n",
      "trying 10949_24.69_-7.21_-2.23_39.81\n",
      "trying 10950_24.69_-7.21_-2.23_43.81\n",
      "trying 10951_24.69_-7.21_-2.23_47.81\n",
      "trying 10952_24.69_-7.21_-2.23_51.81\n",
      "trying 10953_24.69_-7.21_-2.23_55.81\n",
      "trying 10958_24.69_-7.21_-2.03_31.81\n",
      "trying 10959_24.69_-7.21_-2.03_35.81\n",
      "trying 10960_24.69_-7.21_-2.03_39.81\n",
      "trying 10961_24.69_-7.21_-2.03_43.81\n",
      "trying 10962_24.69_-7.21_-2.03_47.81\n",
      "trying 10963_24.69_-7.21_-2.03_51.81\n",
      "trying 10964_24.69_-7.21_-2.03_55.81\n",
      "trying 10965_24.69_-7.21_-2.03_59.81\n",
      "trying 10969_24.69_-7.21_-1.83_31.81\n",
      "trying 10970_24.69_-7.21_-1.83_35.81\n",
      "trying 10971_24.69_-7.21_-1.83_39.81\n",
      "trying 10972_24.69_-7.21_-1.83_43.81\n",
      "trying 10973_24.69_-7.21_-1.83_47.81\n",
      "trying 10974_24.69_-7.21_-1.83_51.81\n",
      "trying 10975_24.69_-7.21_-1.83_55.81\n",
      "trying 10976_24.69_-7.21_-1.83_59.81\n",
      "trying 10980_24.69_-7.21_-1.63_31.81\n",
      "trying 10981_24.69_-7.21_-1.63_35.81\n",
      "trying 10982_24.69_-7.21_-1.63_39.81\n",
      "trying 10983_24.69_-7.21_-1.63_43.81\n",
      "trying 10984_24.69_-7.21_-1.63_47.81\n",
      "trying 10985_24.69_-7.21_-1.63_51.81\n",
      "trying 10986_24.69_-7.21_-1.63_55.81\n",
      "trying 10987_24.69_-7.21_-1.63_59.81\n",
      "trying 10992_24.69_-7.21_-1.43_35.81\n",
      "trying 10993_24.69_-7.21_-1.43_39.81\n",
      "trying 10994_24.69_-7.21_-1.43_43.81\n",
      "trying 10995_24.69_-7.21_-1.43_47.81\n",
      "trying 10996_24.69_-7.21_-1.43_51.81\n",
      "trying 10997_24.69_-7.21_-1.43_55.81\n",
      "trying 10998_24.69_-7.21_-1.43_59.81\n",
      "trying 11003_24.69_-7.21_-1.23_35.81\n",
      "trying 11004_24.69_-7.21_-1.23_39.81\n",
      "trying 11005_24.69_-7.21_-1.23_43.81\n",
      "trying 11006_24.69_-7.21_-1.23_47.81\n",
      "trying 11007_24.69_-7.21_-1.23_51.81\n",
      "trying 11008_24.69_-7.21_-1.23_55.81\n",
      "trying 11023_24.69_-6.21_-3.03_27.81\n",
      "trying 11024_24.69_-6.21_-3.03_31.81\n",
      "accepted with 362.0704615528721 and 381.7851034929463\n",
      "trying 11035_24.69_-6.21_-2.83_31.81\n",
      "trying 11036_24.69_-6.21_-2.83_35.81\n",
      "trying 11037_24.69_-6.21_-2.83_39.81\n",
      "trying 11038_24.69_-6.21_-2.83_43.81\n",
      "trying 11046_24.69_-6.21_-2.63_31.81\n",
      "trying 11047_24.69_-6.21_-2.63_35.81\n",
      "trying 11048_24.69_-6.21_-2.63_39.81\n",
      "trying 11049_24.69_-6.21_-2.63_43.81\n",
      "trying 11050_24.69_-6.21_-2.63_47.81\n",
      "trying 11057_24.69_-6.21_-2.43_31.81\n",
      "trying 11058_24.69_-6.21_-2.43_35.81\n",
      "trying 11059_24.69_-6.21_-2.43_39.81\n",
      "trying 11060_24.69_-6.21_-2.43_43.81\n",
      "trying 11061_24.69_-6.21_-2.43_47.81\n",
      "trying 11062_24.69_-6.21_-2.43_51.81\n",
      "trying 11067_24.69_-6.21_-2.23_27.81\n",
      "trying 11068_24.69_-6.21_-2.23_31.81\n",
      "trying 11069_24.69_-6.21_-2.23_35.81\n",
      "trying 11070_24.69_-6.21_-2.23_39.81\n",
      "trying 11071_24.69_-6.21_-2.23_43.81\n",
      "trying 11072_24.69_-6.21_-2.23_47.81\n",
      "trying 11073_24.69_-6.21_-2.23_51.81\n",
      "trying 11074_24.69_-6.21_-2.23_55.81\n",
      "trying 11078_24.69_-6.21_-2.03_27.81\n",
      "trying 11079_24.69_-6.21_-2.03_31.81\n",
      "trying 11080_24.69_-6.21_-2.03_35.81\n",
      "trying 11081_24.69_-6.21_-2.03_39.81\n",
      "trying 11082_24.69_-6.21_-2.03_43.81\n",
      "trying 11083_24.69_-6.21_-2.03_47.81\n",
      "trying 11084_24.69_-6.21_-2.03_51.81\n",
      "trying 11085_24.69_-6.21_-2.03_55.81\n",
      "trying 11086_24.69_-6.21_-2.03_59.81\n",
      "trying 11090_24.69_-6.21_-1.83_31.81\n",
      "trying 11091_24.69_-6.21_-1.83_35.81\n",
      "trying 11092_24.69_-6.21_-1.83_39.81\n",
      "trying 11093_24.69_-6.21_-1.83_43.81\n",
      "trying 11094_24.69_-6.21_-1.83_47.81\n",
      "trying 11095_24.69_-6.21_-1.83_51.81\n",
      "trying 11096_24.69_-6.21_-1.83_55.81\n",
      "trying 11097_24.69_-6.21_-1.83_59.81\n",
      "trying 11101_24.69_-6.21_-1.63_31.81\n",
      "trying 11102_24.69_-6.21_-1.63_35.81\n",
      "trying 11103_24.69_-6.21_-1.63_39.81\n",
      "trying 11104_24.69_-6.21_-1.63_43.81\n",
      "trying 11105_24.69_-6.21_-1.63_47.81\n",
      "trying 11106_24.69_-6.21_-1.63_51.81\n",
      "trying 11107_24.69_-6.21_-1.63_55.81\n",
      "trying 11113_24.69_-6.21_-1.43_35.81\n",
      "trying 11114_24.69_-6.21_-1.43_39.81\n",
      "trying 11115_24.69_-6.21_-1.43_43.81\n",
      "trying 11116_24.69_-6.21_-1.43_47.81\n",
      "trying 11117_24.69_-6.21_-1.43_51.81\n",
      "trying 11118_24.69_-6.21_-1.43_55.81\n",
      "trying 11124_24.69_-6.21_-1.23_35.81\n",
      "trying 11125_24.69_-6.21_-1.23_39.81\n",
      "trying 11126_24.69_-6.21_-1.23_43.81\n",
      "trying 11127_24.69_-6.21_-1.23_47.81\n",
      "trying 11128_24.69_-6.21_-1.23_51.81\n",
      "trying 11145_24.69_-5.21_-3.03_31.81\n",
      "accepted with 389.74170272991705 and 360.00933630453073\n",
      "trying 11146_24.69_-5.21_-3.03_35.81\n",
      "trying 11156_24.69_-5.21_-2.83_31.81\n",
      "trying 11157_24.69_-5.21_-2.83_35.81\n",
      "trying 11158_24.69_-5.21_-2.83_39.81\n",
      "trying 11159_24.69_-5.21_-2.83_43.81\n",
      "trying 11167_24.69_-5.21_-2.63_31.81\n",
      "trying 11168_24.69_-5.21_-2.63_35.81\n",
      "trying 11169_24.69_-5.21_-2.63_39.81\n",
      "trying 11170_24.69_-5.21_-2.63_43.81\n",
      "trying 11171_24.69_-5.21_-2.63_47.81\n",
      "trying 11177_24.69_-5.21_-2.43_27.81\n",
      "trying 11178_24.69_-5.21_-2.43_31.81\n",
      "trying 11179_24.69_-5.21_-2.43_35.81\n",
      "trying 11180_24.69_-5.21_-2.43_39.81\n",
      "trying 11181_24.69_-5.21_-2.43_43.81\n",
      "trying 11182_24.69_-5.21_-2.43_47.81\n",
      "trying 11183_24.69_-5.21_-2.43_51.81\n",
      "trying 11188_24.69_-5.21_-2.23_27.81\n",
      "trying 11189_24.69_-5.21_-2.23_31.81\n",
      "trying 11190_24.69_-5.21_-2.23_35.81\n",
      "trying 11191_24.69_-5.21_-2.23_39.81\n",
      "trying 11192_24.69_-5.21_-2.23_43.81\n",
      "trying 11193_24.69_-5.21_-2.23_47.81\n",
      "trying 11194_24.69_-5.21_-2.23_51.81\n",
      "trying 11195_24.69_-5.21_-2.23_55.81\n",
      "trying 11200_24.69_-5.21_-2.03_31.81\n",
      "trying 11201_24.69_-5.21_-2.03_35.81\n",
      "trying 11202_24.69_-5.21_-2.03_39.81\n",
      "trying 11203_24.69_-5.21_-2.03_43.81\n",
      "trying 11204_24.69_-5.21_-2.03_47.81\n",
      "trying 11205_24.69_-5.21_-2.03_51.81\n",
      "trying 11206_24.69_-5.21_-2.03_55.81\n",
      "trying 11211_24.69_-5.21_-1.83_31.81\n",
      "trying 11212_24.69_-5.21_-1.83_35.81\n",
      "trying 11213_24.69_-5.21_-1.83_39.81\n",
      "trying 11214_24.69_-5.21_-1.83_43.81\n",
      "trying 11215_24.69_-5.21_-1.83_47.81\n",
      "trying 11216_24.69_-5.21_-1.83_51.81\n",
      "trying 11217_24.69_-5.21_-1.83_55.81\n",
      "trying 11222_24.69_-5.21_-1.63_31.81\n",
      "trying 11223_24.69_-5.21_-1.63_35.81\n",
      "trying 11224_24.69_-5.21_-1.63_39.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying 11225_24.69_-5.21_-1.63_43.81\n",
      "trying 11226_24.69_-5.21_-1.63_47.81\n",
      "trying 11227_24.69_-5.21_-1.63_51.81\n",
      "trying 11228_24.69_-5.21_-1.63_55.81\n",
      "trying 11234_24.69_-5.21_-1.43_35.81\n",
      "trying 11235_24.69_-5.21_-1.43_39.81\n",
      "trying 11236_24.69_-5.21_-1.43_43.81\n",
      "trying 11237_24.69_-5.21_-1.43_47.81\n",
      "trying 11238_24.69_-5.21_-1.43_51.81\n",
      "trying 11239_24.69_-5.21_-1.43_55.81\n",
      "trying 11245_24.69_-5.21_-1.23_35.81\n",
      "trying 11246_24.69_-5.21_-1.23_39.81\n",
      "trying 11247_24.69_-5.21_-1.23_43.81\n",
      "trying 11248_24.69_-5.21_-1.23_47.81\n",
      "trying 11249_24.69_-5.21_-1.23_51.81\n",
      "trying 11267_24.69_-4.21_-3.03_35.81\n",
      "accepted with 375.65108565916853 and 392.2916675521765\n",
      "trying 11277_24.69_-4.21_-2.83_31.81\n",
      "trying 11278_24.69_-4.21_-2.83_35.81\n",
      "trying 11279_24.69_-4.21_-2.83_39.81\n",
      "trying 11280_24.69_-4.21_-2.83_43.81\n",
      "trying 11287_24.69_-4.21_-2.63_27.81\n",
      "trying 11288_24.69_-4.21_-2.63_31.81\n",
      "trying 11289_24.69_-4.21_-2.63_35.81\n",
      "trying 11290_24.69_-4.21_-2.63_39.81\n",
      "trying 11291_24.69_-4.21_-2.63_43.81\n",
      "trying 11292_24.69_-4.21_-2.63_47.81\n",
      "trying 11293_24.69_-4.21_-2.63_51.81\n",
      "trying 11298_24.69_-4.21_-2.43_27.81\n",
      "trying 11299_24.69_-4.21_-2.43_31.81\n",
      "trying 11300_24.69_-4.21_-2.43_35.81\n",
      "trying 11301_24.69_-4.21_-2.43_39.81\n",
      "trying 11302_24.69_-4.21_-2.43_43.81\n",
      "trying 11303_24.69_-4.21_-2.43_47.81\n",
      "trying 11304_24.69_-4.21_-2.43_51.81\n",
      "trying 11305_24.69_-4.21_-2.43_55.81\n",
      "trying 11310_24.69_-4.21_-2.23_31.81\n",
      "trying 11311_24.69_-4.21_-2.23_35.81\n",
      "trying 11312_24.69_-4.21_-2.23_39.81\n",
      "trying 11313_24.69_-4.21_-2.23_43.81\n",
      "trying 11314_24.69_-4.21_-2.23_47.81\n",
      "trying 11315_24.69_-4.21_-2.23_51.81\n",
      "trying 11316_24.69_-4.21_-2.23_55.81\n",
      "trying 11321_24.69_-4.21_-2.03_31.81\n",
      "trying 11322_24.69_-4.21_-2.03_35.81\n",
      "trying 11323_24.69_-4.21_-2.03_39.81\n",
      "trying 11324_24.69_-4.21_-2.03_43.81\n",
      "trying 11325_24.69_-4.21_-2.03_47.81\n",
      "trying 11326_24.69_-4.21_-2.03_51.81\n",
      "trying 11327_24.69_-4.21_-2.03_55.81\n",
      "trying 11332_24.69_-4.21_-1.83_31.81\n",
      "trying 11333_24.69_-4.21_-1.83_35.81\n",
      "trying 11334_24.69_-4.21_-1.83_39.81\n",
      "trying 11335_24.69_-4.21_-1.83_43.81\n",
      "trying 11336_24.69_-4.21_-1.83_47.81\n",
      "trying 11337_24.69_-4.21_-1.83_51.81\n",
      "trying 11338_24.69_-4.21_-1.83_55.81\n",
      "trying 11343_24.69_-4.21_-1.63_31.81\n",
      "trying 11344_24.69_-4.21_-1.63_35.81\n",
      "trying 11345_24.69_-4.21_-1.63_39.81\n",
      "trying 11346_24.69_-4.21_-1.63_43.81\n",
      "trying 11347_24.69_-4.21_-1.63_47.81\n",
      "trying 11348_24.69_-4.21_-1.63_51.81\n",
      "trying 11349_24.69_-4.21_-1.63_55.81\n",
      "trying 11355_24.69_-4.21_-1.43_35.81\n",
      "trying 11356_24.69_-4.21_-1.43_39.81\n",
      "trying 11357_24.69_-4.21_-1.43_43.81\n",
      "trying 11358_24.69_-4.21_-1.43_47.81\n",
      "trying 11359_24.69_-4.21_-1.43_51.81\n",
      "trying 11360_24.69_-4.21_-1.43_55.81\n",
      "trying 11366_24.69_-4.21_-1.23_35.81\n",
      "trying 11367_24.69_-4.21_-1.23_39.81\n",
      "trying 11368_24.69_-4.21_-1.23_43.81\n",
      "trying 11369_24.69_-4.21_-1.23_47.81\n",
      "trying 11370_24.69_-4.21_-1.23_51.81\n",
      "trying 11398_24.69_-3.21_-2.83_31.81\n",
      "trying 11399_24.69_-3.21_-2.83_35.81\n",
      "trying 11400_24.69_-3.21_-2.83_39.81\n",
      "accepted with 368.2091801401002 and 362.57105301041975\n",
      "trying 11401_24.69_-3.21_-2.83_43.81\n",
      "trying 11402_24.69_-3.21_-2.83_47.81\n",
      "trying 11409_24.69_-3.21_-2.63_31.81\n",
      "trying 11410_24.69_-3.21_-2.63_35.81\n",
      "trying 11411_24.69_-3.21_-2.63_39.81\n",
      "trying 11412_24.69_-3.21_-2.63_43.81\n",
      "trying 11413_24.69_-3.21_-2.63_47.81\n",
      "trying 11414_24.69_-3.21_-2.63_51.81\n",
      "trying 11420_24.69_-3.21_-2.43_31.81\n",
      "trying 11421_24.69_-3.21_-2.43_35.81\n",
      "trying 11422_24.69_-3.21_-2.43_39.81\n",
      "trying 11423_24.69_-3.21_-2.43_43.81\n",
      "trying 11424_24.69_-3.21_-2.43_47.81\n",
      "trying 11425_24.69_-3.21_-2.43_51.81\n",
      "trying 11426_24.69_-3.21_-2.43_55.81\n",
      "trying 11431_24.69_-3.21_-2.23_31.81\n",
      "trying 11432_24.69_-3.21_-2.23_35.81\n",
      "trying 11433_24.69_-3.21_-2.23_39.81\n",
      "trying 11434_24.69_-3.21_-2.23_43.81\n",
      "trying 11435_24.69_-3.21_-2.23_47.81\n",
      "trying 11436_24.69_-3.21_-2.23_51.81\n",
      "trying 11437_24.69_-3.21_-2.23_55.81\n",
      "trying 11442_24.69_-3.21_-2.03_31.81\n",
      "trying 11443_24.69_-3.21_-2.03_35.81\n",
      "trying 11444_24.69_-3.21_-2.03_39.81\n",
      "trying 11445_24.69_-3.21_-2.03_43.81\n",
      "trying 11446_24.69_-3.21_-2.03_47.81\n",
      "trying 11447_24.69_-3.21_-2.03_51.81\n",
      "trying 11448_24.69_-3.21_-2.03_55.81\n",
      "trying 11453_24.69_-3.21_-1.83_31.81\n",
      "trying 11454_24.69_-3.21_-1.83_35.81\n",
      "trying 11455_24.69_-3.21_-1.83_39.81\n",
      "trying 11456_24.69_-3.21_-1.83_43.81\n",
      "trying 11457_24.69_-3.21_-1.83_47.81\n",
      "trying 11458_24.69_-3.21_-1.83_51.81\n",
      "trying 11459_24.69_-3.21_-1.83_55.81\n",
      "trying 11464_24.69_-3.21_-1.63_31.81\n",
      "trying 11465_24.69_-3.21_-1.63_35.81\n",
      "trying 11466_24.69_-3.21_-1.63_39.81\n",
      "trying 11467_24.69_-3.21_-1.63_43.81\n",
      "trying 11468_24.69_-3.21_-1.63_47.81\n",
      "trying 11469_24.69_-3.21_-1.63_51.81\n",
      "trying 11470_24.69_-3.21_-1.63_55.81\n",
      "trying 11476_24.69_-3.21_-1.43_35.81\n",
      "trying 11477_24.69_-3.21_-1.43_39.81\n",
      "trying 11478_24.69_-3.21_-1.43_43.81\n",
      "accepted with 355.1075907358336 and 350.0151155864796\n",
      "trying 11479_24.69_-3.21_-1.43_47.81\n",
      "trying 11480_24.69_-3.21_-1.43_51.81\n",
      "trying 11481_24.69_-3.21_-1.43_55.81\n",
      "trying 11487_24.69_-3.21_-1.23_35.81\n",
      "trying 11488_24.69_-3.21_-1.23_39.81\n",
      "trying 11489_24.69_-3.21_-1.23_43.81\n",
      "trying 11490_24.69_-3.21_-1.23_47.81\n",
      "trying 11491_24.69_-3.21_-1.23_51.81\n",
      "trying 11509_24.69_-2.21_-3.03_35.81\n",
      "trying 11510_24.69_-2.21_-3.03_39.81\n",
      "accepted with 382.8191916822043 and 392.79931013990154\n",
      "trying 11519_24.69_-2.21_-2.83_31.81\n",
      "trying 11520_24.69_-2.21_-2.83_35.81\n",
      "trying 11521_24.69_-2.21_-2.83_39.81\n",
      "trying 11522_24.69_-2.21_-2.83_43.81\n",
      "trying 11523_24.69_-2.21_-2.83_47.81\n",
      "trying 11530_24.69_-2.21_-2.63_31.81\n",
      "trying 11531_24.69_-2.21_-2.63_35.81\n",
      "trying 11532_24.69_-2.21_-2.63_39.81\n",
      "trying 11533_24.69_-2.21_-2.63_43.81\n",
      "trying 11534_24.69_-2.21_-2.63_47.81\n",
      "trying 11535_24.69_-2.21_-2.63_51.81\n",
      "trying 11541_24.69_-2.21_-2.43_31.81\n",
      "trying 11542_24.69_-2.21_-2.43_35.81\n",
      "trying 11543_24.69_-2.21_-2.43_39.81\n",
      "trying 11544_24.69_-2.21_-2.43_43.81\n",
      "trying 11545_24.69_-2.21_-2.43_47.81\n",
      "trying 11546_24.69_-2.21_-2.43_51.81\n",
      "trying 11547_24.69_-2.21_-2.43_55.81\n",
      "trying 11551_24.69_-2.21_-2.23_27.81\n",
      "trying 11552_24.69_-2.21_-2.23_31.81\n",
      "trying 11553_24.69_-2.21_-2.23_35.81\n",
      "trying 11554_24.69_-2.21_-2.23_39.81\n",
      "trying 11555_24.69_-2.21_-2.23_43.81\n",
      "trying 11556_24.69_-2.21_-2.23_47.81\n",
      "trying 11557_24.69_-2.21_-2.23_51.81\n",
      "trying 11558_24.69_-2.21_-2.23_55.81\n",
      "trying 11563_24.69_-2.21_-2.03_31.81\n",
      "trying 11564_24.69_-2.21_-2.03_35.81\n",
      "trying 11565_24.69_-2.21_-2.03_39.81\n",
      "trying 11566_24.69_-2.21_-2.03_43.81\n",
      "trying 11567_24.69_-2.21_-2.03_47.81\n",
      "trying 11568_24.69_-2.21_-2.03_51.81\n",
      "trying 11569_24.69_-2.21_-2.03_55.81\n",
      "trying 11570_24.69_-2.21_-2.03_59.81\n",
      "trying 11574_24.69_-2.21_-1.83_31.81\n",
      "trying 11575_24.69_-2.21_-1.83_35.81\n",
      "trying 11576_24.69_-2.21_-1.83_39.81\n",
      "trying 11577_24.69_-2.21_-1.83_43.81\n",
      "trying 11578_24.69_-2.21_-1.83_47.81\n",
      "trying 11579_24.69_-2.21_-1.83_51.81\n",
      "trying 11580_24.69_-2.21_-1.83_55.81\n",
      "trying 11585_24.69_-2.21_-1.63_31.81\n",
      "trying 11586_24.69_-2.21_-1.63_35.81\n",
      "trying 11587_24.69_-2.21_-1.63_39.81\n",
      "trying 11588_24.69_-2.21_-1.63_43.81\n",
      "trying 11589_24.69_-2.21_-1.63_47.81\n",
      "trying 11590_24.69_-2.21_-1.63_51.81\n",
      "trying 11591_24.69_-2.21_-1.63_55.81\n",
      "trying 11596_24.69_-2.21_-1.43_31.81\n",
      "trying 11597_24.69_-2.21_-1.43_35.81\n",
      "trying 11598_24.69_-2.21_-1.43_39.81\n",
      "trying 11599_24.69_-2.21_-1.43_43.81\n",
      "trying 11600_24.69_-2.21_-1.43_47.81\n",
      "trying 11601_24.69_-2.21_-1.43_51.81\n",
      "trying 11602_24.69_-2.21_-1.43_55.81\n",
      "trying 11608_24.69_-2.21_-1.23_35.81\n",
      "trying 11609_24.69_-2.21_-1.23_39.81\n",
      "trying 11610_24.69_-2.21_-1.23_43.81\n",
      "trying 11611_24.69_-2.21_-1.23_47.81\n",
      "trying 11612_24.69_-2.21_-1.23_51.81\n",
      "trying 11630_24.69_-1.21_-3.03_35.81\n",
      "trying 11631_24.69_-1.21_-3.03_39.81\n",
      "accepted with 403.5773233184409 and 361.03637336361135\n",
      "trying 11632_24.69_-1.21_-3.03_43.81\n",
      "accepted with 361.04107411706264 and 414.327131976268\n",
      "trying 11641_24.69_-1.21_-2.83_35.81\n",
      "trying 11642_24.69_-1.21_-2.83_39.81\n",
      "trying 11643_24.69_-1.21_-2.83_43.81\n",
      "accepted with 352.5862337992703 and 397.6630463160009\n",
      "trying 11644_24.69_-1.21_-2.83_47.81\n",
      "trying 11651_24.69_-1.21_-2.63_31.81\n",
      "trying 11652_24.69_-1.21_-2.63_35.81\n",
      "trying 11653_24.69_-1.21_-2.63_39.81\n",
      "trying 11654_24.69_-1.21_-2.63_43.81\n",
      "trying 11655_24.69_-1.21_-2.63_47.81\n",
      "trying 11656_24.69_-1.21_-2.63_51.81\n",
      "trying 11662_24.69_-1.21_-2.43_31.81\n",
      "trying 11663_24.69_-1.21_-2.43_35.81\n",
      "trying 11664_24.69_-1.21_-2.43_39.81\n",
      "trying 11665_24.69_-1.21_-2.43_43.81\n",
      "trying 11666_24.69_-1.21_-2.43_47.81\n",
      "trying 11667_24.69_-1.21_-2.43_51.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying 11668_24.69_-1.21_-2.43_55.81\n",
      "trying 11673_24.69_-1.21_-2.23_31.81\n",
      "trying 11674_24.69_-1.21_-2.23_35.81\n",
      "trying 11675_24.69_-1.21_-2.23_39.81\n",
      "trying 11676_24.69_-1.21_-2.23_43.81\n",
      "accepted with 352.8529821651264 and 367.95418365787555\n",
      "trying 11677_24.69_-1.21_-2.23_47.81\n",
      "trying 11678_24.69_-1.21_-2.23_51.81\n",
      "trying 11679_24.69_-1.21_-2.23_55.81\n",
      "trying 11684_24.69_-1.21_-2.03_31.81\n",
      "trying 11685_24.69_-1.21_-2.03_35.81\n",
      "trying 11686_24.69_-1.21_-2.03_39.81\n",
      "trying 11687_24.69_-1.21_-2.03_43.81\n",
      "trying 11688_24.69_-1.21_-2.03_47.81\n",
      "trying 11689_24.69_-1.21_-2.03_51.81\n",
      "trying 11690_24.69_-1.21_-2.03_55.81\n",
      "trying 11695_24.69_-1.21_-1.83_31.81\n",
      "trying 11696_24.69_-1.21_-1.83_35.81\n",
      "trying 11697_24.69_-1.21_-1.83_39.81\n",
      "trying 11698_24.69_-1.21_-1.83_43.81\n",
      "trying 11699_24.69_-1.21_-1.83_47.81\n",
      "trying 11700_24.69_-1.21_-1.83_51.81\n",
      "trying 11701_24.69_-1.21_-1.83_55.81\n",
      "trying 11706_24.69_-1.21_-1.63_31.81\n",
      "trying 11707_24.69_-1.21_-1.63_35.81\n",
      "trying 11708_24.69_-1.21_-1.63_39.81\n",
      "trying 11709_24.69_-1.21_-1.63_43.81\n",
      "trying 11710_24.69_-1.21_-1.63_47.81\n",
      "trying 11711_24.69_-1.21_-1.63_51.81\n",
      "trying 11712_24.69_-1.21_-1.63_55.81\n",
      "trying 11717_24.69_-1.21_-1.43_31.81\n",
      "trying 11718_24.69_-1.21_-1.43_35.81\n",
      "trying 11719_24.69_-1.21_-1.43_39.81\n",
      "trying 11720_24.69_-1.21_-1.43_43.81\n",
      "accepted with 350.9802361207185 and 380.0095296242689\n",
      "trying 11721_24.69_-1.21_-1.43_47.81\n",
      "trying 11722_24.69_-1.21_-1.43_51.81\n",
      "trying 11723_24.69_-1.21_-1.43_55.81\n",
      "trying 11729_24.69_-1.21_-1.23_35.81\n",
      "trying 11730_24.69_-1.21_-1.23_39.81\n",
      "trying 11731_24.69_-1.21_-1.23_43.81\n",
      "accepted with 350.49561636508224 and 372.4154856935593\n",
      "trying 11732_24.69_-1.21_-1.23_47.81\n",
      "trying 11733_24.69_-1.21_-1.23_51.81\n",
      "trying 11752_24.69_-0.21_-3.03_39.81\n",
      "trying 11753_24.69_-0.21_-3.03_43.81\n",
      "accepted with 392.0460725768544 and 373.5852596573759\n",
      "trying 11754_24.69_-0.21_-3.03_47.81\n",
      "trying 11762_24.69_-0.21_-2.83_35.81\n",
      "trying 11763_24.69_-0.21_-2.83_39.81\n",
      "trying 11764_24.69_-0.21_-2.83_43.81\n",
      "accepted with 380.0048288708167 and 367.94713252769634\n",
      "trying 11765_24.69_-0.21_-2.83_47.81\n",
      "trying 11766_24.69_-0.21_-2.83_51.81\n",
      "trying 11772_24.69_-0.21_-2.63_31.81\n",
      "trying 11773_24.69_-0.21_-2.63_35.81\n",
      "trying 11774_24.69_-0.21_-2.63_39.81\n",
      "trying 11775_24.69_-0.21_-2.63_43.81\n",
      "trying 11776_24.69_-0.21_-2.63_47.81\n",
      "trying 11777_24.69_-0.21_-2.63_51.81\n",
      "trying 11778_24.69_-0.21_-2.63_55.81\n",
      "trying 11783_24.69_-0.21_-2.43_31.81\n",
      "trying 11784_24.69_-0.21_-2.43_35.81\n",
      "trying 11785_24.69_-0.21_-2.43_39.81\n",
      "trying 11786_24.69_-0.21_-2.43_43.81\n",
      "accepted with 368.48297963613277 and 357.44291884519225\n",
      "trying 11787_24.69_-0.21_-2.43_47.81\n",
      "trying 11788_24.69_-0.21_-2.43_51.81\n",
      "trying 11789_24.69_-0.21_-2.43_55.81\n",
      "trying 11794_24.69_-0.21_-2.23_31.81\n",
      "trying 11795_24.69_-0.21_-2.23_35.81\n",
      "trying 11796_24.69_-0.21_-2.23_39.81\n",
      "trying 11797_24.69_-0.21_-2.23_43.81\n",
      "accepted with 358.06752176385726 and 365.6498138109382\n",
      "trying 11798_24.69_-0.21_-2.23_47.81\n",
      "trying 11799_24.69_-0.21_-2.23_51.81\n",
      "trying 11800_24.69_-0.21_-2.23_55.81\n",
      "trying 11805_24.69_-0.21_-2.03_31.81\n",
      "trying 11806_24.69_-0.21_-2.03_35.81\n",
      "trying 11807_24.69_-0.21_-2.03_39.81\n",
      "trying 11808_24.69_-0.21_-2.03_43.81\n",
      "trying 11809_24.69_-0.21_-2.03_47.81\n",
      "trying 11810_24.69_-0.21_-2.03_51.81\n",
      "trying 11811_24.69_-0.21_-2.03_55.81\n",
      "trying 11816_24.69_-0.21_-1.83_31.81\n",
      "trying 11817_24.69_-0.21_-1.83_35.81\n",
      "trying 11818_24.69_-0.21_-1.83_39.81\n",
      "trying 11819_24.69_-0.21_-1.83_43.81\n",
      "trying 11820_24.69_-0.21_-1.83_47.81\n",
      "trying 11821_24.69_-0.21_-1.83_51.81\n",
      "trying 11822_24.69_-0.21_-1.83_55.81\n",
      "trying 11827_24.69_-0.21_-1.63_31.81\n",
      "trying 11828_24.69_-0.21_-1.63_35.81\n",
      "trying 11829_24.69_-0.21_-1.63_39.81\n",
      "trying 11830_24.69_-0.21_-1.63_43.81\n",
      "trying 11831_24.69_-0.21_-1.63_47.81\n",
      "trying 11832_24.69_-0.21_-1.63_51.81\n",
      "trying 11833_24.69_-0.21_-1.63_55.81\n",
      "trying 11838_24.69_-0.21_-1.43_31.81\n",
      "trying 11839_24.69_-0.21_-1.43_35.81\n",
      "trying 11840_24.69_-0.21_-1.43_39.81\n",
      "trying 11841_24.69_-0.21_-1.43_43.81\n",
      "trying 11842_24.69_-0.21_-1.43_47.81\n",
      "trying 11843_24.69_-0.21_-1.43_51.81\n",
      "trying 11850_24.69_-0.21_-1.23_35.81\n",
      "trying 11851_24.69_-0.21_-1.23_39.81\n",
      "trying 11852_24.69_-0.21_-1.23_43.81\n",
      "trying 11853_24.69_-0.21_-1.23_47.81\n",
      "trying 11854_24.69_-0.21_-1.23_51.81\n",
      "trying 11874_24.69_0.79_-3.03_43.81\n",
      "trying 11875_24.69_0.79_-3.03_47.81\n",
      "accepted with 381.79920575330107 and 403.04382658672966\n",
      "trying 11876_24.69_0.79_-3.03_51.81\n",
      "trying 11884_24.69_0.79_-2.83_39.81\n",
      "trying 11885_24.69_0.79_-2.83_43.81\n",
      "trying 11886_24.69_0.79_-2.83_47.81\n",
      "accepted with 356.2731448813729 and 408.67490258623184\n",
      "trying 11887_24.69_0.79_-2.83_51.81\n",
      "trying 11894_24.69_0.79_-2.63_35.81\n",
      "trying 11895_24.69_0.79_-2.63_39.81\n",
      "trying 11896_24.69_0.79_-2.63_43.81\n",
      "trying 11897_24.69_0.79_-2.63_47.81\n",
      "trying 11898_24.69_0.79_-2.63_51.81\n",
      "trying 11899_24.69_0.79_-2.63_55.81\n",
      "trying 11904_24.69_0.79_-2.43_31.81\n",
      "trying 11905_24.69_0.79_-2.43_35.81\n",
      "trying 11906_24.69_0.79_-2.43_39.81\n",
      "trying 11907_24.69_0.79_-2.43_43.81\n",
      "trying 11908_24.69_0.79_-2.43_47.81\n",
      "trying 11909_24.69_0.79_-2.43_51.81\n",
      "trying 11910_24.69_0.79_-2.43_55.81\n",
      "trying 11915_24.69_0.79_-2.23_31.81\n",
      "trying 11916_24.69_0.79_-2.23_35.81\n",
      "trying 11917_24.69_0.79_-2.23_39.81\n",
      "trying 11918_24.69_0.79_-2.23_43.81\n",
      "accepted with 370.1989873566963 and 354.87885176257623\n",
      "trying 11919_24.69_0.79_-2.23_47.81\n",
      "trying 11920_24.69_0.79_-2.23_51.81\n",
      "trying 11921_24.69_0.79_-2.23_55.81\n",
      "trying 11926_24.69_0.79_-2.03_31.81\n",
      "trying 11927_24.69_0.79_-2.03_35.81\n",
      "trying 11928_24.69_0.79_-2.03_39.81\n",
      "trying 11929_24.69_0.79_-2.03_43.81\n",
      "accepted with 355.2785321612837 and 355.91058957511177\n",
      "trying 11930_24.69_0.79_-2.03_47.81\n",
      "trying 11931_24.69_0.79_-2.03_51.81\n",
      "trying 11932_24.69_0.79_-2.03_55.81\n",
      "trying 11937_24.69_0.79_-1.83_31.81\n",
      "trying 11938_24.69_0.79_-1.83_35.81\n",
      "trying 11939_24.69_0.79_-1.83_39.81\n",
      "trying 11940_24.69_0.79_-1.83_43.81\n",
      "trying 11941_24.69_0.79_-1.83_47.81\n",
      "trying 11942_24.69_0.79_-1.83_51.81\n",
      "trying 11943_24.69_0.79_-1.83_55.81\n",
      "trying 11948_24.69_0.79_-1.63_31.81\n",
      "trying 11949_24.69_0.79_-1.63_35.81\n",
      "trying 11950_24.69_0.79_-1.63_39.81\n",
      "trying 11951_24.69_0.79_-1.63_43.81\n",
      "trying 11952_24.69_0.79_-1.63_47.81\n",
      "trying 11953_24.69_0.79_-1.63_51.81\n",
      "trying 11954_24.69_0.79_-1.63_55.81\n",
      "trying 11960_24.69_0.79_-1.43_35.81\n",
      "trying 11961_24.69_0.79_-1.43_39.81\n",
      "trying 11962_24.69_0.79_-1.43_43.81\n",
      "trying 11963_24.69_0.79_-1.43_47.81\n",
      "trying 11964_24.69_0.79_-1.43_51.81\n",
      "trying 11965_24.69_0.79_-1.43_55.81\n",
      "trying 11971_24.69_0.79_-1.23_35.81\n",
      "trying 11972_24.69_0.79_-1.23_39.81\n",
      "trying 11973_24.69_0.79_-1.23_43.81\n",
      "trying 11974_24.69_0.79_-1.23_47.81\n",
      "trying 11975_24.69_0.79_-1.23_51.81\n",
      "trying 11995_24.69_1.79_-3.03_43.81\n",
      "trying 11996_24.69_1.79_-3.03_47.81\n",
      "accepted with 428.6891981663248 and 355.8988376914822\n",
      "trying 11997_24.69_1.79_-3.03_51.81\n",
      "accepted with 369.0817284108134 and 421.48583649239845\n",
      "trying 12005_24.69_1.79_-2.83_39.81\n",
      "trying 12006_24.69_1.79_-2.83_43.81\n",
      "trying 12007_24.69_1.79_-2.83_47.81\n",
      "accepted with 387.2448347020145 and 373.32086166824774\n",
      "trying 12008_24.69_1.79_-2.83_51.81\n",
      "trying 12009_24.69_1.79_-2.83_55.81\n",
      "trying 12015_24.69_1.79_-2.63_35.81\n",
      "trying 12016_24.69_1.79_-2.63_39.81\n",
      "trying 12017_24.69_1.79_-2.63_43.81\n",
      "trying 12018_24.69_1.79_-2.63_47.81\n",
      "accepted with 356.9691666730296 and 396.1213155390178\n",
      "trying 12019_24.69_1.79_-2.63_51.81\n",
      "trying 12020_24.69_1.79_-2.63_55.81\n",
      "trying 12026_24.69_1.79_-2.43_35.81\n",
      "trying 12027_24.69_1.79_-2.43_39.81\n",
      "trying 12028_24.69_1.79_-2.43_43.81\n",
      "trying 12029_24.69_1.79_-2.43_47.81\n",
      "trying 12030_24.69_1.79_-2.43_51.81\n",
      "trying 12031_24.69_1.79_-2.43_55.81\n",
      "trying 12032_24.69_1.79_-2.43_59.81\n",
      "trying 12036_24.69_1.79_-2.23_31.81\n",
      "trying 12037_24.69_1.79_-2.23_35.81\n",
      "trying 12038_24.69_1.79_-2.23_39.81\n",
      "trying 12039_24.69_1.79_-2.23_43.81\n",
      "trying 12040_24.69_1.79_-2.23_47.81\n",
      "trying 12041_24.69_1.79_-2.23_51.81\n",
      "trying 12042_24.69_1.79_-2.23_55.81\n",
      "trying 12043_24.69_1.79_-2.23_59.81\n",
      "trying 12047_24.69_1.79_-2.03_31.81\n",
      "trying 12048_24.69_1.79_-2.03_35.81\n",
      "trying 12049_24.69_1.79_-2.03_39.81\n",
      "trying 12050_24.69_1.79_-2.03_43.81\n",
      "trying 12051_24.69_1.79_-2.03_47.81\n",
      "trying 12052_24.69_1.79_-2.03_51.81\n",
      "trying 12053_24.69_1.79_-2.03_55.81\n",
      "trying 12058_24.69_1.79_-1.83_31.81\n",
      "trying 12059_24.69_1.79_-1.83_35.81\n",
      "trying 12060_24.69_1.79_-1.83_39.81\n",
      "trying 12061_24.69_1.79_-1.83_43.81\n",
      "trying 12062_24.69_1.79_-1.83_47.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying 12063_24.69_1.79_-1.83_51.81\n",
      "trying 12064_24.69_1.79_-1.83_55.81\n",
      "trying 12069_24.69_1.79_-1.63_31.81\n",
      "trying 12070_24.69_1.79_-1.63_35.81\n",
      "trying 12071_24.69_1.79_-1.63_39.81\n",
      "trying 12072_24.69_1.79_-1.63_43.81\n",
      "trying 12073_24.69_1.79_-1.63_47.81\n",
      "trying 12074_24.69_1.79_-1.63_51.81\n",
      "trying 12075_24.69_1.79_-1.63_55.81\n",
      "trying 12080_24.69_1.79_-1.43_31.81\n",
      "trying 12081_24.69_1.79_-1.43_35.81\n",
      "trying 12082_24.69_1.79_-1.43_39.81\n",
      "trying 12083_24.69_1.79_-1.43_43.81\n",
      "trying 12084_24.69_1.79_-1.43_47.81\n",
      "trying 12085_24.69_1.79_-1.43_51.81\n",
      "trying 12086_24.69_1.79_-1.43_55.81\n",
      "trying 12092_24.69_1.79_-1.23_35.81\n",
      "trying 12093_24.69_1.79_-1.23_39.81\n",
      "trying 12094_24.69_1.79_-1.23_43.81\n",
      "trying 12095_24.69_1.79_-1.23_47.81\n",
      "trying 12096_24.69_1.79_-1.23_51.81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "burial_check_pose = pyrosetta.Pose()\n",
    "left_thresh = 350\n",
    "right_thresh = 350\n",
    "\n",
    "burial_filtered_helices = []\n",
    "\n",
    "for name,helix in tqdm.tqdm_notebook(acceptable_helices):\n",
    "    print(f\"trying {name}\")\n",
    "    burial_check_pose.detached_copy(context_pose)\n",
    "    burial_check_pose.append_pose_by_jump(helix,1)\n",
    "    left_burial_after = left_burial.report_sm(burial_check_pose)\n",
    "    right_burial_after = right_burial.report_sm(burial_check_pose)\n",
    "    delta_left = left_burial_after - left_burial_before\n",
    "    delta_right = right_burial_after - right_burial_before\n",
    "    \n",
    "    if delta_left > left_thresh and delta_right > right_thresh:\n",
    "        \n",
    "        print(f\"accepted with {delta_left} and {delta_right}\")\n",
    "        burial_filtered_helices.append((name,helix))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump( burial_filtered_helices, open( \"burial_filtered_helices.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "for name, helix in random.sample(burial_filtered_helices,30):\n",
    "    helix.dump_pdb(f\"filtered_{name}.pdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(burial_filtered_helices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rdkibler/.conda/envs/pyro/lib/python3.7/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f85e9c310829445b946680ce98fc863c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2026.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#that's enough to dump and do connectchainsmover on!\n",
    "output_pose = pyrosetta.Pose()\n",
    "\n",
    "#os.mkdir(\"output\")\n",
    "\n",
    "for name,helix in tqdm.tqdm_notebook(acceptable_helices):\n",
    "    output_pose.detached_copy(context_pose)\n",
    "    output_pose.append_pose_by_jump(helix,1)\n",
    "    \n",
    "    output_pose.dump_pdb(f\"output/{name}.pdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyro]",
   "language": "python",
   "name": "conda-env-pyro-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
